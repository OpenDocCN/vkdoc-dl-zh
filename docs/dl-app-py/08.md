# 8\. 美国有线电视新闻网在硬

本章将演示如何使用 Keras 建立 CNN 模型。CNN 模型可以帮助你建立一个可以预测和分类图像的图像分类器。一般来说，您在模型架构中创建一些层，这些层具有权重和偏差的初始值。然后，在训练数据集的帮助下，调整权重和偏差变量。在这种情况下，您将学习如何用 Keras 编码。还有另一种方法涉及使用预训练的模型，如 InceptionV3 和 ResNet50，这些模型可以对图像进行分类。

让我们定义一个 CNN 模型，并评估它的性能。您将使用带有卷积层的结构；然后，您将使用 max pooling 并展平网络以完全连接图层并进行预测。

## 为 Keras 中的 MNIST 数据构建影像分类器

在这里，我将演示使用流行的 MNIST 数据集构建手写数字分类器的过程。

这项任务对于玩神经网络来说是一个很大的挑战，但它可以在单台计算机上管理。

MNIST 数据库包含 60，000 幅训练图像和 10，000 幅测试图像。

首先导入 Numpy 并为计算机的伪随机数发生器设置一个种子。这允许您从脚本中重现结果。

```py
import numpy as np
# random seed for reproducibility
np.random.seed(123)

```

接下来，从 Keras 导入顺序模型类型。这只是神经网络层的线性堆栈。

```py
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers import Conv2D
from keras.layers import MaxPooling2d
#Now we will import some utilities
from keras.utils import np_utils
#Fixed dimension ordering issue
from keras import backend as K
K.set_image_dim_ordering('th')

#Load image data from MNIST

#Load pre-shuffled MNIST data into train and test sets
(X_train,y_train),(X_test, y_test)=mnist.load_data()

#Preprocess imput data for Keras

# Reshape input data.
# reshape to be [samples][channels][width][height]
X_train=X_train.reshape(X_train.shape[0],1,28,28)
X_test=X_test.reshape(X_test.shape[0],1,28,28)
# to convert our data type to float32 and normalize our database
X_train=X_train.astype('float32')
X_test=X_test.astype('float32')
print(X_train.shape)

# Z-scoring or Gaussian Normalization
X_train=X_train - np.mean(X_train) / X_train.std()
X_test=X_test – np.mean(X_test) / X_test.std()
#(60000, 1, 28, 28)

# convert 1-dim class arrays to 10 dim class metrices
#one hot encoding outputs
y_train=np_utils.to_categorical(y_train)
y_test-np_utils.to_categorical(y_test)
num_classes=y_test.shape[1]
print(num_classes)
#10

#Define a simple CNN model
print(X_train.shape)
#(60000,1,28,28)

```

### 定义网络结构

网络结构如下:

*   网络有一个卷积输入层，有 32 个大小为 5×5 的特征图。激活函数是整流线性单位。
*   最大池层的大小为 2×2。
*   辍学率设定为 30%。
*   您可以展平图层。
*   该网络具有 240 个单元的全连接层，并且激活函数是指数线性单元。
*   网络的最后一层是具有 10 个单元的全连接输出层，激活函数是 softmax。

然后，使用二元交叉熵作为损失函数，使用 adagrad 作为优化器来编译模型。

### 定义模型架构

该架构由卷积层和最大池化层以及最后的密集层组成。

```py
# create a model

     model=Sequential()
     model.add(Conv2D(32, (5,5), input_shape=(1,28,28), activation="relu"))
     model.add(MaxPooling2D(pool_size=(2,2)))
     model.add(Dropout(0.3))      # Dropout, one form of regularization
     model.add(Flatten())
     model.add(Dense(240,activation='elu'))
     model.add(Dense(num_classes, activation="softmax"))
     print(model.output_shape)
     (None, 10)

# Compile the model

model.compile(loss='binary_crossentropy', optimizer="adagrad", matrices=['accuracy'])

```

然后，通过采用 200 的批量大小，使用训练数据集来拟合模型。该模型从训练数据集中取出前 200 个实例/行(从第 1 个到第 200 个),并训练网络。然后，该模型再次取第二个 200 个实例(从第 201 个到第 400 个)用于训练网络。这样，您可以通过网络传播所有实例。该模型需要较少的内存，因为每次训练的网络实例较少。但是小批量不能很好地估计梯度，因此调整重量和偏差是一个挑战。

一个时期意味着所有训练样本的一次向前传递和一次向后传递。完成一个历元需要多次迭代。

这里，你有 60，000 个训练样本，你的批量是 200 个，那么完成 1 个历元需要 300 次迭代。

```py
# Fit the model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=200)

# Evaluate model on test data

     # Final evaluation of the model
     scores =model.evaluate(X_test, y_test, verbose=0)
     print("CNN error: % .2f%%" % (100-scores[1]*100))
     # CNN Error: 17.98%

     # Save the model
     # save model
     model_json= model.to_join()
     with open("model_json", "w") as json_file:
     json_file.write(model_json)
     # serialize weights to HDFS
     model.save_weights("model.h5")

```

## 利用 CIFAR-10 数据构建图像分类器

本节解释了如何使用 Keras CNN 模型构建一个分类器来对 CIFAR-10 数据集的 10 个标签进行分类。

Note

CIFAR-10 数据集由 10 类 60，000 幅 32×32 彩色图像组成，每类 6，000 幅图像。有 50，000 个训练图像和 10，000 个测试图像。

```py
###########Building CNN Model with CIFAR10 data###################
# plot cifar10 instances
     from keras.datasets import cifar10
     from matplotlib import pyplot
     from scipy.misc import toimage
     import numpy
     from keras.models import Sequential
     from keras.layers import Dense
     from keras.layers import Dropout
     from keras.layers import Flatten
     from keras.layers import Conv2D
     from keras.layers import MaxPooling2d
     #Now we will import some utilities
     from keras.utils import np_utils
     from keras.layers.normalization import BatchNormalization

     #Fixed dimension ordering issue
     from keras import backend as K
     K.set_image_dim_ordering('th')

     # fix random seed for reproducibility
     seed=12
     numpy.random.seed(seed)
     #Preprocess imput data for Keras

     # Reshape input data.
     # reshape to be [samples][channels][width][height]
     X_train=X_train.reshape(X_train.shape[0],3,32,32).astype('float32')
     X_test=X_test.reshape(X_test.shape[0],3,32,32).astype('float32')

     # Z-scoring or Gaussian Normalization
     X_train=X_train - np.mean(X_train) / X_train.std()
     X_test=X_test – np.mean(X_test) / X_test.std()

     # convert 1-dim class arrays to 10 dim class metrices
     #one hot encoding outputs
     y_train=np_utils.to_categorical(y_train)
     y_test-np_utils.to_categorical(y_test)
     num_classes=y_test.shape[1]
     print(num_classes)
     #10

     #Define a simple CNN model
     print(X_train.shape)
     #(50000,3,32,32)

```

### 定义网络结构

网络结构如下:

*   卷积输入层有 32 个大小为 5×5 的特征映射，激活函数是一个校正的线性单元。
*   最大池层的大小为 2×2。
*   卷积层有 32 个大小为 5×5 的特征图，激活函数是一个校正的线性单元。
*   网络有批量归一化。
*   最大池层的大小为 2×2。
*   辍学率设定为 30%。
*   您可以展平图层。
*   全连接层有 240 个单元，激活函数是指数线性单元。
*   全连接输出层有十个单元，激活函数是 softmax。

然后，通过采用 200 的批量大小，使用训练数据集来拟合模型。从训练数据集中取出前 200 个实例/行(从第 1 个到第 200 个)来训练网络。然后你取第二个 200 个实例(从第 201 个到第 400 个)再次训练网络。这样，您可以通过网络传播所有实例。一个时期意味着所有训练样本的一次向前传递和一次向后传递。完成一个历元需要多次迭代。

这里，你有 50，000 个训练样本，你的批量是 200 个，那么完成 1 个历元需要 250 次迭代。

## 定义模型架构

使用卷积层和最大池层的组合创建顺序模型。随后，附着完全连接的致密层。

```py
# create a model

     model=Sequential()
     model.add(Conv2D(32, (5,5), input_shape=(3,32,32), activation="relu"))
     model.add(MaxPooling2D(pool_size=(2,2)))
     model.add(Conv2D(32, (5,5), activation="relu", padding="same"))
     model.add(BatchNormalization())
     model.add(MaxPooling2D(pool_size=(2,2)))
     model.add(Dropout(0.3))      # Dropout, one form of regularization
     model.add(Flatten())
     model.add(Dense(240,activation='elu'))
     model.add(Dense(num_classes, activation="softmax"))
     print(model.output_shape)
     model.compile(loss='binary_crossentropy', optimizer="adagrad")
     # fit model
     model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=200)

     # Final evaluation of the model
     scores =model.evaluate(X_test, y_test, verbose=0)
     print("CNN error: % .2f%%" % (100-scores[1]*100

```

## 预训练模型

在这一部分，我将展示如何使用预训练的模型，如 VGG 和 inception，来构建一个分类器。

![A456157_1_En_8_Figb_HTML.gif](A456157_1_En_8_Figb_HTML.gif)

![A456157_1_En_8_Figa_HTML.gif](A456157_1_En_8_Figa_HTML.gif)

Inception-V3 预训练模型可以检测/分类 22，000 个类别的对象。它可以检测/分类托盘，手电筒，雨伞和其他。

在许多场景中，我们需要根据自己需求构建分类器。为此，在我们使用预训练模型(用于特征提取)和多个神经网络的情况下，使用迁移学习。