# 3.回归

术语“回归”在计量经济学和机器学习之间的常见用法不同。在计量经济学中，回归涉及将因变量与自变量相关联的参数值的估计。计量经济学中最常见的回归形式是多元线性回归，它涉及对连续因变量和多个自变量之间线性关联的估计。然而，在计量经济学中，该术语还包括非线性模型和因变量为离散变量的模型。相反，机器学习中的回归指的是具有连续因变量(目标)的线性或非线性监督学习模型。在本章中，我们将采用回归的更广泛的计量经济学定义，但将介绍机器学习中常用的方法。

## 线性回归

在这一节中，我们将介绍“线性回归”的概念，这是计量经济学中最常用的经验方法。当因变量是连续的，并且因变量和自变量之间的真实关系被假定为线性时，使用它。

### 概观

线性回归对因变量 *Y* 和一组自变量{*X*T4】0，…， *X* <sub>*k*</sub> }之间的关系进行建模，假设系数是线性的。线性要求每个 *X* <sub>*j*</sub> 和 *Y* 之间的关系可以建模为一个常数斜率，用一个标量系数 *β* <sub>*j*</sub> 来表示。等式 3-1 提供了独立变量为 k 的线性模型的一般形式。

*方程式 3-1。一个* *线性模型。*

![$$ Y=\alpha +{\beta}_0{X}_0+\dots +{\beta}_{k-1}{X}_{k-1} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equa.png)

在许多情况下，我们将采用方程 3-2 中给出的符号，它明确地为每个观测值指定一个指数。 *Y* <sub>*i*</sub> 例如，表示实体 *i* 的变量 *Y* 的值。

*方程式 3-2。具有实体指数的* *线性模型。*

![$$ {Y}_i=\alpha +{\beta}_0{X}_{i0}+\dots +{\beta}_{k-1}{X}_{ik-1} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equb.png)

除了实体指数，我们在经济问题中还会经常用到时间指数。在这种情况下，我们通常会使用一个 *t* 下标来表示变量被观测的时间段，就像我们在方程 3-3 中所做的那样。

*方程式 3-3。一个* *带有实体和时间索引的线性模型。*

![$$ {Y}_{it}=\alpha +{\beta}_0{X}_{it0}+\dots +{\beta}_{k-1}{X}_{it k-1} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equc.png)

在线性回归中，模型参数{α，β <sub>1</sub> ，…， *β* <sub>*k*</sub> }不会随时间或实体而变化，因此也不会被任何实体索引。此外，不允许参数的非线性变换。例如，密集神经网络层具有类似的函数形式，但对系数可变乘积的和应用非线性变换，如等式 3-4 所示，其中 *σ* 表示 sigmoid 函数。

*方程式 3-4。具有 sigmoid 激活函数的神经网络的* *密集层。*

![$$ {Y}_{it}=\sigma \left(\alpha +{\beta}_0{X}_{it0}+\dots +{\beta}_{k-1}{X}_{it k-1}\right) $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equd.png)

虽然线性可能看起来是一个严重的函数形式限制，但它并不妨碍我们对独立变量应用变换，包括非线性变换。例如，我们可以将 *X* <sub>0</sub> 重新定义为其自然对数，并将其作为独立变量。线性回归也允许两个变量之间的相互作用，如*X*T6】0∑*X*<sub>1</sub>或指标变量，如![$$ {1}_{\left\{{X}_0&gt;{x}_0\right\}} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq1.png)。另外，在时序和面板设置中，我们可以包含变量的滞后，例如*X*<sub>*t*—1*j*</sub>和*X*<sub>*t*—2*j*</sub>。

变换和重新定义变量使线性回归成为一种灵活的方法，可用于以任意高的精度逼近非线性函数。例如，考虑这样的情况，其中 *X* 和 *Y* 之间的真实关系由等式 3-5 中的指数函数给出。

*方程式 3-5。指数模型。*

![$$ {Y}_i=\mathit{\exp}\left(\alpha +\beta {X}_i\right) $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Eque.png)

如果我们取 *Y* <sub>*i*</sub> 的自然对数，就可以在方程 3-6 中进行线性回归，恢复出模型参数，{ *α* ， *β* }。

*方程式 3-6。一个* *转换后的指数模型。*

![$$ \ln \left({Y}_i\right)=\alpha +\beta {X}_i $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equf.png)

在大多数情况下，我们不知道底层的数据生成过程(DGP)。此外，因变量和自变量之间没有确定的关系。相反，会有一些噪声， *ϵ* <sub>*i*</sub> ，与每个观察相关联，这可能是由于未观察到的、实体间的随机差异或测量误差而引起的。

作为一个例子，假设我们从一个已知为非线性的过程中提取数据，但其确切的函数形式未知。图 [3-1](#Fig1) 显示了数据的散点图，以及两个线性回归模型的曲线图。第一个是在假设 *X* 和 *Y* 之间的关系在[0，10]区间上用一条直线很好地逼近的情况下训练的，如等式 3-7 所示。第二种是在假设需要五条线段的情况下训练的，如等式 3-8 所示。

*方程式 3-7。一个* *线性逼近一个非线性模型。*

![$$ {Y}_i=\alpha +\beta {X}_i+{\epsilon}_i $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equg.png)

等式 3-8。 *一种非线性关系的线性近似。*

![$$ {Y}_i=\left[{\alpha}_0+{\beta}_0{X}_i\right]\ {1}_{\left\{0\le {X}_i&lt;2\right\}}+\dots +\left[{\alpha}_0+{\beta}_0\left({X}_i-8\right)\right]\ {1}_{\left\{8\le {X}_i\le 10\right\}}+{\epsilon}_i $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equh.png)

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig1_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig1_HTML.png)

图 3-1

非线性函数的两种线性近似

图 [3-1](#Fig1) 表明使用单一斜率和截距的线性回归模型是不够的；然而，即使我们完全在线性回归的框架内工作，以分段多项式样条的形式使用多个线段也足以逼近非线性函数。

### 普通最小二乘法(OLS)

正如我们所看到的，线性回归是一种通用的方法，可以用来模拟因变量和自变量之间的关系。即使这种关系是非线性的，我们也看到了使用指示函数、变量交互或变量转换在线性模型中逼近它的可能性。在某些情况下，我们甚至能够通过变量转换准确地捕捉到它。

在本节中，我们将讨论如何在 TensorFlow 中实现线性回归。我们这样做的方式将取决于我们对损失函数的选择。在经济学中，最常见的损失函数是误差平方和或均值，这是我们首先要考虑的。出于这个例子的目的，我们将把所有的独立变量堆叠在一个 *n x k* 矩阵、 *X* 中，其中 *n* 是观察值的数量， *k* 是独立变量的数量，包括常数(偏差)项。

我们将让![$$ \hat{\beta} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq2.png)表示独立变量上的估计系数的向量，我们将其与真实参数值 *β* 区分开来。我们用来构造损失函数的“误差”项在方程 3-9 中给出。它通常有不同的名称，如误差项、残差项或扰动项。

*方程式 3-9。线性回归中的扰动项。*

![$$ \epsilon =Y-\hat{\beta}X $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equi.png)

注意， *ϵ* 是一个 *n* 元素的列向量。这意味着我们可以通过预乘其转置来平方和求和每个元素，如等式 3-10 所示，这给出了误差平方和。

*方程式 3-10。误差平方和。*

![$$ {\epsilon}^{\prime}\epsilon ={\left(Y-\hat{\beta}X\right)}^{\prime}\left(Y-\hat{\beta}X\right) $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equj.png)

使用误差平方和作为损失函数(也称为执行“普通最小二乘法”(OLS))的一个好处是，它允许解析解，如方程 3-11 所示，这意味着我们不需要使用耗时且容易出错的优化算法。我们通过选择![$$ \hat{\beta} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq3.png)使误差平方和最小来获得这个解。

*方程式 3-11。最小化误差平方和。*

![$$ \frac{\partial {\epsilon}^{\prime}\epsilon }{\partial \hat{\beta}}=\frac{\partial }{\partial \hat{\beta}}{\left(Y-\hat{\beta}X\right)}^{\prime}\left(Y-\hat{\beta}X\right)=0 $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equk.png)

![$$ -2{X}^{\prime }Y+2{X}^{\prime }X\ \hat{\beta}=0 $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equl.png)

![$$ {X}^{\prime }X\hat{\beta}={X}^{\prime }Y $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equm.png)

![$$ \hat{\beta}={\left({X}^{\prime }X\right)}^{-1}{X}^{\prime }Y $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equn.png)

唯一需要检查的是![$$ \hat{\beta} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq4.png)是最小值还是最大值。每当 *X* 拥有“满秩”时，它将是最小值如果 X 的任何一列都不是 X 的一个或多个其他列的线性组合，这将成立。清单 [3-1](#PC1) 演示了我们如何在 TensorFlow 中为一个玩具问题执行普通最小二乘法(OLS)。

```py
import tensorflow as tf

# Define the data as constants.
X = tf.constant([[1, 0], [1, 2]], tf.float32)
Y = tf.constant([[2], [4]], tf.float32)

# Compute vector of parameters.
XT = tf.transpose(X)
XTX = tf.matmul(XT,X)
beta = tf.matmul(tf.matmul(tf.linalg.inv(XTX),XT),Y)

Listing 3-1Implementation of OLS in TensorFlow 2

```

为了方便起见，我们将 *X* 的转置定义为 *XT* 。我们还将 *XTX* 定义为 *XT* 乘以 *X* 。我们可以通过反相 *XTX* ，后乘 *XT* ，然后再后乘 Y 来计算![$$ \hat{\beta} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq5.png)。

我们计算的参数向量![$$ \hat{\beta} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq6.png)，使误差平方和最小。虽然计算![$$ \hat{\beta} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq7.png)很简单，但我们可能不清楚为什么要使用 TensorFlow 来完成这样的任务。如果我们使用 MATLAB，编写线性代数运算的语法应该是紧凑的和可读的。或者，如果我们使用了 Stata 或 Python 或 R 中的任何统计模块，我们将能够自动计算参数向量的标准误差和置信区间，以及回归拟合度。

当然，如果一项任务需要并行或分布式计算，TensorFlow 确实有天然的优势；然而，当分析性地执行 OLS 时，这种需要可能是次要的。当我们想要最小化没有解析解的损失函数时，或者当我们无法在内存中保存所有数据时，TensorFlow 的价值将变得显而易见。

### 最小绝对偏差

虽然 OLS 是经济学中最常用的线性回归形式，并且具有许多吸引人的特性，但我们有时会希望使用另一种损失函数。例如，我们可能希望最小化误差的绝对值之和，而不是平方和。这种形式的线性回归被称为最小绝对偏差(LAD)或最小绝对误差(LAE)。

对于所有模型，包括 OLS 和拉德，参数估计对异常值的敏感性是由损失函数驱动的。由于 OLS 最小化了误差的平方，它高度重视设置参数值来解释异常值。也就是说，OLS 将更加重视消除一个单一的大误差，而不是两个误差的一半。相反，LAD 会对较大的误差和两个较小的误差给予同等的重视。

OLS 和 LAD 之间的另一个区别是，我们不能解析地表达 LAD 回归的解，因为绝对值阻止我们获得封闭形式的代数表达式。这意味着我们必须通过“训练”或“估计”模型来寻找最小值。

虽然 TensorFlow 对求解 OLS 并不特别有用，但在执行 LAD 回归或训练另一种没有解析解的模型时，它具有明显的优势。我们将在 TensorFlow 中了解如何做到这一点，同时评估 TensorFlow 识别真实参数值的准确性。更具体地说，我们将执行蒙特卡罗实验，在该实验中，我们在某些假定的参数值下随机生成数据。然后，我们将使用这些数据来估计模型，从而允许我们比较真实参数和估计参数。

清单 [3-2](#PC2) 显示了数据是如何生成的。我们首先定义观察值的数量和样本的数量。由于我们想要评估 TensorFlow 的性能，我们将在 100 个单独的样本上训练模型参数。我们还将使用 10，000 次观察来确保有足够的数据来训练模型。

接下来，我们定义模型参数`alpha`和`beta`的真实值，它们对应于常数(偏差)项和斜率。我们将常数项设置为 1.0，斜率设置为 3.0。由于这些是参数的真实值，不需要训练，我们将使用`tf.constant()`来定义它们。

我们现在从正态分布中画出`X`和`epsilon`。对于`X`，我们使用标准正态分布，其均值为 0，标准差为 1。这些是`tf.random.normal()`的默认参数值，因此我们不需要指定样本数和观察数之外的任何内容。对于ε，我们使用标准偏差 0.25，这是我们使用`stddev`参数指定的。最后，我们计算因变量`Y`。

我们现在可以使用生成的数据通过 LAD 来训练模型。我们需要完成几个步骤，这些步骤在 TensorFlow 中的所有模型构建和训练流程中都是通用的。我们将首先用一个例子来说明它们，这个例子只利用了随机抽取的数据的第一个样本。然后，我们将对 100 个样本中的每一个重复这一过程。

```py
import tensorflow as tf

# Set number of observations and samples
S = 100
N = 10000

# Set true values of parameters.
alpha = tf.constant([1.], tf.float32)
beta = tf.constant([3.], tf.float32)

# Draw independent variable and error.
X = tf.random.normal([N, S])
epsilon = tf.random.normal([N, S], stddev=0.25)

# Compute dependent variable.
Y = alpha + beta*X + epsilon

Listing 3-2Generate input data for a linear regression

```

清单 [3-3](#PC3) 提供了 TensorFlow 中模型训练过程第一步的代码。我们首先从平均值为 0、标准偏差为 5.0 的正态分布中提取值，然后用它们来初始化`alphaHat`和`betaHat`。5.0 的选择是任意的，但是旨在模拟一个问题，其中我们对真实参数值的先验知识有限。我们使用后缀“Hat”来表示这些不是真实值，而是估计值。由于我们想要训练参数以最小化损失函数，我们将使用`tf.Variable()`而不是`tf.constant()`来定义它们。

下一步是定义一个函数来计算损失。LAD 回归最小化绝对误差的总和，这相当于最小化平均绝对误差。我们将最小化平均绝对误差，因为这有更好的数值特性。 <sup>[1](#Fn1)</sup>

为了计算平均绝对误差，我们定义了一个名为`maeLoss`的函数，它将参数和数据作为输入，并输出损失函数的相关值。该函数首先计算每个观测值的误差。然后使用`tf.abs()`将这些值转换成绝对值，然后使用`tf.reduce_mean()`返回所有观察值的平均值。

```py
# Draw initial values randomly.
alphaHat0 = tf.random.normal([1], stddev=5.0)
betaHat0 = tf.random.normal([1], stddev=5.0)

# Define variables.
alphaHat = tf.Variable(alphaHat0, tf.float32)
betaHat = tf.Variable(betaHat0, tf.float32)

# Define function to compute MAE loss.
def maeLoss(alphaHat, betaHat, xSample, ySample):
        prediction = alphaHat + betaHat*xSample
        error = ySample – prediction
        absError = tf.abs(error)
        return tf.reduce_mean(absError)

Listing 3-3Initialize variables and define the loss

```

最后一步是执行优化，我们在清单 [3-4](#PC4) 中进行了优化。为此，我们将首先使用`tf.optimizers.SGD()`创建一个名为`opt`的随机梯度下降优化器实例。然后，我们将使用该实例来执行最小化。这包括将`minimize()`方法应用于`opt`。为了对整个样本执行单步优化，我们将把损失作为`lambda`函数返回给`minimize`操作。此外，我们将参数`alphaHat`和`betaHat`以及输入数据的第一个样本`X[:,0]`和`Y[0:]`传递给`maeLoss().`，最后，我们还需要将可训练变量列表`var_list`传递给`minimize()`。循环的每个增量执行一个最小化步骤，该步骤更新优化器的参数和状态。在这个例子中，我们已经重复最小化步骤 1000 次。

```py
# Define optimizer.
opt = tf.optimizers.SGD()

# Define empty lists to hold parameter values.
alphaHist, betaHist = [], []

# Perform minimization and retain parameter updates.
for j in range(1000):

        # Perform minimization step.
        opt.minimize(lambda: maeLoss(alphaHat, betaHat,
        X[:,0], Y[:,0]), var_list = [alphaHat,
        betaHat])

        # Update list of parameters.
        alphaHist.append(alphaHat.numpy()[0])
        betaHist.append(betaHat.numpy()[0])

Listing 3-4Define an optimizer and minimize the loss function

```

在我们对剩余的 99 个样本重复这个过程之前，让我们看看我们在第一个样本中识别真实参数值有多成功。图 [3-2](#Fig2) 显示了最小化过程中每一步`alphaHat`和`betaHat`值的曲线图。生成该图的代码如清单 [3-5](#PC5) 所示。请注意，我们没有将样本分成小批量，因此每一步都被标记为一个时期，其中一个时期是样本的一次完整传递。正如我们前面看到的，初始值是从一个方差很大的正态分布中随机产生的。然而，`alphaHat`和`betaHat`似乎在大约 600 个时期后收敛到它们的真实参数值。

```py
# Define DataFrame of parameter histories.
params = pd.DataFrame(np.hstack([alphaHist,
        betaHist]), columns = ['alphaHat', 'betaHat'])

# Generate plot.
params.plot(figsize=(10,7))

# Set x axis label.
plt.xlabel('Epoch')

# Set y axis label.
plt.ylabel('Parameter Value')

Listing 3-5Plot the parameter training histories

```

此外，`alphaHat`和`betaHat`在它们收敛到它们的真实参数值后似乎不再进一步调整。这表明训练过程是稳定的，我们将在本章后面详细讨论的随机梯度下降算法能够确定一个明确的局部最小值，在这种情况下，它被证明是全局最小值。 <sup>[2](#Fn2)</sup>

现在我们已经测试了一个样本的求解方法，我们将用不同的初始参数值和不同的样本重复这个过程 100 次。然后，我们将评估我们的解决方法的性能，以确定它是否对初始值的选择或提取的数据样本敏感。图 [3-3](#Fig3) 显示了每个样本在第 1000 个时期的参数值估计直方图。大多数估计似乎紧紧围绕着真实的参数值；然而，由于初始值或抽取的样本，存在一些偏差。如果我们计划在属性类似于我们在蒙特卡罗实验中生成的数据集上使用 LAD，我们可能会考虑使用更多的历元来增加我们收敛到真实参数值的概率。

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig2_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig2_HTML.png)

图 3-2

超过 1000 个训练时期的参数值历史

除了改变历元的数量，我们可能还想考虑调整优化算法的超参数，而不是使用默认选项。或者，我们可以考虑完全使用不同的优化算法。正如我们将在本章后面讨论的，这在 TensorFlow 中是相对简单的。

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig3_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig3_HTML.png)

图 3-3

蒙特卡罗实验的参数估计计数

### 其他损失函数

正如我们所讨论的，OLS 有一个解析解，但拉德没有。由于大多数机器学习模型不允许解析解，因此 LAD 可以提供一个有指导意义的示例。我们用于构建模型、定义损失函数和执行 LAD 最小化的相同过程将在本章和本书中重复。实际上，通过简单地修改损失函数，用于执行 LAD 的步骤可以应用于任何形式的线性回归。

当然，除了 OLS 有一个封闭的解决方案之外，还有其他支持它的理由。例如，如果满足高斯-马尔可夫定理的条件，那么 OLS 估计量在所有线性和无偏估计量中具有最低的方差。 <sup>[3](#Fn3)</sup> 还有大量基于 OLS 及其变体的计量经济学文献，这使其成为相关工作的自然选择。

然而，在经济学和金融学的许多机器学习应用中，目标通常是执行预测，而不是假设检验。在这些情况下，使用不同形式的线性回归可能是有意义的；而使用 TensorFlow 会让这个任务变得更简单。

## 部分线性模型

在许多机器学习应用中，我们希望以一种使用线性回归模型无法令人满意地实现的方式对非线性进行建模，即使使用我们之前概述的策略也是如此。这将需要我们使用不同的建模技术。在本节中，我们将扩展线性模型，以允许包含非线性函数。

我们将从所谓的“部分线性模型”开始，而不是构建一个纯粹的非线性模型这种模型允许某些独立变量线性进入，而允许其他变量通过非线性函数进入模型。

在标准计量经济学应用的背景下，目标通常是统计推断，部分线性模型通常由线性输入的单个感兴趣变量和允许非线性输入的一组控制组成。这种练习的目的是对线性输入的参数进行推断。

然而，用部分线性模型进行有效的统计推断存在计量经济学的挑战。首先，当感兴趣的变量和控制共线时，存在参数一致性的问题。 <sup>[4](#Fn4)</sup> 这在 Robinson (1988)中有所论述，他为这种情况构造了一个一致的估计量。 <sup>[5](#Fn5)</sup> 当我们将正则化应用于控制的非线性函数时，另一个问题出现了。如果我们简单地应用 Robinson (1988)的估计量，感兴趣的参数将是有偏的。Chernozhukov 等人(2017)演示了如何通过使用正交化和样本分割来消除偏倚。

出于本章的目的，我们将专门关注用于预测目的的部分线性模型的构建和训练，而不是用于统计推断。在此过程中，我们将回避与一致性和偏差相关的问题，并将重点放在 TensorFlow 中训练程序的实际实施上。

我们将从定义我们希望在等式 3-12 中训练的模型开始。这里， *β* 是线性进入模型的系数向量， *g* ( *Z* )是控制的非线性函数。

*方程式 3-12。一个* *部分线性模型。*

![$$ Y=\alpha +\beta X+g(Z)+\epsilon $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equo.png)

与 LAD 的示例类似，我们将使用蒙特卡罗实验来评估我们是否在 TensorFlow 中正确构建和训练了模型，并确定在给定样本大小和模型规格的情况下，我们是否可能会遇到数值问题。

为了执行蒙特卡洛实验，我们需要对线性参数的值以及 *g* ()的函数形式做出具体假设。为了简单起见，我们假设只有一个感兴趣的变量， *X* ，和一个控制， *Z* ，它以函数形式 exp(θZ)进入。此外，真实参数值假定为 *α* = 1、 *β* = 3、 *θ* = 0.05。

我们将通过生成数据来开始清单 [3-6](#PC6) 中的蒙特卡洛实验。和前面的例子一样，我们将使用 100 个样本和 10，000 个观察值，并使用`tf.constant()`定义真实的参数值。接下来，我们将绘制回归量`X`和`Z`以及误差项`epsilon`的实现。最后，我们使用随机生成的数据来构建因变量`Y`。

```py
import tensorflow as tf

# Set number of observations and samples
S = 100
N = 10000

# Set true values of parameters.
alpha = tf.constant([1.], tf.float32)
beta = tf.constant([3.], tf.float32)
theta = tf.constant([0.05], tf.float32)

# Draw independent variable and error.
X = tf.random.normal([N, S])
Z = tf.random.normal([N, S])
epsilon = tf.random.normal([N, S], stddev=0.25)

# Compute dependent variable.
Y = alpha + beta*X + tf.exp(theta*Z) + epsilon

Listing 3-6Generate data for partially linear regression experiment

```

清单 [3-7](#PC7) 中显示的下一步是定义和初始化模型参数:`alphaHat0`、`betaHat0`和`thetaHat0`。然后，我们稍微偏离前面的例子:不是立即计算损失函数，我们将首先为部分线性模型定义一个函数，它将参数和数据样本作为输入，然后输出每个观察的预测。

```py
# Draw initial values randomly.
alphaHat0 = tf.random.normal([1], stddev=5.0)
betaHat0 = tf.random.normal([1], stddev=5.0)
thetaHat0 = tf.random.normal([1], mean=0.05,
            stddev=0.10)

# Define variables.
alphaHat = tf.Variable(alphaHat0, tf.float32)
betaHat = tf.Variable(betaHat0, tf.float32)
thetaHat = tf.Variable(thetaHat0, tf.float32)

# Compute prediction.
def plm(alphaHat, betaHat, thetaHat, xS, zS):
        prediction = alphaHat + betaHat*xS + \
                        tf.exp(thetaHat*zS)
        return prediction

Listing 3-7Initialize variables and compute the loss

```

我们现在已经生成了数据，初始化了参数，并定义了部分线性模型。下一步是定义一个损失函数，我们在清单 [3-8](#PC8) 中就是这么做的。和前面的例子一样，我们可以使用最适合我们问题的损失函数。在这种情况下，我们将使用平均绝对误差(MAE)。此外，我们将使用张量流运算，而不是像以前那样自己计算 MAE。`tf.losses.mae()`操作的第一个参数是一个真值数组，第二个是一个预测值数组。

```py
# Define function to compute MAE loss.
def maeLoss(alphaHat, betaHat, thetaHat, xS, zS, yS):
        yHat = plm(alphaHat, betaHat, thetaHat, xS, zS)
        return tf.losses.mae(yS, yHat)

Listing 3-8Define a loss function for a partially linear regression

```

最后一步是执行最小化，这是我们在清单 [3-9](#PC9) 中做的。与在 LAD 示例中一样，我们将通过实例化一个优化器，然后应用 minimize 方法来实现这一点。每次我们执行 minimize 方法，我们将完成一个完整的训练周期。

```py
# Instantiate optimizer.
opt = tf.optimizers.SGD()

# Perform optimization.
for i in range(1000):
        opt.minimize(lambda: maeLoss(alphaHat, betaHat,
        thetaHat, X[:,0], Z[:,0], Y[:,0]),
        var_list = [alphaHat, betaHat, thetaHat])

Listing 3-9Train a partially linear regression model

```

优化过程结束后，我们可以评估结果，就像我们对 LAD 示例所做的那样。图 [3-4](#Fig4) 显示了 1000 个训练时期的参数值估计历史。请注意，`alphaHat`、`betaHat`和`thetaHat`在大约 800 个时期的训练后都收敛到它们的真实值。此外，随着训练过程的继续，他们似乎没有偏离他们的真实值。

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig4_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig4_HTML.png)

图 3-4

超过 1000 个训练时期的参数值历史

除此之外，我们还将检查所有 100 个样本的估计值，看看结果对初始化和数据有多敏感。每个样本的最终历元参数值在图 [3-5](#Fig5) 的直方图中显示。从图中可以清楚地看出，`alphaHat`和`betaHat`的估计值都紧紧围绕着它们各自的真实值。虽然`thetaHat`看起来是无偏的，但由于直方图以`theta`的真实值为中心，估计值中似乎有更多的变化。这表明我们可能想要对训练过程进行调整，可能通过使用更高数量的纪元。

执行 LAD 回归和部分线性回归证明 TensorFlow 能够处理任意模型的构建和训练，包括那些包含非线性的模型。在下一节中，我们将看到 TensorFlow 也可以处理离散的因变量。然后，我们将通过讨论调整培训过程以改善结果的各种方法来结束本章。

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig5_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig5_HTML.png)

图 3-5

部分线性回归的蒙特卡罗实验结果

## 非线性回归

在上一节中，我们讨论了部分线性模型，它既有线性部分，也有非线性部分。求解完全非线性模型可以使用与部分线性模型相同的工作流程来完成。我们首先生成或加载数据。接下来，我们定义模型和损失函数。最后，我们实例化一个优化器并执行损失函数的最小化。

我们将利用美元(USD)和英镑(GBP)每日汇率的自然对数，而不是使用生成的数据，如图 [3-6](#Fig6) 所示。 <sup>[6](#Fn6)</sup>

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig6_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig6_HTML.png)

图 3-6

每日频率下美元对英镑汇率的自然对数(1970-2020)。资料来源:美国联邦储备理事会

由于汇率很难预测，随机游走经常被用作预测练习中的基准模型。如等式 3-13 所示，随机游走将下一期的汇率建模为本期的汇率加上一些随机噪声。

*方程式 3-13。一个* *名义汇率的随机游走模型* *。*

![$$ {e}_t=\alpha +{e}_{t-1}+{\epsilon}_t $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equp.png)

20 世纪 90 年代出现的一系列文献认为，门限自回归(TAR)模型可以产生对随机游走模型的改进。提出了这种模型的几种变体，包括平滑过渡自回归模型(STAR)和指数平滑自回归模型(ESTAR)。 <sup>[7](#Fn7)</sup>

我们的练习将集中于在 TensorFlow 中实施 TAR 模型，并通过使用名义汇率而非实际汇率等方式偏离文献。此外，我们将再次通过关注预测来从与统计推断相关的问题中抽象出来。

自回归模型假设序列中的运动可以用序列的过去值和噪声来解释。例如，随机游走是一阶自回归模型——因为它包含一个滞后——自回归参数为 1。自回归参数是因变量滞后值的系数。

TAR 模型通过允许参数值根据预定义的阈值变化来修改自回归。也就是说，参数被假定为在特定的制度内是固定的，但是可以在不同的制度之间变化。我们将使用方程 3-14 中给出的状态。如果出现超过 2%的大幅贬值，那么我们处于一种状态，与一个自回归参数值相关联。否则，我们就另当别论了。

*方程式 3-14。一个具有两种状态的* *门限自回归(TAR* *)模型* *。*

![$$ {e}_t=\left\{\begin{array}{c}{\rho}_0{e}_{t-1}+{\epsilon}_t,\kern0.5em {\epsilon}_{t-1}-{\epsilon}_{t-2}&lt;-0.02\\ {}{\rho}_1{e}_{t-1}+{\epsilon}_t,\kern0.5em {\epsilon}_{t-1}-{\epsilon}_{t-2}\ge -0.02\end{array}\right. $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equq.png)

TensorFlow 实现的第一步是准备数据。为了做到这一点，我们需要加载名义汇率的日志，计算一个滞后，并计算一个滞后一阶差。我们将加载并转换`pandas`和`numpy`中的数据。然后我们将它们转换成`tf.constant()`物体。对于阈值变量，我们还需要将其类型从布尔值更改为 32 位浮点数。所有步骤如清单 [3-10](#PC10) 所示。

```py
import pandas as pd
import numpy as np
import tensorflow as tf

# Define data path.
data_path = '../data/chapter3/'

# Load data.
data = pd.read_csv(data_path+'exchange_rate.csv')

# Convert log exchange rate to numpy array.
e = np.array(data["log_USD_GBP"])

# Identify exchange decreases greater than 2%.
de = tf.cast(np.diff(e[:-1]) < -0.02, tf.float32)

# Define the lagged exchange rate as a constant.
le = tf.constant(e[1:-1], tf.float32)

# Define the exchange rate as a constant.
e = tf.constant(e[2:], tf.float32)

Listing 3-10Prepare the data for a TAR model

of the USD-GBP exchange rate

```

现在数据已经准备好，我们将在清单 [3-11](#PC11) 中定义可训练模型参数`rho0Hat`和`rho1Hat`。

```py
# Define variables.
rho0Hat = tf.Variable(0.80, tf.float32)
rho1Hat = tf.Variable(0.80, tf.float32)

Listing 3-11Define parameters for a TAR model of the USD-GBP exchange rate

```

我们接下来在清单 [3-12](#PC12) 中定义模型和损失函数。然后，我们将自回归系数乘以制度的虚拟变量`de`。最后，这要乘以汇率的滞后值`le`。为了简单起见，我们将使用平均绝对损失函数和张量流运算。

```py
# Define model.
def tar(rho0Hat, rho1Hat, le, de):
        # Compute regime-specific prediction.
        regime0 = rho0Hat*le
        regime1 = rho1Hat*le
        # Compute prediction for regime.
        prediction = regime0*de + regime1*(1-de)
        return prediction

# Define loss.
def maeLoss(rho0Hat, rho1Hat, e, le, de):
        ehat = tar(rho0Hat, rho1Hat, le, de)
        return tf.losses.mae(e, ehat)

Listing 3-12Define model and loss function for TAR model of USD-GBP exchange rate

```

最后一步是定义一个优化器并执行优化，这是我们在清单 [3-13](#PC13) 中所做的。

图 [3-7](#Fig7) 显示了培训历史。“正常”状态的自回归参数——前一天没有出现大幅贬值——迅速收敛到大约 1.0。这表明，在正常时期，汇率最好被建模为随机游走。然而，当我们观察前一天发生大幅贬值的情况时，我们发现自回归系数为 0.993，表明汇率将高度持续，但将倾向于向其均值漂移，而不是永久保持较低水平。

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig7_HTML.jpg](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig7_HTML.jpg)

图 3-7

美元对英镑汇率 TAR 模型的培训历史

```py
# Define optimizer.
opt = tf.optimizers.SGD()

# Perform minimization.
for i in range(20000):
        opt.minimize(lambda: maeLoss(
        rho0Hat, rho1Hat, e, le, de),
        var_list = [rho0Hat, rho1Hat]
        )

Listing 3-13Train TAR model of the USD-GBP exchange rate

```

我们现在已经了解了如何在 TensorFlow 中使用不同的损失函数执行线性回归、部分线性回归和非线性回归。在下一节中，我们将研究另一种类型的回归，它有一个离散的因变量。

## 逻辑回归

在机器学习中，监督学习模型通常根据它们是否具有离散或连续的因变量而分为“回归”和“分类”类别。如前所述，我们将使用计量经济学中回归的定义，它也适用于分类模型，如逻辑回归。

逻辑回归或“logit”预测因变量的类别。在微观经济环境中，logit 可以用来模拟两种交通方式的选择。在金融环境中，它可能被用来模拟我们是否处于危机之中。

由于构建和训练逻辑回归的过程涉及许多与线性、部分线性和非线性回归相同的步骤，因此我们将专门关注不同之处。

首先，该模型采用特定的函数形式，即逻辑曲线形式，如等式 3-15 所示。

*方程式 3-15。逻辑曲线。*

![$$ p(X)=\frac{1}{1+{e}^{-\left(\alpha +{\beta}_0{X}_0+\dots +{\beta}_k{X}_k\right)}} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equr.png)

请注意，模型的输出是一个连续的概率，而不是一个离散的结果。由于概率范围从 0 到 1，大于 0.5 的概率通常被视为结果 1 的预测。虽然这种函数形式不同于我们在本章之前处理的任何形式，但它可以使用 TensorFlow 中所有相同的工具和操作来处理。

最后，逻辑模型和我们在本章前面定义的模型的另一个区别是它需要不同的损失函数。具体来说，我们将使用二元交叉熵损失函数，它在方程 3-16 中定义。

*方程式 3-16。二元交叉熵损失函数。*

![$$ {\Sigma}_i-\Big({Y}_i\ast \log \left(p\left({X}_i\right)\right)+\left(1-{Y}_i\right)\ast \log \left(1-p\left({X}_i\right)\right) $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equs.png)

我们使用这种特殊的函数形式，因为结果是离散的，而预测是连续的。请注意，二元交叉熵损失的总和是结果变量与每次观察的预测概率的自然对数的乘积。例如，如果 *Y* <sub>*i*</sub> 的真实类别是 1，并且模型预测类别 1 的概率是 0.98，那么该观察将会给损失增加 0.02。相反，如果预测值为 0.10，这与真实分类相差甚远，那么损失的增加将改为 2.3。

虽然计算二元交叉熵损失函数相对简单，但 TensorFlow 通过提供操作`tf.losses.binary_crossentropy()`进一步简化了它，该操作将真实标签作为其第一个参数，将预测概率作为其第二个参数。

## 损失函数

每当我们在 TensorFlow 中求解一个模型时，我们都需要定义一个损失函数。最小化操作将利用该函数来确定如何调整参数值。幸运的是，并不总是需要定义一个定制的损失函数。相反，我们通常能够使用 TensorFlow 提供的预定义损失函数之一。

TensorFlow 目前有两个子模块包含损失函数:`tf.losses`和`tf.keras.losses`。第一个子模块包含损失函数的本地张量流实现。第二个子模块包含损失函数的 Keras 实现。Keras 是一个用于执行深度学习的库，既可以作为 Python 中的独立模块，也可以作为 TensorFlow 中的高级 API。

TensorFlow 2.3 在`tf.losses`子模块中提供了 15 个标准损失函数。这些损失函数中的每一个都采用了`tf.loss_function(y_true, y_pred)`的形式。也就是说，我们将因变量`y_true`作为第一个参数，将模型的预测`y_pred`作为第二个参数。然后它返回损失函数的值。

当我们在后面的章节中使用 TensorFlow 中的高级 API 时，我们将直接使用损失函数。然而，为了本章的目的，即围绕使用低级张量流操作的优化，我们需要将这些损失函数包含在模型的可训练参数和数据的函数中。优化器将需要利用外部函数来执行最小化。

### 离散因变量

子模块`tf.losses`为回归设置中的离散因变量提供了两个损失函数:`tf.binary_crossentropy()`、`tf.categorical_crossentropy()`和`tf.sparse_categorical_crossentropy()`。我们之前已经介绍过用于逻辑回归的二元交叉熵函数。当我们有一个二元因变量时，这为我们提供了一个损失的衡量标准，如经济是否衰退的指标，以及一个连续的预测，如处于衰退的概率。为了方便起见，我们在方程 3-17 中重复二元交叉熵的公式。

*方程式 3-17。* *二元交叉熵损失函数* *。*

![$$ L\left(Y,p(X)\right)={\Sigma}_i-\Big({Y}_i\ast \log \left(p\left({X}_i\right)\right)+\left(1-{Y}_i\right)\ast \log \left(1-p\left({X}_i\right)\right) $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equt.png)

分类交叉熵损失是二元交叉熵损失的简单扩展，适用于因变量有两个以上分类的情况。这种模型通常用于离散选择问题，如决定乘地铁、自行车、汽车或步行上下班的模型。在机器学习中，分类交叉熵是具有两个以上类别的分类问题的标准损失函数，并且通常用于执行图像和文本分类的神经网络中。分类交叉熵的等式在等式 3-18 中给出。注意(Y <sub>i</sub> ==k)是二进制变量，如果 Y <sub>i</sub> 是 k 类，则等于 1，否则等于 0。另外，*p*<sub>*k*</sub>(*X*<sub>*I*</sub>)是模型赋给 *X* <sub>*i*</sub> 为 k 类的概率

*方程式 3-18。分类交叉熵损失函数。*

![$$ L\left(Y,p(X)\right)=-{\Sigma}_i{\Sigma}_k\left({\mathrm{Y}}_{\mathrm{i}}==\mathrm{k}\right)\ast \log \left({p}_k\left({X}_i\right)\right) $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equu.png)

最后，如果我们有一个因变量可能属于多个类别的问题，即“多标签”问题，我们将使用稀疏分类交叉熵损失函数，而不是分类交叉熵。请注意，正常的交叉熵损失函数假设因变量只能有一个类。

### 连续因变量

对于连续因变量，最常见的损失函数是平均绝对误差(MAE)和均方误差(MSE)。在 OLS，MAE 用于 LAD 和 MSE。等式 3-19 定义了平均平均误差损失函数，等式 3-20 定义了平均误差损失。回想一下![$$ \hat{Y_i} $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_IEq8.png)是模型对观察值 *i* 的预测值。

*方程式 3-19。* *表示绝对误差损失* *。*

![$$ L\left(Y,\hat{Y}\right)=\frac{1}{n}{\sum}_i\mid {Y}_i-\hat{Y_i}\mid $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equv.png)

*方程式 3-20。* *均方差损失* *。*

![$$ L\left(Y,\hat{Y}\right)=\frac{1}{n}{\sum}_i{\left({Y}_i-\hat{Y_i}\right)}^2 $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equw.png)

注意，我们可以使用`tf.losses.mae()`和`tf.losses.mse()`来计算损耗。

线性回归的其他常见损失函数包括平均绝对百分比误差(MAPE)、均方对数误差(MSLE)和休伯误差，它们在方程 3-21、3-22 和 3-23 中定义。分别有`tf.losses.MAPE()`、`tf.losses.MSLE()`和`tf.losses.Huber()`三种。

*方程式 3-21。平均绝对百分比误差。*

![$$ L\left(Y,\hat{Y}\right)=100\ast \frac{1}{n}{\Sigma}_i\mid \left({Y}_i-\hat{Y_i}\right)/\hat{Y_i}\mid $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equx.png)

*方程式 3-22。均方对数误差。*

![$$ L\left(Y,\hat{Y}\right)=\frac{1}{n}{\Sigma}_i{\left(\log \left({Y}_i+1\right)-\log \left(\hat{Y_i}+1\right)\right)}^2 $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equy.png)

*方程式 3-23。*胡贝尔*错误。*

![$$ L\left(Y,\hat{Y}\right)=\left\{\begin{array}{c}\frac{1}{2}{\left({Y}_i-\hat{Y_i}\right)}^2\kern2.75em for\ \left|{Y}_i-\hat{Y_i}\right|\le \delta \\ {}\delta {\left(|{Y}_i-\hat{Y_i}|-\frac{1}{2}\delta \right)}^2\kern2.25em otherwise\end{array}\right. $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equz.png)

图 [3-8](#Fig8) 提供了所选损失函数的比较。对于每个损失函数，损失值相对于误差值绘制。请注意，MAE 损耗与误差成线性比例关系。相反，MSE 损失在接近 0 时增长缓慢，但在远离 0 时增长更快，导致对异常值应用大量惩罚。最后，Huber 损失类似于接近零的 MSE 损失，但随着误差大小的增加，类似于 MAE 损失。

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig8_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig8_HTML.png)

图 3-8

常见损失函数的比较

## 优化者

本章中我们要考虑的最后一个主题是 TensorFlow 中优化器的使用。当我们在线性回归的上下文中应用优化器时，我们已经看到了它们是如何工作的。在每种情况下，我们都使用随机梯度下降(SGD)优化器，它简单且可解释，但在最近的机器学习工作中不太常用。在这一节中，我们将扩展我们讨论的优化器集。

### 随机梯度下降

随机梯度下降(SGD)是一种通过使用梯度来更新参数值的最小化算法。在这种情况下，梯度是损失函数相对于每个参数的偏导数的张量。

方程 3-24 给出了参数更新过程。为了确保与等效张量流操作兼容，我们使用文档中提供的定义。注意 *θ* <sub>*t*</sub> 是迭代 *t* ， *lr* 是学习率， *g* <sub>*t*</sub> 是迭代 *i* 计算的梯度。

*方程式 3-24。张量流中的随机梯度下降。*

![$$ {\theta}_t={\theta}_{t-1}- lr\ast {g}_t $$](../images/496662_1_En_3_Chapter/496662_1_En_3_Chapter_TeX_Equaa.png)

你可能想知道 SGD 在什么意义上是“随机的”随机性来自用于更新参数的采样过程。这不同于梯度下降，在梯度下降中，在每次迭代中使用整个样本。梯度下降的随机版本的好处是，它提高了迭代速度，减轻了内存限制。

我们来看一个带有截距项和单变量的线性回归的单个 SGD 步骤，其中*θ*<sub>T3】tT5】=【*α*<sub>*t*</sub>， *β* <sub>*t*</sub> 】。我们将从迭代 0 开始，并假设我们已经为该批数据计算出梯度*g*<sub>0</sub>【0.25，0.33】。此外，我们将学习率 *lr* 设置为 0.01。这对*θ*T26】1</sub>意味着什么？利用等式 3-24，我们可以看到*θ*<sub>1</sub>=[*α*<sub>0</sub>+0.025，*β*<sub>0</sub>—0.033]。也就是说，我们将 *α* <sub>0</sub> 减少 0.025，将 *β* <sub>0</sub> 增加 0.033。

为什么偏导数为负时我们增加一个参数值，偏导数为正时我们减少它？因为偏导数告诉我们，损失函数是如何随着给定参数的变化而变化的。如果损失函数在增加，我们离最小值越来越远，所以我们想改变方向；然而，如果损失函数是减少的，我们正在向最小值移动，所以我们想继续在相同的方向上。此外，如果损失函数既不增加也不减少，这意味着我们处于最小值，算法将自然终止。

图 [3-9](#Fig9) 显示了损失函数相对于截距项的偏导数。我们关注截距真实值附近的一个狭窄窗口，并绘制损失函数及其导数。我们可以看到，导数最初是负的，但在截距的真值处增加到 0。然后它变成正值，并在此后增加。

![../images/496662_1_En_3_Chapter/496662_1_En_3_Fig9_HTML.png](../images/496662_1_En_3_Chapter/496662_1_En_3_Fig9_HTML.png)

图 3-9

损失函数及其对截距的导数

回到方程 3-24，注意学习率的选择也是相当重要的。如果我们选择一个高的学习率，我们将在每次迭代中迈出更大的步伐，这将使我们更快地接近最小值。然而，迈出更大的步伐也可能导致我们跳过最小的，完全错过它。学习率的选择应该考虑这种折衷。

最后，值得一提的是，我们确定的“最小值”是局部的，因此可能高于全局最小值。也就是说，SGD 不区分区域中的最低点和损失函数的最小值。因此，对于几组不同的初始参数值重新运行该算法，以查看我们是否总是收敛到相同的最小值，这可能是值得的。

### 现代优化者

虽然 SGD 很容易理解，但它很少以原始形式用于机器学习应用程序。这是因为现代扩展通常提供更多的灵活性和健壮性，并且在基准测试任务中表现更好。SGD 最常见的扩展是均方根传播(RMSProp)、自适应矩估计(Adam)和自适应梯度方法(Adagrad 和 Adadelta)。

使用 SGD 的现代扩展有几个优点。首先，从最老的 RMSProp 开始，它们允许对每个参数应用单独的学习率。在许多优化问题中，梯度中的偏导数之间会有数量级的差异。因此，例如，应用 0.001 的学习率对于一个参数可能是合理的，但对于另一个参数可能是不合理的。RMSProp 允许我们克服这个问题。它还允许使用“动量”，即梯度在小批量上累积，使算法有可能突破局部最小值。

Adagrad、Adadelta 和 Adam 都提供了使用动量的变体，并对每个单独的参数进行自适应更新。Adam 倾向于使用其默认参数很好地处理许多优化问题。Adagrad 的核心是梯度的累积和学习速率对单个参数的适应。并且 Adadelta 通过引入保留累积梯度的窗口来修改 Adagrad。 <sup>[8](#Fn8)</sup>

在所有情况下，优化器的使用将遵循一个熟悉的两步过程。我们将首先实例化一个优化器，并使用`tf.optimizer`子模块在流程中设置它的参数值。其次，我们将迭代应用最小化函数，并将损失函数作为 lambda 函数传递给它。

因为我们已经多次执行了第二步，所以我们将只关注清单 [3-14](#PC14) 中的第一步。在这里，我们已经实例化了 SGD、RMSProp、Adagrad 和 Adadelta 优化器，并强调了如何设置它们各自的参数值。

```py
# Instantiate optimizers.
sgd = tf.optimizers.SGD(learning_rate = 0.001,
        momentum = 0.5)
rms = tf.optimizers.RMSprop(learning_rate = 0.001,
        rho = 0.8, momentum = 0.9)
agrad = tf.optimizers.Adagrad(learning_rate = 0.001,
        initial_accumulator_value = 0.1)
adelt = tf.optimizers.Adadelta(learning_rate = 0.001,
        rho = 0.95)
adam = tf.optimizers.Adam(learning_rate = 0.001,
        beta_1 = 0.9, beta_2 = 0.999)

Listing 3-14Instantiate optimizers

```

对于`SGD`，我们设置学习率和`momentum`。如果我们担心有很多局部最小值，我们可以增加`momentum`到一个更高的值。对于`RMSProp`，我们不仅设置了一个`momentum`参数，还设置了`rho`，这是关于梯度的信息衰减的速率。在一段时间内保持梯度的`Adadelta`参数也具有相同的衰减参数`rho`。对于`Adagrad`，我们设置一个初始累加器值，该值与梯度随时间累积的强度相关。最后，对于 Adam 优化器，我们为关于梯度的平均值和方差的信息的累积设置衰减率。在这种情况下，我们使用 Adam 优化器的默认值，它通常在大型优化问题中表现良好。

我们现在已经介绍了我们将在整本书中使用的主要优化器。当我们将它们应用于训练模型时，我们将再次详细讨论它们。当我们训练具有数千个参数的大型模型时，SGD 的现代变体将特别有用。

## 摘要

经济学中最常用的实证方法是回归。在机器学习中，术语回归指的是具有连续目标的监督学习模型。在经济学中，术语“回归”的定义更广泛，可能指二元或分类因变量的情况，如逻辑回归。出于本书的目的，我们采用经济学术语。

在这一章中，我们介绍了回归的概念，包括线性、部分线性和非线性变量。我们看到了如何在 TensorFlow 中定义和训练这样的模型，这将最终形成在 TensorFlow 中求解任何任意模型的基础，我们将在后面的章节中看到。

最后，我们讨论了培训过程的细节。我们看到了如何构建损失函数，以及 TensorFlow 中有哪些预定义的损失函数。我们还看到了如何使用各种不同的优化例程来执行最小化。

## 文献学

Chernozhukov，v .，D. Chetverikov，M. Demirer，E. Duflo，C. Hansen，W. Newey 和 J. Robins。2017."用于治疗和结构参数的双/去偏置机器学习."*计量经济学杂志* 21 卷 1 期。

古德费勒，我，y .本吉奥，和 a .库维尔。2017.*深度学习。麻省剑桥:麻省理工学院出版社。*

罗宾逊，下午 1988。"根 N 一致的半参数回归."*计量经济学*56(4):931–954。

泰勒议员地方检察官皮尔和萨尔诺。2001."实际汇率的非线性均值回归:购买力平价难题的解决方案."*国际经济评论*42(4):1015–1042。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

因为平均值是总和除以观察值的数量(即，由常数缩放)，所以最小化平均值将等同于最小化总和。在实践中，我们通常会最小化平均值，因为计算大的和会导致溢出，当一个数超过其数据类型允许的范围时就会发生溢出。

  [2](#Fn2_source)

局部最小值是函数在给定区域的最低值，而全局最小值是函数的最低整体值。在实践中，损失函数通常具有许多局部最小值，使得确定全局最小值具有挑战性。

  [3](#Fn3_source)

高斯-马尔可夫定理做了五个假设:(1)真实模型在参数上是线性的；(2)数据是随机抽样的；(3)自变量之间没有一个是完全相关的(没有完全共线性)；(4)误差项是外生的(与自变量不相关)；和(5)误差项的方差是常数和有限的。

  [4](#Fn4_source)

如果两个回归量 X 和 Z 在统计上不独立，则称它们是“共线的”。

  [5](#Fn5_source)

当观测值趋于无穷大时，一致估计量以概率收敛于真实参数值。

  [6](#Fn6_source)

raw 系列可在 [`https://fred.stlouisfed.org/series/DEXUSUK`](https://fred.stlouisfed.org/series/DEXUSUK) 下载。

  [7](#Fn7_source)

参见 Taylor 等人(2001 年)对 STAR 和 e STAR 模型的概述。

  [8](#Fn8_source)

有关优化器理论属性的详细讨论，请参见 Goodfellow 等人(2017)。

 </aside>