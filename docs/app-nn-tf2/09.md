# 9.自然语言处理

自然语言处理(NLP)是一个跨学科的子领域，包括语言学、计算机科学和人工智能等主要领域。NLP 主要关注人和计算机之间的交互。NLP 的范围从计算理解和生成人类语言到处理和分析大量自然语言数据。自然语言处理的范围还包括文本、语音、认知以及它们之间的相互作用。在这一章中，我们简要介绍了自然语言处理的历史，基于规则的自然语言处理和基于统计的自然语言处理之间的区别，以及主要的自然语言处理方法和技术。最后，我们对 NLP 进行了一个案例研究，让你为现实世界中的问题做好准备。

## 自然语言处理的历史

NLP 的历史可以分为四个主要时代:

*   早期思想时代

*   基于规则的自然语言处理时代

*   监督学习时代的统计自然语言处理

*   无监督和半监督学习时代

请注意，这些时代是互补的，而不是破坏性的。因此，我们仍然利用早期引入的规则和方法。

### 早期的想法

自然语言处理的历史始于 17 世纪，由莱布尼茨和笛卡尔提出哲学建议，引入特殊代码将不同语言之间的单词连接起来。尽管这些建议总是停留在理论层面，但它们影响了未来几个世纪的科学家们实现自动机器翻译的想法。

### 基于规则的自然语言处理

这个时代的共同特点是大量使用复杂的手写规则来覆盖 NLP 任务的潜在结果。与自然语言处理相关的早期创新最早出现在 20 世纪 30 年代的“翻译机”专利中。这些早期专利包含自动双语词典和处理语言间语法规则的方法。

在第二次世界大战期间，机器翻译设备被开发出来翻译敌人之间的通信。然而，这些机器大多不成功。

正如在人工智能的所有其他领域一样，1950 年，图灵测试为智能设定了标准，其中包括理解自然语言的对话。

1957 年，诺姆·乔姆斯基公布了句法结构，这是一个基于规则的系统，用一个普遍的语法规则彻底改变了语言学研究。

1954 年，在乔治敦大学的实验中，60 个俄语句子被自动翻译成英语。这个成功的实验鼓励作者宣称这两种语言之间的机器翻译将在 3 到 5 年内完成。这种积极的方法与其他人工智能子领域一致，在这些子领域中，大多数乐观的承诺都未能实现。因此，在 20 世纪 60 年代末和 70 年代初，在人工智能冬天的时代，NLP 研究的资金被削减。

尽管资金有限，一些成功的 NLP 系统还是在 20 世纪 60 年代开发出来，在有限的环境中工作。20 世纪 70 年代是许多程序员开始编写“概念本体”的年代，概念本体将现实世界的对象结构化、分组并分类成二进制数据。

### 统计自然语言处理和监督学习

大约在 20 世纪 80 年代，计算能力的稳步增长和优先使用机器学习方法进行语言处理的语料库语言学的普及使得在 NLP 中使用统计模型成为可能。尽管统计 NLP 的早期研究与基于规则的 NLP 研究没有太大的不同，但是随着更复杂方法的引入，统计 NLP 变得更具概率性。这种从基于规则的模型到统计模型的转变提高了精度性能，尤其是对于不寻常的观察。

在这个时代，IBM Research 走在了前面，开发了 IBM Watson 等几个成功的 NLP 解决方案。此外，欧盟、联合国和加拿大议会制作的多语言官方文档也为成功的机器翻译系统的开发做出了贡献。

另一方面，对这些大型文本语料库的访问有限的较小参与者专注于开发可以从有限数量的数据中有效学习的方法。

### 无监督和半监督自然语言处理

如今，NLP 问题在现实世界中的应用越来越成功。然而，找到足够的标记数据是现代自然语言处理研究中的主要问题之一。因此，使用无监督和半监督学习算法来完成常见的 NLP 任务变得越来越流行。一般来说，使用无监督学习算法做出的预测不如有监督算法准确。然而，通过无监督模型，研究人员可以从大量数据中推断出结果，这对发现更复杂的模式非常有用。

## 自然语言处理的实际应用

随着机器学习领域的进步，NLP 现实世界应用的数量正在增加。随着计算能力的提高，大量可用的机器学习模型，以及大量文本语料库的可用性，每天都有新的 NLP 用例被发现。以下是最受欢迎的 NLP 应用程序列表:

*   机器翻译:将文本从一种语言翻译成另一种语言的任务(例如，谷歌翻译)

*   **语音识别**:识别人声以采取行动或转换成文本的任务

*   情感分析:理解文本片段中的情感的任务，例如评论

*   **问题回答**:开发能够准确给出给定问题答案的系统的任务(例如 Siri)

*   自动摘要(Automatic Summarization】:在不丢失要点的情况下，从全文中提取简短摘要的任务

*   聊天机器人(Chatbots):开发特殊系统的任务，这些系统能够完成几项自然语言处理任务，比如问答、语音识别等等

*   **市场情报**:利用多种 NLP 和其他统计方法分析客户行为的任务

*   文本分类:通过分析文本的内容、结构和其他相关特征，将文本分类到给定类别的任务

*   **光学字符识别(OCR)** :借助计算机视觉和图像处理方法，分析图像数据并将其转换为文本的任务

*   **拼写检查**:识别和纠正文本中拼写错误的任务(例如，语法上)

为了能够开发这些真实世界的应用程序，研究人员必须使用几种 NLP 方法，这些方法将在下一节中介绍。

## 主要评估、技术、方法和任务

自然语言数据的处理由几个小任务组成，这些小任务可以分成以下几组:

*   形态句法

*   语义学

*   话语

*   演讲

*   对话

*   认识

在下一节中，我们将在相应的组下讨论这些任务。

### 形态句法

形态句法是对基于形态和句法属性创造的语法范畴和语言单位的研究。在自然语言处理领域，有许多基本的形态句法任务，列举如下:

*   基本形式提取:有两种流行的方法来提取单词的基本形式。
    *   **词条化**:通过使用一个实际的词典(例如通过去掉 *-ing* 后缀将*游泳*转换为*游泳*)来去掉单词的无关紧要的词尾，并返回它们的基本词典形式(即词条)。

    *   **词干化**:一种将屈折词或派生词还原为其词根形式的方法。虽然词干化类似于词汇化，但是使用词干化生成的词根形式不必是真实的单词(例如，单词*troubl*、*troubl*和*troubl*被词干化为 *troubl* )。

*   **语法归纳**:生成描述其语法的全语言形式语法。

*   **词法切分**:将单词拆分成最小的有意义的单位(即*语素*，并识别这些单位的类别。

*   **词性标注**:确定每个单词的词性类型。常见的词类有名词、动词、形容词、副词、代词、介词、连词、感叹词、数词、冠词或限定词。

*   **解析**:确定给定字符串(如句子)的解析树。解析树是一个有序的、有根的树，它代表了字符串的语法结构。

*   **断句**:寻找句子边界。一些标点符号，如句号或感叹号，对这项任务很有用。

*   **分词**:将给定文本分割成单独的单词。这个过程通常用于创建一个单词包(BOW)和**文本矢量化**。

*   **术语提取**:从给定的语料库中提取相关术语。

### 语义学

语义学是语言学和逻辑学的交叉学科，研究意义。逻辑语义学关注的是意义、指称和蕴涵，而词汇语义学关注的是对词义及其关系的分析。与语义相关的主要问题、方法和任务如下:

*   机器翻译:如前所述，将文本从一种人类语言自动翻译成另一种语言。

*   **命名实体识别(NER)** :在给定的字符串中寻找人名和地名。尽管资本化对 NER 很有用，但肯定还有更多的工作要做。

*   **自然语言生成**:使用单词表示和统计模型生成自然语言文本。

*   **光学字符识别**:如前所述，从包含打印文本的图像中识别文本数据。

*   **问题回答**:如前所述，用自然语言给出一个问题，提供答案。

*   **识别文本蕴涵**:识别文本片段之间的方向关系，比死板的逻辑蕴涵更宽松。

    两个字符串之间的正文本蕴涵的示例如下:

    **正文**:努力就会成功。

    假设:努力工作会有好的结果。

*   **关系提取**:从给定文本中识别现实世界的关系(例如，人 A 为 X 公司工作)。

*   **情感分析**:如前所述，从一组文档中提取主观信息(即情感)。

*   **主题分割和识别**:将一组文档或文本分类成单独的主题。虽然在某些情况下主题界限可能很明显，但通常需要更多的评估。

*   **词义消歧**:根据上下文确定一个有一个以上含义的单词的含义。

### 话语

*   自动摘要:如前所述，产生一个大文本的可读摘要。

*   **共指消解**:确定哪些词指代相同的对象，既包括名词也包括代词。当一个文本中有多个表达式引用同一个对象时，就会出现共指。

*   话语分析:研究书面语或口语与其社会背景的关系，旨在了解语言在现实生活中的使用情况。

### 演讲

*   **语音识别**:如前所述，将一个人说话的给定声音片段转换成文本

*   **语音分割**:语音识别的一个子任务，将识别的文本分割成单词

*   **文本到语音**:将给定的文本转换成它的音频表示

### 对话

开始并继续与人或机器进行有意义的书面或口头交流。对话需要同时完成几项任务，如回答问题、文本到语音转换、语音识别、情感分析等。

### 认识

通过思想、经验和感觉获得知识和理解。它被认为是最复杂的自然语言处理评估，通常被称为自然语言理解(NLU)。

## 自然语言工具包(NLTK)

NLTK 是一个为 NLP 任务设计的重要 Python 库。NLTK 支持基本的 NLP 任务，例如文本分类、词干提取和词汇化、标记、解析、标记化，甚至推理。

在由宾夕法尼亚大学的 Steven Bird 和 Edward Loper 开发之后，NLTK 被认为是 Python 的主要 NLP 库。

尽管您可以利用数据科学库，如 Pandas、scikit-learn、TensorFlow 和 NumPy，但这些库中可用的方法甚至无法与 NLTK 提供的方法相比。

这里列出了可用的 NLTK 模块。

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

`app`

 | 

`parse`

 |
| --- | --- |
| `ccg` | `probability` |
| `chat` | `sem` |
| `chunk` | `sentiment` |
| `classify` | `stem` |
| `cluster` | `tag` |
| `collections` | `tbl` |
| `corpus` | `test` |
| `data` | `text` |
| `downloader` | `tokenize` |
| `draw` | `toolbox` |
| `featstruct` | `translate` |
| `grammar` | `tree` |
| `help` | `treetransform` |
| `inference` | `twitter` |
| `lm` | `util` |
| `metrics` | `wsd` |
| `misc` |   |

**关于 NLTK 的有用信息**

*   **网站** : [`www.nltk.org/`](http://www.nltk.org/)

*   **模块的文档 URL**:[`www.nltk.org/py-modindex`](http://www.nltk.org/py-modindex)

*   **安装命令** : `pip install --user -U nltk`

*   **导入**的首选别名:`import nltk`

## 案例研究|深度自然语言处理的文本生成

请注意，NLP 的主题本身就是一个专业领域。有人可以花一生的时间来研究 NLP。在这一章中，我们只做一个介绍，现在我们已经讨论了自然语言处理中的主要主题，我们可以继续我们的案例研究:使用深度自然语言处理的文本生成。

NLP 项目中最重要的主题之一是文本矢量化。在本案例研究中，我们将参考 Andrej Karpathy 的博文《递归神经网络的不合理有效性》 <sup>[1](#Fn1)</sup> ，以及 TensorFlow 团队对这篇博文的承担 <sup>[2](#Fn2)</sup> 。

研究表明，用于 NLP 的最有效的人工神经网络类型之一是递归神经网络(RNNs)。rnn 广泛用于 NLP 任务，如机器翻译、文本生成和图像字幕。在 NLP 任务中，通常，开发者使用 NLP 工具和方法来将文本数据处理成向量，然后将它们馈送到选定的人工神经网络，例如 RNN、CNN，或者甚至前馈神经网络，以完成任务。在我们的案例研究中，我们也遵循这两个标准化的步骤:(I)将文本处理成向量，(ii)用这些向量训练神经网络。

### 案例研究的目标

充分理解案例研究的目标至关重要。在这个案例研究中，我们的目标是训练一个 RNN，它能够使用字符生成有意义的文本。RNN 可以从单词和字符中生成文本，我们选择使用字符来生成这个案例研究的文本。问题是，当我们未经训练就建立一个新的 RNN 时，它组合了一堆毫无意义的字符，这没有任何意义。然而，如果我们给我们的 RNN 输入大量文本数据，它就会开始模仿这些文本的风格，并使用字符生成有意义的文本。所以，如果我们给模型输入大量说教性的文本，我们的模型就会生成教育材料。如果我们给我们的模型输入大量的诗歌，我们的模型将开始生成诗歌，所以我们将最终拥有一个人工诗人。这些都是可行的选择，但是我们将为我们的模型提供一些其他的东西:一个包含莎士比亚作品的长文本数据集。因此，我们将创造一个人造的莎士比亚。

### 莎士比亚文集

莎士比亚语料库是一个包含 40，000 行莎士比亚作品的文本文件，由 Karpathy 清理和准备，由 TensorFlow 团队托管于此 URL:

[T2`https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt`](https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt)

我强烈建议您看看。txt 文件来理解我们正在处理的文本。文件包含对话内容，每个角色的名字放在相应部分的前面，如图 [9-1](#Fig1) 所示。

![../images/501289_1_En_9_Chapter/501289_1_En_9_Fig1_HTML.jpg](../images/501289_1_En_9_Chapter/501289_1_En_9_Fig1_HTML.jpg)

图 9-1

莎士比亚文集的一部分

### 初始进口

在本案例研究中，所需的库是 TensorFlow、NumPy 和 os，我们可以使用以下代码导入它们:

```
import tensorflow as tf
import numpy as np
import os

```

你注意到我没有提到 NLTK 库吗？原因是 TensorFlow 对 NLP 任务的支持也有限，在本案例研究中，结合 NumPy 操作，我们能够使用 TensorFlow 对数据集进行矢量化。这主要是因为我们的语料库非常标准化和干净。如果我们需要一个更复杂的 NLP 方法，我们将不得不在更大程度上依赖 NLTK、Pandas 和 NumPy 库。

### 加载语料库

为了能够从在线目录加载数据集，我们可以使用 TensorFlow 中 Keras API 的`util`模块。对于这个任务，我们将使用`get_file()`函数，如果文件不在缓存中，它将从 URL 下载文件，代码如下:

```
path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')

```

下载文件后，我们可以使用以下 Python 代码从缓存中打开文件:

```
text = open(path_to_file, 'rb').read()
text = text.decode(encoding='utf-8')

```

现在，我们成功地将整个语料库作为变量保存在了 Colab 笔记本的内存中。让我们看看语料库中有多少个字符，前 100 个字符是什么，代码如下:

```
print ('Total number of characters in the corpus is:', len(text))
print('The first 100 characters of the corpus are as follows:\n', text[:100])
Output:
Total number of characters in the corpus is: 1115394
The first 100 characters of the corpus are as follows:
 First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You

```

我们的整个语料库可以通过一个名为 *text* 的 Python 变量来访问，现在我们可以开始对它进行矢量化了。

### 向量化文本

文本矢量化是一种基本的 NLP 方法，用于将文本数据转换为机器可以理解的有意义的数字向量。文本矢量化有多种方法。在本案例研究中，我们是这样一步步进行的:

*   给每个独特的字符一个索引号。

*   在语料库中运行一个 for 循环，并索引整个文本中的每个字符。

为了给每个独特的字符分配一个索引号，我们首先必须创建一个只包含文本中所有独特字符的单个副本的列表。使用内置的`set()`函数很容易做到这一点，该函数将一个列表对象转换成一个只有唯一值的集合对象。

集合和列表数据结构的区别在于，列表是有序的，允许重复，而集合是无序的，不允许重复元素。因此，当我们运行`set()`函数时，如下面的代码所示，它在文本文件中返回一组独特的字符:

```
vocab = sorted(set(text))
print ('The number of unique characters in the corpus is', len(vocab))
print('A slice of the unique characters set:\n', vocab[:10])
Output:
The number of unique characters in the corpus is 65
A slice of the unique characters set:
 ['\n', ' ', '!', '$', '&', "'", ',', '-', '.', '3']

```

我们还需要给每个字符一个索引号。以下代码为每个集合项目分配一个编号，然后使用以下代码创建一个集合项目字典，其中包含这些集合项目的给定编号:

```
char2idx = {u:i for i, u in enumerate(vocab)}

```

我们还复制了 NumPy 数组格式的唯一集合元素，供以后解码预测时使用:

```
idx2char = np.array(vocab)

```

现在，我们可以使用一个简单的 for 循环对文本进行矢量化处理，遍历文本中的每个字符，为它们分配相应的索引值，并将所有索引值保存为一个新列表，代码如下:

```
text_as_int = np.array([char2idx[c] for c in text])

```

### 创建数据集

此时，我们用`char2idx`字典对文本进行矢量化，用`idx2char`对矢量化后的文本进行去矢量化(即解码)。最后，我们将`text_as_int`作为矢量化的 NumPy 数组。我们现在可以创建数据集了。

首先，我们将使用来自`Dataset`模块的`from_tensor_slices`方法从我们的`text_as_int`对象创建一个 TensorFlow Dataset 对象，我们将把它们分成几批。数据集的每个输入的长度限制为 100 个字符。我们可以用下面的代码实现所有这些:

```
char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)
seq_length = 100 # The max. length for single input
sequences = char_dataset.batch(seq_length+1, drop_remainder=True)

```

我们的`sequences`对象包含字符序列，但是我们必须创建一个这些序列的元组，以便输入到 RNN 模型中。我们可以通过如下自定义映射函数来实现这一点:

```
def split_input_target(chunk):
  input_text = chunk[:-1]
  target_text = chunk[1:]
  return input_text, target_text

dataset = sequences.map(split_input_target)

```

我们生成这些元组的原因是为了让 RNN 工作，我们需要创建一个管道，如图 [9-2](#Fig2) 所示。

![../images/501289_1_En_9_Chapter/501289_1_En_9_Fig2_HTML.jpg](../images/501289_1_En_9_Chapter/501289_1_En_9_Fig2_HTML.jpg)

图 9-2

具有四维输入和输出层的 RNN 的例子。注意输入和输出字符之间的延迟

最后，我们重组数据集，分成 64 个句子批次，每行如下:

```
BUFFER_SIZE = 10000 # TF shuffles the data only within buffers
BATCH_SIZE = 64 # Batch size

dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)
print(dataset)

Output:

<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)

```

### 构建模型

我们的数据已经准备好输入模型管道。让我们创建我们的模型。我们希望训练我们的模型，然后做出新的预测。重要的是，我们的训练管道将在每一批输入 64 个句子。因此，我们需要以一次接受 64 个输入句子的方式构建我们的模型。然而，在我们训练了我们的模型之后，我们想要输入单句来生成新的任务。所以，我们需要不同的训练前和训练后模型的批量大小。为了实现这一点，我们需要创建一个函数，它允许我们为不同的批量大小重现模型。下面的代码可以做到这一点:

```
def build_model(vocab_size, embedding_dim, rnn_units, batch_size):

  model = tf.keras.Sequential([

    tf.keras.layers.Embedding(
            vocab_size,
            embedding_dim,
            batch_input_shape=[batch_size, None]),

    tf.keras.layers.GRU(
            rnn_units,
            return_sequences=True,
            stateful=True,
            recurrent_initializer='glorot_uniform'),

    tf.keras.layers.Dense(vocab_size)

  ])
  return model

```

我们的模型有三层:

*   **嵌入层**:该层作为输入层，接受输入值(数字格式)并将其转换为矢量。

*   **GRU 图层**:填充了 1024 个梯度下降单元的 RNN 图层

*   **密集层**:输出结果，`vocab_size`输出。

现在，我们可以使用以下代码创建我们的培训模型:

```
model = build_model(
    vocab_size = len(vocab), # no. of unique characters
    embedding_dim=embedding_dim, # 256
    rnn_units=rnn_units, # 1024
    batch_size=BATCH_SIZE)  # 64 for the training

```

图 [9-3](#Fig3) 总结了我们的模型。

![../images/501289_1_En_9_Chapter/501289_1_En_9_Fig3_HTML.jpg](../images/501289_1_En_9_Chapter/501289_1_En_9_Fig3_HTML.jpg)

图 9-3

培训模型的摘要视图。请注意输出形状中的 64，对于训练后的单个预测，它必须为 1

### 编译和训练模型

为了编译我们的模型，我们需要配置我们的优化器和损失函数。对于这个任务，我们选择“Adam”作为优化器，选择稀疏分类交叉熵函数作为损失函数。

由于我们的输出总是 65 个字符中的一个，这是一个多类分类问题。因此，我们必须选择一个分类交叉熵函数。然而，在这个例子中，我们选择了分类交叉熵的一个变体:稀疏分类交叉熵。我们使用稀疏分类交叉熵的原因是，即使它们使用相同的损失函数，它们的输出格式也是不同的。请记住，我们将文本矢量化为整数(例如，[0]，[2]，[1])，而不是一键编码格式(例如，[0，0，0]，[0，1]，[1，0，0])。为了能够输出整数，我们必须使用稀疏分类交叉熵函数。

为了能够设置我们自定义的损失函数，让我们创建一个包含稀疏分类交叉熵损失的基本 Python 函数:

```
def loss(labels, logits):
  return tf.keras.losses.sparse_categorical_crossentropy( labels, logits, from_logits=True)

```

现在，我们可以使用以下代码设置损失函数和优化器:

```
model.compile(optimizer='adam', loss=loss)

```

为了能够加载我们的重量并保存我们的训练成绩，我们需要使用以下代码设置和配置一个检查点目录:

```
# Directory where the checkpoints will be saved
checkpoint_dir = './training_checkpoints'

# Name of the checkpoint files
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt_{epoch}")

checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_prefix,
    save_weights_only=True)

```

我们的模型和检查点目录已经配置好了。我们将为我们的模型训练 30 个时期，并将训练历史保存到名为 history 的变量中，代码如下:

```
EPOCHS = 30
history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])

```

在训练模型时，我们得到了如图 [9-4](#Fig4) 所示的以下输出:

![../images/501289_1_En_9_Chapter/501289_1_En_9_Fig4_HTML.jpg](../images/501289_1_En_9_Chapter/501289_1_En_9_Fig4_HTML.jpg)

图 9-4

模型训练的最后八个时期

由于模型的简单性以及我们对模型进行编码的方式，我们的训练并不需要太长时间(大约 3 `–` 4 分钟)。现在，我们可以使用保存的权重并构建一个自定义模型，该模型接受单个输入来生成文本。

### 用训练好的模型生成文本

为了能够查看我们最新检查点的位置，我们需要运行以下代码:

```
tf.train.latest_checkpoint(checkpoint_dir)
Output:
./training_checkpoints/ckpt_30

```

现在，我们可以使用之前创建的定制`build_model()`函数，使用`latest_checkpoint`中保存的权重，用`batch_size=1`、`load weights`构建一个新模型，并使用`build()`函数基于接收到的输入形状(即`[1, None]`)构建模型。我们可以用下面的代码实现所有这些和`summarize()`关于我们新模型的信息:

```
model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)
model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))
model.build(tf.TensorShape([1, None]))
model.summary()

```

输出如图 [9-5](#Fig1) 所示:

`Output:`

![../images/501289_1_En_9_Chapter/501289_1_En_9_Fig5_HTML.jpg](../images/501289_1_En_9_Chapter/501289_1_En_9_Fig5_HTML.jpg)

图 9-5

新创建的模型的概要视图。现在它接受单一输入

我们的模型已经准备好进行预测，我们所需要的只是一个定制函数来为模型准备输入。我们必须设置以下内容:

*   要生成的字符数

*   向量化输入(从字符串到数字)

*   存储结果的空变量

*   手动调整预测可变性的温度值

*   对输出进行去因子化，并且还将输出再次馈送到模型，用于下一次预测

*   将所有生成的字符连接成一个最终字符串

以下自定义函数完成所有这些工作:

```
def generate_text(model, num_generate, temperature, start_string):
  input_eval = [char2idx[s] for s in start_string] # string to numbers (vectorizing)
  input_eval = tf.expand_dims(input_eval, 0) # dimension expansion
  text_generated = [] # Empty string to store our results
  model.reset_states() # Clears the hidden states in the RNN

  for i in range(num_generate): #Run a loop for number of characters to generate
    predictions = model(input_eval) # prediction for single character
    predictions = tf.squeeze(predictions, 0) # remove the batch dimension

    # using a categorical distribution to predict the character returned by the model
    # higher temperature increases the probability of selecting a less likely character
    # lower --> more predictable

    predictions = predictions / temperature
    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()

    # The predicted character as the next input to the model
    # along with the previous hidden state
    # So the model makes the next prediction based on the previous character
    input_eval = tf.expand_dims([predicted_id], 0)
    # Also devectorize the number and add to the generated text
    text_generated.append(idx2char[predicted_id])

  return (start_string + ''.join(text_generated))

```

它返回我们的最终预测值，我们可以使用下面一行轻松地生成一个文本:

```
generated_text = generate_text(
                    model,
                    num_generate=500,
                    temperature=1,
                    start_string=u"ROMEO")

```

我们可以用内置的打印功能打印出来:

```
print(generated_text)

Output:
ROMEO:

Third Servingman:
This attemptue never long to smile
under garlands grass and enterhoand of death.

GREMIO:
Have I not fought for such a joy? can come to Spilet O, thy husband!
Go, sirs, confusion's cut off? princely Noboth, my any thing thee;
Whereto we will kiss thy lips.

ANTIGONUS:
It is your office: you have ta'en her relatants so many friends as they
or no man upon the market-play with thee!

GRUMIO:
First, know, my lord.

KING RICHARD II:
Then why.

CORIOLANUS:
How like a tinker? Was e

```

如您所见，我们的模型能够生成任意长度的文本。请注意:我们的模型使用字符，因此模型的奇迹在于它学会了从字符中创建有意义的单词。所以，不要认为它把一堆不相关的单词加在一起。它检查了数千个单词，学习了不同字符之间的关系，以及如何使用它们来创建有意义的单词。然后它复制这个，并返回给我们有意义的单词的句子。

请玩玩温度，看看如何将输出从更合适的单词变成更失真的单词。较高的温度值会增加我们的功能选择不太可能的字符的机会。当我们把它们都加起来时，我们得到的结果就没那么有意义了。另一方面，低温会导致函数生成更简单的文本，更像是原始语料库的副本。

## 结论

在这一章中，我们讨论了自然语言处理，它是人工智能的一个分支，处理文本数据。我们介绍了 NLP 研究中使用的主要方法和技术。我们也简单参观了 NLP 的时间线。我们最后进行了一个案例研究，使用递归神经网络生成类似莎士比亚的文本。

在下一章，我们将讨论推荐系统，它是我们今天所知的大型科技公司提供的许多服务的支柱。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

递归神经网络的不合理有效性，可用 [`http://karpathy.github.io/2015/05/21/rnn-effectiveness`](http://karpathy.github.io/2015/05/21/rnn-effectiveness)

  [2](#Fn2_source)

使用 RNN | TensorFlow 核心 TensorFlow 生成文本，可在 [`www.tensorflow.org/tutorials/text/text_generation`](https://www.tensorflow.org/tutorials/text/text_generation) 上使用

 </aside>