# 12.生成对抗网络

生成对抗网络(GANs)是 Ian Goodfellow 和他的同事在 2014 年设计的一种深度学习模型。

GANs 的发明出乎意料。著名的研究员，当时是蒙特利尔大学的博士研究员，伊恩·古德费勒，在一个朋友的告别派对上和他的朋友讨论其他生成算法的缺陷时偶然想到了这个想法。聚会结束后，他满怀希望地回到家中，实施了他心中的构想。令人惊讶的是，在第一次试验中，一切都如他所愿，他成功地创建了生成性对抗网络(简称 GANs)。

据脸书大学人工智能研究主任、纽约大学教授 Yann LeCun 称，GANs 是“过去 10 年机器学习中最有趣的想法”

## 方法

在 GAN 架构中，有两个神经网络(一个生成器和一个鉴别器)在博弈中相互竞争。在暴露于训练集之后，生成器学习生成具有相似特征的新样本。另一方面，鉴别器试图判断生成的数据是真实的还是伪造的。通过训练，生成器被迫生成接近真实的样本，使得鉴别器无法将它们与训练数据区分开。训练结束后，我们可以使用生成器生成非常真实的样本，如图像、声音和文本。

GANs 最初被设计用来处理无监督的学习任务。然而，最近的研究表明，GANs 在监督、半监督和强化学习任务中表现出良好的结果。

## 体系结构

如前所述，有两个网络形成了生成性对抗网络:生成者网络和鉴别者网络。这两个网络通过一个潜在的空间相互连接，所有的魔法都在这里发生。换句话说，我们使用发生器网络的输出作为鉴别器网络的输入。让我们深入研究一下生成网络和判别网络，以真正理解 gan 是如何工作的；见图 [12-1](#Fig1) :

![../images/501289_1_En_12_Chapter/501289_1_En_12_Fig1_HTML.jpg](../images/501289_1_En_12_Chapter/501289_1_En_12_Fig1_HTML.jpg)

图 12-1

生成性对抗网络的可视化

### GAN 组件

#### 生成网络

生成器网络采用固定长度的随机向量(从随机噪声开始)并生成新样本。它使用高斯分布来生成新的样本，通常从一维层开始，最终被整形为训练数据样本的形状。例如，如果我们使用 MNIST 数据集来生成图像，则生成器网络的输出图层必须对应于图像尺寸(例如，28 x 28 x 1)。这最后一层也被称为潜在空间或向量空间。

#### 鉴别器网络

鉴别器网络以相对相反的顺序工作。生成网络的输出被用作鉴别器网络中的输入数据(例如，28×28×1)。鉴别器网络的主要任务是决定产生的样本是否真实。因此，鉴别器网络的输出由单个神经元密集层提供，该神经元密集层输出所生成样本的真实性的概率(例如，0.6475)。

#### 潜在空间

潜在空间(即向量空间)作为发生器网络的输出和鉴别器网络的输入。生成对抗模型中的潜在空间通常具有原始训练数据集样本的形状。潜在空间试图捕捉训练数据集的特征，以便生成器可以成功地生成接近真实的样本。

### 一个已知问题:模式崩溃

在生成对抗网络的训练过程中，我们经常会遇到“模式崩溃”的问题。模式崩溃基本上是指未能正确归纳，或者换句话说，未能了解成功生成样本的有意义特征。模式崩溃的形式可能是完全学习失败或学习部分特征失败。例如，当我们处理 MNIST 数据集(从 0 到 9 的手写数字)时，由于模式崩溃问题，我们的 GAN 可能永远不会学习生成一些数字。模式崩溃有两种可能的解释:

*   弱鉴别网络

*   目标函数选择错误

因此，研究一下我们网络的规模和深度，以及目标函数，可能会解决这个问题。

### 关于建筑的最后笔记

保持发生器和鉴别器网络之间的良性竞争对于构建有用的 GAN 模型是至关重要的。只要这两个网络互相对抗来完善它们的性能，你就可以根据问题自由设计这些网络的内部结构。例如，在处理序列数据时，只要其中一个网络作为生成器网络，而另一个网络作为鉴别器网络，就可以用 LSTM 和 GRU 图层构建两个网络。另一个例子是我们的案例研究。当用 GANS 生成图像时，我们给我们的网络增加了许多卷积或转置卷积层，因为它们降低了图像数据的计算复杂度。

## 氮化镓的应用

目前有许多领域正在使用 GANs，可列举如下:

*   时尚、艺术和广告

*   制造业和 R&D

*   视频游戏

*   恶意应用程序和深度伪造

*   其他应用

### 艺术和时尚

生成对抗网络能够“生成”样本。所以，他们天生就有创造力。这就是为什么艺术和时尚是生成性对抗网络最有前途的领域之一。有了训练有素的 GANs，你可以创作绘画、歌曲、服装，甚至诗歌。事实上，Nvidia 的 StyleGAN 网络生成的一幅画“Edmond de Belamy，from La Famille de Belamy”在纽约以 43.25 万美元的价格售出。因此，你可以清楚地看到甘如何有潜力被用于艺术世界。

### 制造、研究和 R&D

GANs 可用于预测科学研究项目和工业应用中的计算瓶颈。

GAN 网络也可用于提高基于统计分布的图像的清晰度。换句话说，GANs 可以使用统计分布来预测缺失的部分，并产生合适的像素值，这将提高望远镜或显微镜拍摄的图像质量。

### 视频游戏

GANs 可用于使用小清晰度图像获得更精确和更清晰的图像。这种能力可能被用来使老游戏对新的一代更有吸引力。

### 恶意应用程序和深度伪造

GANs 可能被用来生成接近真实的虚假社会档案或虚假的名人视频。例如，GAN 算法可用于伪造证据来陷害某人。因此，有许多恶意的 GAN 应用程序，也有许多检测恶意 GAN 生成的样本并将其标记为假的 GAN。

### 杂项应用

除了前面的用例，gan 还用于以下目的:

*   用于医疗行业的早期诊断

*   在建筑和内部设计行业中生成逼真的图像

*   从图像中重建物体的三维模型

*   对于诸如老化的图像处理

*   以产生可用于癌症研究的蛋白质序列

*   通过声音重建一个人的脸。

生成性对抗性网络应用是巨大的和无限的，它是人工智能界的一个非常热门的话题。既然我们已经讨论了生成性敌对网络的基础，我们可以开始我们的案例研究了。请注意，我们将从 TensorFlow 团队发布的深度卷积 GAN 教程中获取自己的内容。 <sup>[1](#Fn1)</sup>

## 案例研究|使用 MNIST 生成数字

在本案例研究中，我们一步一步地构建了一个生成性对抗网络(GAN)，它能够生成手写数字(0 到 9)。为了能够完成这项任务，我们需要建立一个生成器网络和一个鉴别器网络，以便我们的生成模型可以学习欺骗鉴别器模型，后者检查生成器网络生产什么。让我们从最初的进口开始。

### 初始进口

正如我们在案例研究中经常做的那样，我们进行了一些初始导入，这些导入在我们的 Colab 笔记本的不同单元格中使用。以下行导入 TensorFlow、相关 TensorFlow 图层对象和 Matplotlib:

```
import tensorflow as tf
from tensorflow.keras.layers import(Dense,
                                 BatchNormalization,
                                 LeakyReLU,
                                 Reshape,
                                 Conv2DTranspose,
                                 Conv2D,
                                 Dropout,
                                 Flatten)
import matplotlib.pyplot as plt

```

在接下来的部分中，我们还使用其他库，如 *os* 、 *time* 、 *IPython.display* 、 *PIL* 、 *glob* 、*和 imageio* ，但为了保持它们与上下文相关，我们只在需要使用它们时才导入它们。

### 加载并处理 MNIST 数据集

我们已经讨论过几次 MNIST 数据集的细节。这是一个手写数字数据集，有 60，000 个训练样本和 10，000 个测试样本。如果你想了解更多关于 MNIST 数据集的信息，请参考第 [7](07.html) 章。

由于这是一个无监督的学习任务，我们只需要特征，因此我们不保存标签数组。让我们用下面几行导入数据集:

```
# underscore to omit the label arrays
(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()

```

然后，我们重塑我们的`train_images`,使其具有第四维度，并使用以下代码对其进行规范化(在-1 到 1 的范围内):

```
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]

```

然后，我们设置一个`BUFFER_SIZE`用于混洗，一个`BATCH_SIZE`用于批量处理数据。然后，我们调用以下函数将 NumPy 数组转换为 TensorFlow Dataset 对象:

```
# Batch and shuffle the data
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

```

现在我们的数据被处理和清理。我们可以进入模型构建部分。

### 构建 GAN 模型

与其他案例研究相比，本案例研究的模型构建部分稍微高级一些。我们需要定义自定义损失、训练步骤和训练循环函数。理解正在发生的事情可能更具挑战性。但是我会尽可能地添加更多的评论，让你更容易理解。此外，将这个案例研究视为成为高级机器学习专家的一条途径。另外，如果你真的关注了评论，那就比看起来容易多了。

#### 发电机网络

作为我们 GAN 网络的一部分，我们首先构建一个带有顺序 API 的生成器。生成器将接受具有 100 个数据点的一维输入，并将其慢慢转换成 28×28 像素的图像数据。由于我们使用该模型从一维输入生成图像，因此使用转置卷积层是最佳选择。转置卷积层的工作方式与卷积层正好相反。它们增加了图像数据的清晰度。在使用转置卷积层之后，我们还利用了批量归一化和泄漏 ReLU 层。下面的代码为我们定义了这个网络:

```
def make_generator_model():
  model = tf.keras.Sequential()
  model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))
  model.add(BatchNormalization())
  model.add(LeakyReLU())

  model.add(Reshape((7, 7, 256)))
  assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size

  model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding="same", use_bias=False))
  assert model.output_shape == (None, 7, 7, 128)
  model.add(BatchNormalization())
  model.add(LeakyReLU())

  model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding="same", use_bias=False))
  assert model.output_shape == (None, 14, 14, 64)
  model.add(BatchNormalization())
  model.add(LeakyReLU())

  model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding="same", use_bias=False, activation="tanh"))
  assert model.output_shape == (None, 28, 28, 1)

  return model

```

我们可以用下面的代码来声明我们的网络:

```
generator = make_generator_model()

```

让我们来看看图 [12-2](#Fig2) 中的发电机网络总结:

```
generator.summary()
Output:

```

![../images/501289_1_En_12_Chapter/501289_1_En_12_Fig2_HTML.jpg](../images/501289_1_En_12_Chapter/501289_1_En_12_Fig2_HTML.jpg)

图 12-2

我们的发电机网络概述

并使用我们未经训练的生成器网络生成和绘制一个样本，代码如下:

```
# Create a random noise and generate a sample
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
# Visualize the generated sample
plt.imshow(generated_image[0, :, :, 0], cmap="gray")

```

`Output is shown in Figure`[`12-3`](#Fig3)T2】

![../images/501289_1_En_12_Chapter/501289_1_En_12_Fig3_HTML.jpg](../images/501289_1_En_12_Chapter/501289_1_En_12_Fig3_HTML.jpg)

图 12-3

未经训练的随机生成样本的示例

#### 鉴别器网络

在生成器网络之后，我们应该构建一个鉴别器网络来检查生成器生成的样本。我们的鉴别器网络必须决定生成图像的伪造概率。因此，它获取生成的图像数据(28 x 28)并输出一个值。对于这个任务，我们使用由泄漏 ReLU 和漏失层支持的卷积层。展平图层将二维数据转换为一维数据，密集图层用于将输出转换为单个值。下面几行定义了鉴别器网络的功能:

```
def make_discriminator_model():
  model = tf.keras.Sequential()

  model.add(Conv2D(64, (5, 5), strides=(2, 2), padding="same", input_shape=[28, 28, 1]))
  model.add(LeakyReLU())
  model.add(Dropout(0.3))

  model.add(Conv2D(128, (5, 5), strides=(2, 2), padding="same"))
  model.add(LeakyReLU())
  model.add(Dropout(0.3))

  model.add(Flatten())
  model.add(Dense(1))

  return model

```

我们可以通过调用以下函数来创建鉴别器网络:

```
discriminator = make_discriminator_model()

```

我们可以看到我们的鉴频器网络总结，代码如下(输出见图 [12-4](#Fig4) ):

```
discriminator.summary()
Output:

```

![../images/501289_1_En_12_Chapter/501289_1_En_12_Fig4_HTML.jpg](../images/501289_1_En_12_Chapter/501289_1_En_12_Fig4_HTML.jpg)

图 12-4

我们的鉴别器网络综述

如果我们使用鉴别器网络，我们实际上可以决定我们随机生成的图像是否足够真实:

```
decision = discriminator(generated_image)
print (decision)
Output:
tf.Tensor([[-0.00108097]], shape=(1, 1), dtype=float32)

```

正如你所看到的，我们的输出小于零，我们可以得出结论，这个未经训练的生成器网络生成的特定样本是假的。

#### 配置 GAN 网络

作为模型配置的一部分，我们需要为生成器和鉴别器设置损失函数。此外，我们还需要为它们设置单独的优化器。

##### 损失函数

我们从从`tf.keras.losses`模块创建一个二进制交叉熵对象开始。我们还将参数`from_logits`设置为 true。创建对象后，我们用定制的鉴别器和生成器损耗函数填充它们。

我们的鉴别器损耗计算为(I)鉴别器对真实图像的预测为一组 1，以及(ii)鉴别器对生成图像的预测为一组 0 的组合。

我们的发电机损耗是通过测量它欺骗鉴别器的能力来计算的。因此，我们需要将鉴别者对生成的图像的决定与一系列的决定进行比较。

以下代码行完成了所有这些工作:

```
# This method returns a helper function to compute cross entropy loss
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
  real_loss = cross_entropy(tf.ones_like(real_output), real_output)
  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
  total_loss = real_loss + fake_loss
  return total_loss

def generator_loss(fake_output):
  return cross_entropy(tf.ones_like(fake_output), fake_output)

```

##### 【计算机】优化程序

我们还为生成器和鉴别器网络分别设置了两个优化器。我们可以使用来自`tf.keras.optimizers`模块的 Adam 对象。下面几行设置了优化器:

```
generator_optimizer=tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer=tf.keras.optimizers.Adam(1e-4)

```

#### 设置检查点

由于网络的复杂性，训练 GAN 网络比训练其它网络需要更长的时间。我们必须运行至少 50 `–` 60 个时期的训练，以生成有意义的图像。因此，设置检查点对于以后使用我们的模型非常有用。

通过使用操作系统库，我们设置了一个保存所有培训步骤的路径，代码如下:

```
import os

checkpoint_dir = './training_checkpoints'

checkpoint_prefix=os.path.join(checkpoint_dir, "ckpt")

checkpoint = tf.train.Checkpoint(
  generator_optimizer=generator_optimizer,
  discriminator_optimizer=discriminator_optimizer,
  generator=generator,
  discriminator=discriminator)

```

### 训练 GAN 模型

让我们用下面几行创建一些变量:

```
EPOCHS = 60
# We will reuse this seed overtime (so it's easier)
# to visualize progress in the animated GIF)
noise_dim = 100
num_examples_to_generate = 16
seed = tf.random.normal([num_examples_to_generate, noise_dim])

```

我们的种子是我们用来生成图像的噪音。下面的代码生成一个形状为(16，100)的正态分布随机数组。

#### 训练步骤

这是我们模型中最不寻常的部分:我们正在设置一个定制的训练步骤。在通过注释`tf.function`模块定义自定义`train_step()`函数后，我们的模型将基于我们定义的自定义`train_step()`函数进行训练。

以下带有过多注释的代码是针对培训步骤的。请仔细阅读评论。

```
# tf.function annotation causes the function
# to be "compiled" as part of the training
@tf.function
def train_step(images):
  # 1 - Create a random noise to feed it into the model
  # for the image generation
  noise = tf.random.normal([BATCH_SIZE, noise_dim])
  # 2 - Generate images and calculate loss values
  # GradientTape method records operations for automatic differentiation.
  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    generated_images = generator(noise, training=True)
    real_output = discriminator(images, training=True)
    fake_output = discriminator(generated_images, training=True)
    gen_loss = generator_loss(fake_output)
    disc_loss = discriminator_loss(real_output, fake_output)

  # 3 - Calculate gradients using loss values and model variables
  # "gradient" method computes the gradient using
  # operations recorded in context of this tape (gen_tape and disc_tape).
  # It accepts a target (e.g., gen_loss) variable and
  # a source variable (e.g.,generator.trainable_variables)
  # target --> a list or nested structure of Tensors or Variables to be differentiated.
  # source --> a list or nested structure of Tensors or Variables.
  # target will be differentiated against elements in sources.
  # "gradient" method returns a list or nested structure of Tensors
  # (or IndexedSlices, or None), one for each element in sources.
  # Returned structure is the same as the structure of sources.
  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
  gradients_of_discriminator = disc_tape.gradient( disc_loss, discriminator.trainable_variables)
  # 4 - Process  Gradients and Run the Optimizer
  # "apply_gradients" method processes aggregated gradients.
  # ex: optimizer.apply_gradients(zip(grads, vars))

  """
  Example use of apply_gradients:
  grads = tape.gradient(loss, vars)
  grads = tf.distribute.get_replica_context().all_reduce('sum', grads)
  # Processing aggregated gradients.
  optimizer.apply_gradients(zip(grads, vars), experimental_aggregate_gradients=False)
  """
  generator_optimizer.apply_gradients(zip( gradients_of_generator, generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip( gradients_of_discriminator, discriminator.trainable_variables))

```

现在我们已经用`tf.function`注释定义了我们的定制训练步骤，我们可以为训练循环定义我们的训练函数了。

#### 训练循环

我们为训练循环定义了一个名为`train`的函数。我们不仅运行 for 循环在 MNIST 上迭代我们的自定义训练步骤，还使用单个函数执行以下操作:

*   在训练期间
    *   开始记录每个时期开始时花费的时间

    *   制作 GIF 图像并显示它们

    *   每隔 5 个时期将模型保存为一个检查点

    *   打印出完整的纪元时间

*   训练完成后，最终生成最终图像

以下带有详细注释的行完成所有这些任务:

```
import time
from IPython import display # A command shell for interactive computing in Python.

def train(dataset, epochs):
  # A. For each epoch, do the following:
  for epoch in range(epochs):
  start = time.time()
  # 1 - For each batch of the epoch,
  for image_batch in dataset:
    # 1.a - run the custom "train_step" function
    # we just declared above
    train_step(image_batch)

  # 2 - Produce images for the GIF as we go
  display.clear_output(wait=True)
  generate_and_save_images(generator,
                           epoch + 1,
                           seed)

  # 3 - Save the model every 5 epochs as
  # a checkpoint, which we will use later
  if (epoch + 1) % 5 == 0:
    checkpoint.save(file_prefix = checkpoint_prefix)

  # 4 - Print out the completed epoch no. and the time spent
  print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # B. Generate a final image after the training is completed
  display.clear_output(wait=True)
  generate_and_save_images(generator,
                           epochs,
                           seed)

```

#### 图像生成功能

在训练函数中，有一个我们还没有定义的自定义图像生成函数。我们的图像生成功能执行以下任务:

*   使用模型生成图像。

*   使用 Matplotlib 在 4 x 4 网格布局中显示生成的图像。

*   最后保存最后的数字。

以下部门负责这些任务:

```
def generate_and_save_images(model, epoch, test_input):
  # Notice `training` is set to False.
  # This is so all layers run in inference mode (batchnorm).
  # 1 - Generate images
  predictions = model(test_input, training=False)
  # 2 - Plot the generated images
  fig = plt.figure(figsize=(4,4))
  for i in range(predictions.shape[0]):
    plt.subplot(4, 4, i+1)
    plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap="gray")
      plt.axis('off')

  # 3 - Save the generated images

  plt.savefig('image_at_epoch_{:04d}.png'.format( epoch))
  plt.show()

```

既然我们已经定义了自定义图像生成函数，我们可以在下一部分中安全地调用 train 函数。

#### 开始训练

开始训练循环非常容易。下面的单行代码将从 train 函数开始训练，该函数循环遍历`train_step()`函数并使用`generate_and_save_images()`函数生成图像。在此过程中，我们还会收到统计数据和信息，以及在 4 x 4 网格布局上生成的图像。

```
train(train_dataset, EPOCHS)
Output:

```

![../images/501289_1_En_12_Chapter/501289_1_En_12_Fig5_HTML.jpg](../images/501289_1_En_12_Chapter/501289_1_En_12_Fig5_HTML.jpg)

图 12-5

在 4 x 4 网格布局中 60 个时期后生成的图像

如图 [12-5](#Fig5) 所示，经过 60 个历元，生成的图像非常接近正确的手写数字。我唯一看不到的数字是数字二(2)，这可能只是一个巧合。

既然我们已经训练了我们的模型并保存了我们的检查点，我们可以用下面的代码行恢复训练好的模型:

```
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))

```

### 在训练过程中动画生成的数字

在训练过程中，我们的`generate_and_save_images()`函数成功保存了每个时期生成的 4 x 4 图像网格布局。让我们通过一个简单的练习来看看我们的模型的生成能力是如何随着时间的推移而发展的。

为了能够打开图像，我们可以使用 PIL (Python Image Library)，它支持许多不同的图像格式，包括 PNG。我们可以定义一个自定义函数，用下面几行打开图像:

```
# PIL is a library which may open different image file formats
import PIL
# Display a single image using the epoch number
def display_image(epoch_no):
  return PIL.Image.open( 'image_at_epoch_{:04d}.png'.format( epoch_no ))

```

现在用下面一行测试这个函数，它将显示我们的模型生成的最新 PNG 文件:

```
display_image(EPOCHS)

```

**输出** `is shown in Figure` [`12-6`](#Fig6) `:`

![../images/501289_1_En_12_Chapter/501289_1_En_12_Fig6_HTML.jpg](../images/501289_1_En_12_Chapter/501289_1_En_12_Fig6_HTML.jpg)

图 12-6

GAN 模型生成的最新 PNG 文件的显示。注意，它们与图 [12-5 所示的样品相同。](#Fig5)因为我们从上一个检查点恢复了模型

使用`display_images()`功能，我们可以显示任何我们想要的图像。除此之外，生成一个动画 GIF 图像来显示我们的模型是如何随着时间的推移而演变的，这不是很酷吗？我们可以使用 glob 和 imageio 库来实现这一点，它们将所有的 PNG 文件堆积起来，创建一个动画 GIF 文件。以下代码行执行此任务:

```
import glob # The glob module is used for Unix style pathname pattern expansion.
import imageio # The library that provides an easy interface to read and write a wide range of image data

anim_file = 'dcgan.gif'

with imageio.get_writer(anim_file, mode="I") as writer:
  filenames = glob.glob('image*.png')
  filenames = sorted(filenames)
  for filename in filenames:
    image = imageio.imread(filename)
    writer.append_data(image)
  image = imageio.imread(filename)
  writer.append_data(image)

```

点击 Google Colab 笔记本左侧的*文件*图标，查看所有文件，包括“ *dcgan.gif* ”。您可以简单地下载它来查看我们的模型在每个时期生成的图像的动画版本。为了能够在您的 Google Colab 笔记本中查看 GIF 图像，您可以使用以下代码行:

```
display.Image(open('dcgan.gif','rb').read())

```

图 [12-7](#Fig7) 显示了我们创建的 GIF 图像中的几帧:

![../images/501289_1_En_12_Chapter/501289_1_En_12_Fig7_HTML.jpg](../images/501289_1_En_12_Chapter/501289_1_En_12_Fig7_HTML.jpg)

图 12-7

从不同时代产生的数字例子。了解 GAN 模型如何随着时间的推移学习生成数字

## 结论

在这一章中，我们讨论了最后一个神经网络架构，生成对抗网络，它主要用于艺术、制造、研究和游戏等领域的生成任务。我们还进行了一个案例研究，其中我们训练了一个能够生成手写数字的 GAN 模型。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

深度卷积生成对抗网络，TensorFlow，可用在 [`www.tensorflow.org/tutorials/generative/dcgan`](https://www.tensorflow.org/tutorials/generative/dcgan)

 </aside>