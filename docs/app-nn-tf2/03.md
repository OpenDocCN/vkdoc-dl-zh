# 3.深度学习和神经网络概述

既然你正在读这本书，那么可以有把握地假设你知道深度学习是如何在最近几年流行起来的。深度学习越来越受欢迎有一个非常好的原因:**它不可思议的准确性表现**。尤其是当有丰富的数据和可用的处理能力时，深度学习是机器学习专家的选择。深度学习与传统机器学习算法的性能对比如图 [3-1](#Fig1) 所示。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig1_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig1_HTML.png)

图 3-1

深度学习与传统 ML 在准确性上的比较

深度学习是机器学习的一个子领域，它模仿人脑的数据处理和模式生成能力，用于自动决策。与其他机器学习算法相比，深度学习的独特准确性曲线有助于它被机器学习专家广泛使用和采用。由于人工神经网络，深度学习成为可能。人工神经网络是模拟人脑中神经元的网络结构，以便可以进行深度学习。在图 [3-2](#Fig2) 中，你可能会发现一个具有深度学习能力的人工神经网络(ANN)的例子。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig2_HTML.jpg](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig2_HTML.jpg)

图 3-2

具有两个隐层的人工神经网络的描述

你可能会认为深度学习是一个新发明的领域，最近推翻了其他机器学习算法。很多人都这样想。然而，人工神经网络和深度学习领域可以追溯到 20 世纪 40 年代。最近深度学习的兴起主要是因为大量的可用数据，更重要的是因为廉价而丰富的处理能力。

这是深度学习的概述章节。我们将看看我们在深度学习中经常使用的关键概念，包括(I)激活函数，(ii)损失函数，(iii)优化器和反向传播，(iv)正则化，以及(v)特征缩放。但是，首先，我们将深入研究人工神经网络和深度学习的历史，以便您对本书中经常看到的深度学习概念的根源有所了解。

## 神经网络和深度学习研究的时间线

神经网络和深度学习研究的时间轴并不是由一系列不间断的进步组成的。事实上，人工智能领域经历了几次失败，这些失败被称为 AI winters。让我们深入研究神经网络和深度学习的历史，它始于 1943 年。

****人工神经元**的开发——1943 年，先驱学者沃尔特·皮茨和沃伦·麦卡洛克发表了论文*【神经活动中内在思想的逻辑演算】*，在那里他们提出了一个生物神经元的数学模型，称为 ***麦卡洛克-皮茨神经元*** 。麦卡洛克皮茨神经元的能力是最小的，它没有学习机制。麦卡洛克·皮茨神经元的重要性在于，它为深度学习奠定了基础。1957 年，Frank Rosenblatt 发表了另一篇论文，题为“感知器:感知和识别自动机”，其中他介绍了具有学习和二进制分类功能的**感知器**。革命性的感知机模型——在麦克库洛奇·皮茨神经元之后崛起——激励了许多从事人工神经网络研究的研究人员。**

 ****反向传播**——1960 年，亨利·j·凯利发表了一篇题为《最佳飞行路径的梯度理论》的论文，他在论文中展示了一个连续反向传播的例子。反向传播是一个重要的深度学习概念，我们将在本章中讨论。1962 年，Stuart Dreyfus 在他的论文“变分问题的数值解”中用链式法则改进了反向传播。反向传播这个术语是由 Rumelhart、Hinton 和 Williams 在 1986 年创造的，这些研究人员已经将其应用于人工神经网络。

**训练和计算机化**–1965 年，通常被称为“深度学习之父”的阿列克谢·伊瓦赫年科(Alexey Ivakhnenko)建立了一个神经网络的分层表示，并通过使用多项式激活函数成功训练了这个模型。1970 年，Seppo Linnainmaa 发现了反向传播的自动微分，并能够编写第一个反向传播程序。这一发展可能标志着深度学习计算机化的开始。1971 年，Ivakhnenko 创建了一个八层神经网络，由于其多层结构，它被认为是一个深度学习网络。

1969 年，马文·明斯基和西蒙·派珀特写了《感知机》一书，他在书中猛烈抨击了感知机弗兰克·罗森布拉特的工作。这本书对人工智能项目资金造成了毁灭性的破坏，引发了从 1974 年持续到 1980 年的**人工智能冬天**。

**卷积神经网络**——1980 年，Kunihiko Fukushima 推出了 neocognitron，这是第一个卷积神经网络(CNN)，可以识别视觉模式。1982 年，Paul Werbos 提出了在神经网络中使用反向传播来最小化误差，并且 AI 社区已经广泛采用了这个提议。1989 年，Yann LeCun 使用反向传播来训练 CNN 识别 MNIST(改进的国家标准和技术研究所)数据集中的手写数字。在本书中，我们在第七章[中有一个类似的案例研究。](07.html)

**递归神经网络**–1982 年，John Hopfield 介绍了 Hopfield 网络，这是递归神经网络(RNNs)的早期实现。递归神经网络是革命性的算法，最适用于顺序数据。1985 年，Geoffrey Hinton、David H. Ackley 和 Terrence Sejnowski 提出了玻尔兹曼机，这是一种没有输出层的随机 RNN。1986 年，Paul Smolensky 开发了一种新的玻尔兹曼机器变体，它在输入层和隐藏层中没有层内连接，这种机器被称为受限玻尔兹曼机器。受限玻尔兹曼机器在推荐系统中尤其成功。1997 年，Sepp Hochreiter 和 Jürgen Schmidhuber 发表了一篇关于改进的 RNN 模型——长短期记忆(LSTM)的论文，我们也将在第八章[中涉及。2006 年，Geoffrey Hinton、Simon Osindero 和 Yee Whye Teh 组合了几个受限玻尔兹曼机器(RBM)并创建了深度信念网络，这提高了 RBM 的能力。](08.html)

**深度学习的能力**–1986 年，Terry Sejnowski 开发了 NETtalk，这是一个基于神经网络的文本到语音转换系统，可以对英语文本进行发音。1989 年，George Cybenko 在他的论文“Sigmoidal 函数的叠加逼近”中指出，具有单个隐藏层 ***的前馈神经网络可以求解任何连续函数*** 。

**消失梯度问题**——1991 年，Sepp Hochreiter 发现并证明了消失梯度问题，它减缓了深度学习过程，使其变得不切实际。20 年后，在 2011 年，Yoshua Bengio、Antoine Bordes 和 Xavier Glorot 表明，使用校正线性单位(ReLU)作为激活函数可以防止消失梯度问题。

**用于深度学习的 GPU**——2009 年，吴恩达、拉杰特·刘冰和阿南德·马德哈万在他们的论文《使用图形处理器的大规模深度无监督学习》中建议使用 GPU 进行深度学习，因为在 GPU 中发现的核心数量比在 CPU 中发现的要多得多。这种转换减少了神经网络的训练时间，使它们的应用更加可行。随着 GPU 制造商推出的官方并行计算平台(如 Nvidia 的 CUDA 和 AMD 的 ROCm)，GPU 在深度学习中的使用越来越多，导致了深度学习专用 ASICS 的发展(如谷歌的 TPU)。

**ImageNet** **和****AlexNet**——2009 年，费-李非推出了一个拥有 1400 万张标注图片的数据库，名为 ImageNet。ImageNet 数据库的创建有助于图像处理神经网络的发展，因为深度学习的一个重要组成部分是丰富的数据。自从 ImageNet 数据库创建以来，每年都举行竞赛以改进图像处理研究。2012 年，Alex Krizhevsky 设计了一个经过 GPU 训练的 CNN，AlexNet，与早期的模型相比，模型精度提高了 75%。

**生成对抗网络**——2014 年，伊恩·古德菲勒(Ian Goodfellow)在当地一家酒吧和朋友聊天时，想到了一个新的神经网络模型的想法。这个革命性的模型是在一夜之间设计出来的，现在被称为生成对抗性神经网络(GANs)，它能够生成艺术，文本和诗歌，它可以完成许多其他创造性任务。在第 [12](12.html) 章中，我们有一个关于 GANs 实施的案例研究。

**力量** **强化学习**——2016 年，DeepMind 训练了一个深度强化学习模型 AlphaGo，它可以玩围棋，围棋被认为是比象棋复杂得多的游戏。AlphaGo 在 2017 年击败了围棋世界冠军柯洁。

**图灵奖授予深度学习的先驱**——2019 年，人工智能领域的三位先驱 Yann LeCun、Geoffrey Hinton 和 Yoshua Bengio 分享了图灵奖。这个奖项证明了深度学习对于计算机科学界的重要性。

## 人工神经网络的结构

在深入研究基本的深度学习概念之前，让我们看看当今现代深度神经网络的发展历程。今天，我们可以很容易地找到具有数百层和数千个神经元的神经网络的例子，但在二十世纪中期之前，人工神经网络这个术语甚至不存在。这一切始于 1943 年的一个简单的人工神经元——麦卡洛克·皮茨神经元——它只能进行简单的数学计算，没有学习能力。

### 麦卡洛克-皮茨神经元

麦卡洛克·皮茨神经元于 1943 年问世，它只能进行基本的数学运算。每个事件被赋予一个布尔值(0 或 1)，如果事件结果(0 和 1)的总和超过一个阈值，那么人工神经元就会触发。图 [3-3](#Fig3) 显示了麦卡洛克皮茨神经元的 or 和 and 运算的可视化示例。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig3_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig3_HTML.png)

图 3-3

用于“或”与“与”运算的麦卡洛克·皮茨神经元

由于来自麦卡洛克皮茨神经元事件的输入只能是布尔值(0 或 1)，它的能力是最小的。随着线性阈值单元(LTU)的发展，这种限制得到了解决。

### 线性阈值单位(LTU)

在麦卡洛克·皮茨神经元中，每个事件的重要性是相等的，这是有问题的，因为大多数真实世界的事件不符合这种简单的设置。为了解决这个问题，1957 年引入了线性阈值单元(LTU)。在 LTU 中，权重被分配给每个事件，这些权重可以是负的或正的。每个事件的结果仍被赋予一个布尔值(0 或 1)，但随后乘以指定的权重。只有当这些加权事件结果的总和为正时，才会激活 LTU。在图 [3-4](#Fig4) 中，你可能会发现 LTU 的可视化，它是今天人工神经网络的基础。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig4_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig4_HTML.png)

图 3-4

线性阈值单元(LTU)可视化

### 感知器

感知器是一种用于监督学习的二进制分类算法，由一层 ltu 组成。在感知器中，ltu 使用相同的事件输出作为输入。感知器算法可以调整权重，以校正经过训练的神经网络的行为。此外，可以添加偏置项来提高网络的精度性能。

当感知器只有一层时，称为单层感知器。有一个输出层和一个接收输入的输入层。当隐藏层被添加到单层感知器时，我们最终得到一个多层感知器(MLP)。MLP 被认为是一种深度神经网络，我们为日常问题建立的人工神经网络就是 MLP 的例子。在图 [3-5](#Fig5) 中，你可能会发现一个单层感知器的可视化例子。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig5_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig5_HTML.png)

图 3-5

单层感知器图的例子

### 现代深度神经网络

我们今天遇到的深度神经网络是多层感知器(MLP)的改进版本。我们经常使用比阶跃函数(0 或 1)更复杂的激活函数，如 ReLU、Sigmoid、Tanh 和 Softmax。现代深度神经网络通常利用一种梯度下降方法进行优化。现代深度神经网络示例如图 [3-6](#Fig6) 所示。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig6_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig6_HTML.png)

图 3-6

一个现代深度神经网络的例子

现在，您已经了解了更多关于开发今天的现代深度神经网络的旅程，这是从麦卡洛克·皮茨神经元开始的，我们可以深入研究我们在应用中使用的基本深度学习概念。

## 激活功能

激活函数是用于帮助人工神经网络从数据中学习复杂模式的函数。通常在每个神经元的末端添加一个激活函数，它会影响下一个神经元触发什么。换句话说，如图 [3-7](#Fig7) 所示，一个神经元的激活函数是在给定一个输入或一组输入后，给出该神经元的输出。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig7_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig7_HTML.png)

图 3-7

最后是一个带有激活函数的 LTU 图的例子

激活函数引入了最终的计算步骤，这给人工神经网络增加了额外的复杂性。因此，它们增加了所需的训练时间和处理能力。那么，我们为什么要在神经网络中使用激活函数呢？答案很简单:激活函数提高了神经网络使用相关信息和抑制不相关数据点的能力。如果没有激活函数，我们的神经网络将只能执行线性转换。尽管避免激活函数使得神经网络模型更简单，但是该模型的功能将更弱，并且不能收敛于复杂的模式结构。没有激活函数的神经网络本质上只是一个线性回归模型。

我们可以在神经网络中使用许多不同的激活函数。激活功能的非详尽列表可在此处找到:

*   二进制步骤

*   线性的

*   乙状结肠(逻辑激活功能)

*   双曲正切

*   整流线性单位

*   Softmax(软件最大值)

*   李奇注意到了

*   参数化 ReLU

*   指数线性单位

*   嗖嗖

在这些激活函数中，Tanh、ReLU 和 Sigmoid 激活函数广泛用于单个神经元激活。还有，Softmax 函数在图层之后被广泛使用。您可以在图 [3-8](#Fig8) 中找到 Tanh、ReLU 和 Sigmoid 函数的 X-Y 图。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig8_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig8_HTML.png)

图 3-8

Tanh、ReLU 和 Sigmoid 函数图

根据问题的性质，一个激活功能可能比另一个执行得更好。尽管 ReLU、Tanh 和 Sigmoid 函数通常在深度学习中收敛得很好，但我们应该尝试所有可能的函数，并优化我们的训练，以尽可能实现最高的精度性能。可以通过以下要点对 ReLU、Tanh 和 Sigmoid 进行简单的比较:

*   ReLU 函数是一个广泛使用的通用激活函数。应该用在隐藏层。如果有死亡的神经元，泄漏的 ReLU 可能会修复潜在的问题。

*   Sigmoid 函数在分类任务中工作得最好。

*   Sigmoid 和 Tanh 函数可能会导致消失梯度问题。

优化训练实践的最佳策略是从 ReLU 开始，尝试其他激活功能，看看性能是否有所提高。

## 损失(成本或误差)函数

损失函数是用于测量深度学习模型对于给定数据的性能的函数。它通常基于误差项，误差项被计算为真实(测量)值和训练模型的预测值之间的距离。

![$$ {e}_i={y}_i-{\hat{\mathrm{y}}}_i $$](../images/501289_1_En_3_Chapter/501289_1_En_3_Chapter_TeX_Equa.png)T2】

*误差=测量值-预测值*

因此，我们每次预测都会有一个误差项。假设您正在处理数百万个数据点。为了能够从这些单独的误差项中获得洞察力，我们需要一个聚合函数，以便我们能够得出一个性能评估的单一值。这个函数被称为**损失函数、** **成本函数** **，或者** **误差函数** **，视上下文而定**。

几个损失函数用于性能评估，选择正确的函数是建模的一个组成部分。这种选择必须基于问题的性质。虽然均方根误差(RMSE)函数对于我们想要惩罚大误差的回归问题是正确的损失函数，但是多类交叉熵应该被选择用于多类分类问题。

此外，为了被用于生成聚合误差项的单个值，损失函数也可以被用于强化学习中的奖励。在本书中，我们将主要使用带有误差项的损失函数，但请注意，使用损失函数作为奖励措施是可能的。

深度学习任务中使用了几个损失函数。均方根误差(RMSE)、均方误差(MSE)、平均绝对误差(MAE)和平均绝对百分比误差(MAPE)是回归问题的一些合适的损失函数。对于二元和多类分类问题，我们可以使用交叉熵的变体(即*对数*)函数。

## 深度学习中的优化

既然我们已经讨论了激活和损失函数，是时候继续讨论权重和偏差优化了。神经元和层中使用的激活函数对从权重和偏差项导出的线性结果进行最终调整。我们可以使用这些参数(权重和偏差)进行预测。实际值和预测值之间的距离被记录为误差项。这些误差项通过损失函数聚集成单个值。除了这个过程，优化函数对权重和偏差进行小的改变，并用损失函数测量这些改变的影响。该过程有助于找到最佳权重和偏差值，以最小化误差并最大化模型的准确性。这个训练周期如图 [3-9](#Fig9) 所示。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig9_HTML.jpg](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig9_HTML.jpg)

图 3-9

具有成本函数、激活函数和优化器的深度学习模型训练

在优化过程中会遇到一些优化算法和挑战。在本节中，我们将简要介绍这些功能和挑战。但首先，我们来看看一个必不可少的优化概念:*反向传播*。

### 反向传播

反向传播算法是用于与优化器并行迭代的神经网络架构中的基本组件。它是神经网络学习的中心机制。这个名字本身就说明了问题，因为单词 ***propagate*** 的意思是传送某物。所以*一词 **backpropagation*** 的意思是*将信息传回。*“这正是反向传播算法所要做的:它将计算出的损失返回给系统，由优化器用来调整权重和偏差。这个过程可以一步一步地解释，如下所示:

*   **步骤 1** :训练好的神经网络用当前的权重和偏差进行预测。

*   **步骤 2** :用损失函数作为单一误差度量来测量神经网络的性能。

*   **步骤 3** :这个误差度量被反向传播到优化器，以便它可以重新调整权重和偏差。

*   **重复**

通过使用反向传播算法提供的信息，优化算法可以完善神经网络中使用的权重和偏差。让我们来看看优化算法(即*优化器*)，它们与反向传播机制并行使用。

### 优化算法

优化算法可以被定义为帮助另一个算法无延迟地最大化其性能的算法。深度学习是优化算法被广泛使用的一个领域。深度学习任务中最常用的优化算法如下:

*   圣经》和《古兰经》传统中）亚当（人类第一人的名字

*   随机梯度下降

*   阿达德尔塔

*   Rmsprop

*   阿达玛斯

*   阿达格拉德

*   那达慕

请注意，所有这些优化器以及前面提到的损失和激活函数在 TensorFlow 中都很容易找到。实际应用中最常用的是 Adam 优化器和随机梯度下降(SGD)优化器。让我们看看所有优化器之母，梯度下降和 SGD，以便更好地理解优化算法是如何工作的。

**梯度下降和随机梯度下降(SGD)**–随机梯度下降是梯度下降方法的一种变体。SGD 是深度学习中广泛使用的一种迭代优化方法。SGD 的根源可以追溯到 20 世纪 50 年代，它是最古老的——但也是最成功的——优化算法之一。

梯度下降法是一系列优化算法，用于最小化神经网络中的总损失(或成本)。有几种梯度下降实现:原始梯度下降或批量梯度下降算法使用每个时期的全部训练数据。随机(随机)梯度下降(SGD)选择随机观察来测量由于权重和偏差的变化而导致的总损失(或成本)的变化。最后，小批量梯度下降使用小批量，因此训练可能仍然是快速和可靠的。

Epoch

是超参数，表示使用定型数据集调整神经网络值的次数。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig10_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig10_HTML.png)

图 3-10

显示梯度下降的失重图

图 [3-10](#Fig10) 显示了梯度下降算法的工作原理。当机器学习专家选择更快的学习速率时，采取更大的增量步骤。

Learning Rate

是优化算法中的参数，它调节每次迭代时的步长，同时向前移动损失/成本函数的最小值。学习速度越快，模型越快地收敛到最小值附近，但它可能会超过实际的最小值点。如果学习速度慢，优化可能会花费太多时间。因此，一个机器学习专家必须选择最优的学习速率，它允许模型在合理的时间内找到期望的最小点。

**亚当优化器**–什么是亚当？

我不会深入其他优化算法的细节，因为它们大多是梯度下降法的修改或改进实现。所以暂时了解一下梯度下降算法就够了。

在下一节中，我们将看到在培训过程中对优化过程产生负面影响的优化挑战。如前所述，开发了一些优化算法来缓解这些挑战。

### 优化挑战

我们在深度学习中经常会遇到三个优化挑战。这些挑战是(I)局部最小值，(ii)鞍点，和(iii)消失梯度。我们简单讨论一下它们是什么。

**局部最小值****–**在神经网络训练中，具有单个最小值的简单减肥图可能有助于可视化体重和计算出的体重之间的关系，以用于教育目的。然而，在现实世界的问题中，这个图可能包含许多局部最小值，并且我们的优化算法可能收敛于一个局部最小值而不是全局最小值点。图 [3-11](#Fig11) 显示了我们的模型是如何陷入局部最小值的。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig11_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig11_HTML.png)

图 3-11

具有两个局部最小值和一个全局最小值的减重图

**鞍点—**鞍点是图中的稳定点，算法无法判断它是局部最小值还是局部最大值。鞍点的两边斜率为零。使用多个观测值进行损失计算的优化器可能会陷入鞍点。因此，随机梯度下降是鞍点的一个合适的解决方案。图 [3-12](#Fig12) 为带有鞍点的简化图形。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig12_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig12_HTML.png)

图 3-12

具有两个局部最小值和一个全局最小值的减重图

**消失梯度****–**过度使用某些激活函数(如 Sigmoid)可能会对优化算法产生负面影响。由于损失函数的梯度接近于零，所以降低损失函数的输出变得困难。消失梯度问题的一个有效解决方案是在隐藏层中使用 ReLU 作为激活函数。Sigmoid 激活函数——消失梯度问题的主要原因——及其导数如图 [3-13](#Fig13) 所示。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig13_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig13_HTML.png)

图 3-13

Sigmoid 函数及其导数

为了能够解决这种常见的优化挑战，我们应该尝试并找到激活函数和优化函数的最佳组合，以便我们的模型正确收敛并找到理想的最小点。

## 过度拟合和正则化

深度学习和机器学习的另一个重要概念是过拟合。在本节中，我们将讨论过拟合问题以及如何用正则化方法解决过拟合问题。

### 过度拟合

在第 [2](02.html) 章中，我们已经简单解释了机器学习的过拟合概念。过度拟合也是深度学习中的一个挑战。我们不希望我们的神经网络过于紧密地拟合有限的一组数据点，这会危及它在现实世界中的性能。我们也不希望我们的模型欠拟合，因为它不会给我们一个好的精度水平。欠配合和过配合问题如图 [3-14](#Fig14) 所示。

![../images/501289_1_En_3_Chapter/501289_1_En_3_Fig14_HTML.png](../images/501289_1_En_3_Chapter/501289_1_En_3_Fig14_HTML.png)

图 3-14

X-Y 图中的欠拟合和过拟合

解决拟合不足问题的方法是建立一个具有有意义特征的好模型，输入足够的数据，进行足够的训练。另一方面，更多的数据、去除过多的特征和交叉验证是解决过度拟合问题的适当方法。此外，我们有一组复杂的方法来克服过拟合问题，即正则化方法。

### 正规化

正则化是一种对抗过度拟合的技术。有许多可能的正则化方法，可列举如下:

*   提前停止

*   拒绝传统社会的人

*   L1 和 L2 正规化

*   日期增加

**提前停止**–提前停止是一种非常简单但有效的防止过度拟合的策略。设置足够数量的历元(训练步骤)对于实现高水平的准确性至关重要。但是，您可能很容易走极端，将您的模型训练得与您的训练数据过于吻合。使用早期停止，如果模型在一定数量的时期内没有显示出显著的性能改善，则学习算法停止。

**辍学**–辍学是另一种简单但有效的正规化方法。启用 dropout 后，我们的模型会暂时从网络中删除一些神经元或层，这会给神经网络增加额外的噪声。这种噪声防止模型与训练数据过于接近，并使模型更加灵活。

**L1 和 L2 正则化**–这两种方法在损失函数中增加了一个额外的惩罚项，对误差的惩罚力度更大。对于 L1 正则化，这一项是套索回归，而对于 L2 正则化，这是岭回归。处理大量要素时，L1 和 L2 正则化尤其有用。

**数据扩充**–数据扩充是一种增加训练数据量的方法。通过对现有数据进行小的转换，我们可以生成更多的观察值，并将它们添加到原始数据集中。数据扩充增加了训练数据的总量，这有助于防止过拟合问题。

## 特征缩放

深度学习的另一个关键概念是特征缩放。特征缩放是一种标准化特征范围的方法，以便神经网络更准确地执行。当特征值的范围变化很大时，一些目标函数可能无法在机器学习模型中正确工作。例如，分类器通常计算两个数据点之间的距离。当一个特征的值的方差很大时，这个特征决定了这个计算的距离，这意味着**这个特定特征对结果**的夸大影响。缩放每个特性的值范围有助于消除这个问题。下面列出了几种特征缩放方法:

*   **标准化**:调整各特征值，使均值和单位方差为零。

*   **最小-最大归一化(重新缩放)**:在[0，1]和[-1，1]之间缩放每个特性的值。

*   **均值归一化**:从每个数据点中扣除均值，并将结果除以最大-最小差。它是最小-最大归一化的一个稍有改变且不太流行的版本。

*   **缩放到单位长度**:将特征的每个分量除以该特征向量的欧几里德长度。

在深度学习中使用特征缩放有两个好处:

*   它确保每个特征对预测算法的贡献成比例。

*   它加速了梯度下降算法的收敛，从而减少了训练模型所需的时间。

## 最终评估

在这一章中，我们讨论了人工神经网络和深度学习的时间线。经过多年的研究，它帮助我们理解了我们在职业生活中使用的概念是如何变成现实的。好消息是，由于 TensorFlow，我们能够在几秒钟内将这些组件添加到我们的神经网络中。

沿着深度学习时间线，我们详细分析了神经网络和人工神经元的结构。此外，我们涵盖了基本的深度学习概念，包括(I)优化函数，(ii)激活函数，(iii)损失函数，(iv)过拟合和正则化，以及(v)特征缩放。

这一章是上一章的延续，上一章我们讲述了机器学习的基础知识。在下一章中，我们将了解深度学习研究中最常用的补充技术:(i) NumPy，(ii) SciPy，(iii) Matplotlib，(iii) Pandas，(iv) scikit-learn，以及(v) Flask。**