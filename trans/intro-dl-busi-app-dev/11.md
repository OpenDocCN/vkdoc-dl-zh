# 十一、新的研究和未来方向

有几个领域深度学习非常活跃，几乎每周都有突破出现。强化学习及其在机器人和模拟代理中的应用显然是最活跃的领域之一。图像、视频和语音识别仍然是活跃的领域。NLP 正在显著改善，但也许在不久的将来人类水平的性能是遥不可及的，因为它可能是最难的领域之一。(对于深度学习应用于 NLP 的一些批评，参见 [`https://medium.com/@yoav.goldberg/an-adversarial-review-of-adversarial-generation-of-natural-language-409ac3378bd7`](https://medium.com/@yoav.goldberg/an-adversarial-review-of-adversarial-generation-of-natural-language-409ac3378bd7) 。)

通过大型 rnn，自然语言处理、语音识别和自动视频分析中的许多监督任务可能很快变得微不足道。在不久的将来，监督学习 RNNs 和强化学习都将得到很大的发展。当前的大型人工神经网络具有大约十亿个连接；很快这个数字将会是一万亿，以同样的价格。相比之下，人类大脑有数万亿个——慢得多——连接。

在很大程度上，机器学习的进展是由在具有数百万人类标记的样本的大规模数据集上进行训练的好处推动的。但这种方法从长远来看是不可行的，而且这与人类的学习方式相去甚远。无监督学习需要更多的进展，就像正在生成网络上开发的工作一样。

## 11.1 研究

尽管图像、语音、机器人和视频处理仍然是广泛使用 CNN 和 LSTM 的非常重要的研究领域，但 DL 在这些领域非常活跃:

*   强化学习，或弱监督学习
*   注意机制
*   一次性学习和知识转移
*   多模态学习
*   生成对抗网络

在谷歌最近的一项研究工作( [`https://arxiv.org/abs/1707.02968`](https://arxiv.org/abs/1707.02968) )中，作者表明训练数据的大小非常重要。他们使用了 3 亿张图像的数据集，分为 18，291 个类别，并训练了几个 DL 架构:AlexNet，VGG，ResNet 50，ResNet 101 和 Inception-ResNet v2。他们证明，通过使用更多的训练数据，甚至更简单的架构也能获得相当大的准确性。您可以在 [`https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html`](https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html) 了解更多信息。

这些是其他的结论:

![A454512_1_En_11_Fig1_HTML.jpg](img/A454512_1_En_11_Fig1_HTML.jpg)

图 11-1

Importance of data size in training DL models (source: [`https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html`](https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html) )

*   大型数据集有助于表示学习，并用于预训练模型。
*   性能随着训练数据的数量级线性增加。即使在 3 亿张图像上，也没有观察到饱和。
*   能力至关重要。为了适应数据的复杂性，需要大而深的网络。对于 ResNet-50，COCO 对象检测基准的增益(1.87%)比使用 ResNet-152 时的增益(3%)小得多(见图 [11-1](#Fig1) )。

### 注意

注意机制对于文本、图像注释和视频处理非常关键，因为它们允许您通过学习输入图层应关注的位置的掩码来处理可变(潜在的无限)大小的输入。注意机制主要用于文本或文本和图像的组合(如视觉 V&A)，有 CNN 和 LSTM。“注意力是你所需要的全部”( [`https://arxiv.org/abs/1706.03762`](https://arxiv.org/abs/1706.03762) )这篇论文描述了作者如何用一种完全依赖注意力的机制(变压器)来取代 RNN，以绘制输入和输出之间的全局依赖关系。他们减少了进入网络的离散成分的数量，将典型的递归和卷积映射层替换为使用注意力的映射层。“作者表示，我们计划将转换器扩展到涉及文本以外的输入和输出模式的问题，并研究局部、受限的注意力机制，以有效处理大量输入和输出，如图像、音频和视频。我们的另一个研究目标是让世代变得不那么连续。”

关于如何使用 Keras 在 CNN 中实现注意机制的简单示例，请参见 [`www.danvatterott.com/blog/2016/09/20/attention-in-a-convolutional-neural-net/`](http://www.danvatterott.com/blog/2016/09/20/attention-in-a-convolutional-neural-net/) 。

### 11.1.2 多模式学习

多模态学习，即从多个来源(文本、图像、视频等)学习的能力。)，是一个活跃的研究领域，在未来仍将如此。

能够将结构化和非结构化信息聚合在一个统一的分布式表示中会产生一个强大的框架，并使我们离解决符号基础问题更近了一步。例如，根据[ARDK16]，仅给定三元组(问题、世界、答案)作为训练数据，模型学习从神经模型的库存中组装神经网络，并同时学习这些模块的权重，以便它们可以组成新的结构。他们将组合问答方法扩展到复杂、连续的世界表示，如图像。换句话说，他们用动态的网络拓扑取代了固定的网络拓扑，从而适应了为每个问题执行的计算，使用更复杂的网络来解决更困难的问题，这对小数据集非常有效。

Quoc Le 等人( [`https://arxiv.org/abs/1511.04834`](https://arxiv.org/abs/1511.04834) )的梯度下降工作也有很多破坏性的潜力，因为它允许神经网络学习创建新的程序。这种方法代表了我们构思计算机编程方式的一种范式转变，从离散的离散/符号方法到完全可微的连续替代方法。

麻省理工学院最近的一篇论文( [`http://people.csail.mit.edu/yusuf/see-hear-read/paper.pdf`](http://people.csail.mit.edu/yusuf/see-hear-read/paper.pdf) )结合了声音、图像和文本，采用了一种有趣的方法，并在使用跨模态数据对对象和实体进行分类方面产生了令人印象深刻的结果。

谷歌发表了一篇名为“一个模型来了解所有人”( [`https://arxiv.org/pdf/1706.05137.pdf`](https://arxiv.org/pdf/1706.05137.pdf) )的论文，其中它对跨越多个领域的大量不同数据源使用了一个模型。该模型同时在 ImageNet、翻译任务、图像字幕、语音识别和英语解析上被训练。该模型包含卷积层、注意机制和稀疏门控层。作者观察到，数据较少的任务在很大程度上受益于与其他任务的联合训练，而大型任务的表现仅略有下降。这项工作无疑使我们更接近一个能够解决任何任务的通用算法。

### 一次性学习

一次学习，或称零次学习，也是一个令人兴奋的研究领域。在 DeepMind ( [`https://arxiv.org/abs/1605.06065`](https://arxiv.org/abs/1605.06065) )最近的一项工作中，该团队试图捕捉人类遇到新概念(用一个或几个例子)的能力，并进行归纳，以创建概念的新版本。核心解决方案是一种描述概率过程的方法，通过该方法可以生成观察到的数据点(例如，手写的“8”)。作者使用深度神经网络来指定这一概率过程，并表明他们的模型能够从少量观察中生成书面字符和人脸。

对于机器来说，一次性学习是一项特别复杂的任务，而对于人类来说却是一项微不足道的任务。问题在于，DL 模型通常依赖于基于梯度的优化来调整网络中每个神经元的权重，这需要大量数据和通过网络的迭代。

在“用记忆增强神经网络进行一次性学习”( [`https://arxiv.org/abs/1605.06065`](https://arxiv.org/abs/1605.06065) )的论文中，谷歌 DeepMind 开发了一种能够通过从少量数据中得出有效推论来学习新行为的网络。作者使用了两层学习(元学习)方法，并表明具有记忆的神经网络能够将元学习应用于 Omniglot 分类任务(1600 个类，每个类只有几个例子)。该网络比最先进的网络表现更好，甚至可以超过人类。它通过慢慢学习原始数据的有用表示来做到这一点，然后使用外部存储器来快速绑定新信息。

学习 CNN 中的大量参数需要非常大的训练数据集。几个作者，像蒂莫西·霍斯佩达莱斯( [`www.eecs.qmul.ac.uk/tmh/`](http://www.eecs.qmul.ac.uk/tmh/) )，已经致力于广泛的研究工作，致力于被称为零射击学习的技术。在最近的一项工作( [`https://arxiv.org/abs/1603.06470`](https://arxiv.org/abs/1603.06470) )中，作者使用 CNN 进行人脸识别，使用一种人脸合成方法，交换不同人脸图像的面部成分以生成新的人脸。他们在野外(LFW)和 CASIA NIR-VIS2.0 的线性人脸数据集上实现了最先进的人脸识别性能。在未来，您将把这项技术应用到更多的人脸分析应用中。

在论文“一次性模仿学习”( [`https://arxiv.org/pdf/1703.07326.pdf`](https://arxiv.org/pdf/1703.07326.pdf) )中，作者提出了一种新的模仿学习方法，从很少的演示中学习，并能够在相同的上下文中推广到新的情况。他们的元学习框架使用神经网络，该神经网络将一个演示和当前状态作为输入，并输出一个动作，目标是状态和动作的结果序列尽可能与第二个演示匹配；`http://bit.ly/one-shot-imitation`见。

在斯坦福大学一个小组最近的工作( [`https://arxiv.org/pdf/1611.03199.pdf`](https://arxiv.org/pdf/1611.03199.pdf) )中，作者探索了一套在大量训练数据不可用时扩展 DL 适用性的技术。他们展示了如何使用一次性学习来显著降低在药物发现应用中进行有意义的预测所需的数据量。他们使用了一种名为残差 LSTM 嵌入的架构，当与图形卷积神经网络结合时，可以显著提高在小分子上学习有意义的距离度量的能力。他们的模型在一个名为 DeepChem ( [`http://deepchem.io/`](http://deepchem.io/) )的库中开源。

### 强化学习和推理

大多数积极的强化学习研究都与具有共享模型的代理学习环境有关，或者与同一环境中的相互交互和学习有关，例如学习在迷宫或城市街道等 3D 环境中自主驾驶。反向强化是从观察到的行为中学习任务的目标(例如，学习驾驶或赋予非玩家视频游戏角色类似人类的行为)。

在最近的工作“分层深度强化学习:整合时态抽象和内在动机 Deep mind”([`http://arxiv.org/pdf/1604.06057.pdf`](http://arxiv.org/pdf/1604.06057.pdf))中，作者利用好奇心驱动代理在具有挑战性的雅达利游戏 Montezuma Revenge 中取得了一些成功。

Q 学习之外的无模型学习方法也非常活跃，在 [`https://github.com/karpathy/paper-notes/blob/master/vin.md`](https://github.com/karpathy/paper-notes/blob/master/vin.md) 有描述。

最近的一项工作( [`https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5299026/`](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5299026/) )表明，使用 CNN 和 RNNs 的编码模型可以用于预测大脑对感官刺激的反应，从而模拟感官信息在大脑中的表达方式。他们研究了循环神经网络模型的合理性，以“表示内部记忆，并对任意特征序列进行非线性处理，以预测功能性磁共振成像测量的特征诱发反应序列”，发现它们远远优于岭回归模型。

Sergey Levine 在 [`https://www.youtube.com/watch?v=eKaYnXQUb2g`](https://www.youtube.com/watch?v=eKaYnXQUb2g) 的视频是一个很好的资源，有助于理解 DL 在控制理论方面的理论和改进，并总结了一些最新成果。

dnn 的一个缺点是它们很难明确地提取层次结构，就像在图形贝叶斯模型中一样。人工神经网络从图像和文本等非结构化数据中进行复杂的预测，但几乎没有可解释的结构。用于图像理解的结构化模型很难具有足够的表达能力来捕捉数据的复杂性，并且易于进行易处理的推理。

Hinton 最近的一项工作显示了如何通过结合结构化和非结构化学习来克服这些困难，超越其他非结构化的深度生成方法，如 VAEs，这些方法不容易解释[EHW <sup>+</sup> 16]。结构化生成方法在很大程度上与深度学习不兼容，因此推理既困难又缓慢(例如，通过 MCMC)。Hinton 使用结构化概率模型和深度网络的混合，通过学习和摊销推理进行场景解释。该模型通过适当的部分或全部指定的生成模型，而不是来自标签的监督，在它的表示上强加结构； [`www.cs.toronto.edu/%20hinton/absps/AttendInferRepeat.pdf`见](http://www.cs.toronto.edu/%20hinton/absps/AttendInferRepeat.pdf)。所提出的框架关键地允许对给定场景的复杂性(其潜在空间的维度)进行推理。

关系推理是 GAI 的核心组成部分，但已经证明很难用人工神经网络来解决。最近 Google 提出了一个项目来处理关系推理的难题。其作品( [`https://arxiv.org/abs/1706.01427`](https://arxiv.org/abs/1706.01427) )提出了一个有趣的解决方案。谷歌在三个任务上测试了一个模型:在一个名为 CLEVR 的数据集上进行视觉问答(VQA)，达到了最先进(超人)的性能；使用 bAbI 任务集的基于文本的问题回答；和关于动态物理系统的复杂推理。Google 证明了卷积网络不具有解决关系问题的一般能力，但是当用关系网络扩充时可以获得这种能力。

在最近的两篇论文( [`https://deepmind.com/blog/agents-imagine-and-plan/`](https://deepmind.com/blog/agents-imagine-and-plan/) )中，DeepMind 描述了一系列新的基于想象的规划方法。它还介绍了为代理学习和构建计划提供新方法的体系结构，以最大化任务的效率。这些架构是高效的，对复杂的和不完美的模型是健壮的，并且它们可以采用灵活的策略来开发它们的想象力。他们引入的代理受益于“想象力编码器”，这是一种神经网络，它学习提取任何对代理未来决策有用的信息，但忽略不相关的信息。DeepMind 在多个任务上测试了所提出的架构，包括益智游戏推箱子和宇宙飞船导航游戏。

### 11.1.5 生成神经网络

虽然不是新的，生成神经网络(GNNs)正在成为一个活跃的研究领域。深度生成模型是一种强大的无监督和半监督学习方法，其目标是在不依赖外部标签的情况下发现数据中的隐藏结构。

生成模型在概率密度估计、图像去噪和修复、数据压缩、场景理解、表示学习、3D 场景构建、半监督分类和分级控制中具有应用。

有三种主要类型的生成模型:完全观察模型、潜在变量模型和转换模型。每一个都有特定的推理机制。这些算法包括自回归分布估计器、变分自编码器和生成对抗网络。使用潜在变量的深度生成模型的例子包括深度信念网络、变分自编码器以及无记忆和摊销推理。

原则上，生成模型比判别模型具有更丰富的解释能力。

*   它们能够表示数据中潜在的(隐藏的)结构及其不变量，例如，光强、旋转、亮度或 3D 对象布局的概念。
*   他们可以把世界想象成“它可能是”的样子，而不是“它所呈现的样子”
*   它们能够表达的不仅仅是输入和输出之间的简单联系。
*   他们可以在数据中发现令人惊讶但似乎可信的事件。

生成模型可用于插补，例如，图像嵌入(遮挡、补丁移除)、3D 生成、一次性学习和表示学习(用于控制)。

所有的生成网络都共享使用潜在变量来表示观察到的数据的思想，并且它们在不久的将来将继续非常相关。

### 11.1.6 生成对抗性神经网络

生成对抗性神经网络是一个活跃的研究领域。有关 GANs 的有趣应用列表，请参见位于 [`https://github.com/nashory/gans-awesome-applications`](https://github.com/nashory/gans-awesome-applications) 的资源库。

gan 对于风格转换和用作生成模型特别有用。另一个优点是，他们可以通过避免计算配分函数中的归一化因子来估计概率密度。

使用 GANs，可以做到以下几点:

*   模拟训练数据
*   处理丢失的数据(图像修复、半监督学习)
*   为一个输入提供多个正确答案
*   生成逼真的图像
*   通过预测进行模拟
*   解决困难的推理问题
*   学习有用的嵌入
*   控制潜在空间来表示插值(姿势，年龄等。)

这些模型的缺点是不稳定，难以训练。OpenAI 发表了一篇详细的博客文章，介绍了一些技巧，如何解决训练 GANs 的一些问题，使它们在图像生成方面更加稳定。作者为 GANs 提出了新的架构特征和训练程序，包括半监督学习和人类现实图像的生成。他们用其他目标训练模型，而不是给测试数据分配高可能性，或者在没有标记数据的情况下学习得很好。他们在 MNIST、CIFAR-10 和 SVHN 上实现了半监督分类的最新成果。该模型生成了人类无法从真实数据中区分的 MNIST 样本，并生成了 CIFAR-10 样本，其人为错误率为 21.3%。

像 Photoshop 这样以创意为导向的应用程序有可能让艺术家仅根据高层次的描述就能变出照片。例如，艺术家可以要求应用程序绘制一个有现代家具、大窗户、午后阳光和两个孩子的卧室。一个生成网络，已经在卧室照片和室内装饰杂志的大型语料库上训练过，将能够在几秒钟内创建这样的图片。在检查完第一次渲染后，艺术家可以要求更大的窗户，墙上不同颜色的油漆，等等。因为神经网络理解不同抽象层的图像，在对象级别，它们有能力进行这些改变并实现完整的工作流。

Hyland 等人提出了一种用于生成实值医学时间序列生成的 GAN，采用递归条件 GAN([`https://arxiv.org/pdf/1706.02633.pdf`](https://arxiv.org/pdf/1706.02633.pdf))。这是一种有趣的方法，因为由于监管问题，医疗数据很难获得。

GAN 方法是强大的，因为它适用于难以评估可能性或梯度的模型；所需要的只是一个生成过程，给定一个随机种子，生成一个样本数据对象。具体而言，GAN 方法避免了例如期望最大化算法中所需的计算成本高的推断步骤。Arakaki 和 Barello capture([`https://arxiv.org/pdf/1707.04582.pdf`](https://arxiv.org/pdf/1707.04582.pdf))最近的一项工作使用 GANs 来拟合生物神经元网络的选择性响应的参数，从而避免建立具有预定义可能性和先验的显式推理模型。

### 11.1.7 知识转移和学会学习

从几个例子中学习并能够快速归纳是人类智力最臭名昭著的特征之一。任何人工智能代理都应该能够从少数几个例子中快速学习和适应，并且应该随着更多例子的出现而继续适应。这种快速灵活的学习是具有挑战性的，因为代理必须将其先前的经验与少量的新信息相结合，同时避免过度适应新数据。此外，先前经验和新数据的形式将取决于任务。因此，为了获得最大的适用性，学习的机制(或元学习)应该对任务和完成任务所需的计算形式通用。

Finn 等人提出了一种非常高效的元学习算法，能够从先前训练好的网络中快速适应新的任务( [`https://arxiv.org/pdf/1703.03400.pdf`](https://arxiv.org/pdf/1703.03400.pdf) )。例如，一个被训练行走的机器人可以很快被重新训练奔跑。

一些有前途的新算法，如由 Lake、Salakhutdinov 和 Tenenbaum [LST15]提出的算法，将有助于解决 DNNs 的一个有问题的方面，即它们很难从几个例子中学习和转移知识，以便它们可以仅基于几个观察结果来合并新知识。作者称之为贝叶斯程序学习(BPL)框架，它通过使用潜在的概念为每个类生成一个独特的程序来工作。该软件不仅能够模仿儿童获得读写能力的方式，还能够模仿已经知道如何识别并重建手写字符的成年人的方式。

Long 等人[LCWJ15]还提出了一种有趣的架构来处理知识转移，称为深度适应网络(d an)，它通过显式减少域差异来增强深度神经网络的任务特定层中的特征转移能力，从而将 CNN 推广到域适应场景。所有任务特定层的隐藏表示被嵌入到再生核希尔伯特空间中，在该空间中不同域分布的平均嵌入可以被显式匹配。他们在 KT 中从不同来源的图像中获得了最先进的结果。

Esmali 等人[EHW <sup>+</sup> 16]最近提出了一种通过潜在空间的变分推理来捕获层次结构图像的方案。他们将推理视为一个迭代过程，实现为一个循环神经网络，一次关注一个对象，并学会对每幅图像使用适当数量的推理步骤。这允许通过利用迭代来捕获可扩展的视觉表示，并且还可以通过实现递归推理网络来扩展，从而捕获潜在变量之间的后验相关性，例如考虑到场景的部分已经被解释的事实。

## 11.2 何时不使用深度学习

有时候，深度学习可能是一种障碍，而不是一种资产。DL 包含灵活的模型，具有多种架构和节点类型、优化器和正则化策略。根据应用的不同，模型可能有卷积层。(各层应该有多宽多深？过滤器的尺寸是多少，有多少个？池操作是最大值还是平均值？).或者它可能有一个循环结构。(是单向的还是双向的？是 LSTM 还是 GRU？)它可能很深，或者只有几个隐藏层。(它有几个单元？)它可以使用校正线性单元或其他激活功能。它可能有也可能没有辍学。(在哪几层？用几分？).权重可能应该被正则化(l1、l2 或其他)。应该应用什么损失函数？

这只是部分列表；还有许多其他细节可能会影响网络的性能(正则化、传递函数、损失函数、优化器)，还有许多超参数需要调整，还有许多架构需要探索。谷歌最近吹嘘说，它的 AutoML 管道可以自动找到最佳架构，这令人印象深刻，但它仍然需要 800 多个 GPU 全天候运转数周，这几乎是其他任何人都无法企及的。关键是训练深度网络在计算和调试时间上都需要很大的成本。这样的花费对于许多日常的预测问题和对它们调整深网的投资回报率来说是没有意义的。

即使有足够的预算和承诺，也没有理由不首先尝试替代方法，即使是作为基线。您可能会惊喜地发现，SVM 或 XGBoost 正是您所需要的。

## 11.3 新闻

本节重点介绍人工智能领域的一些新闻和重要发展。

*   OpenAI 最近的一篇博客文章( [`https://blog.openai.com/deep-reinforcement-learning-from-human-preferences/`](https://blog.openai.com/deep-reinforcement-learning-from-human-preferences/) )介绍了一种学习算法，它使用少量的人类反馈在复杂的 RL 环境中导航。该算法需要来自人类评估者的 900 位反馈来学习后空翻——这是一项看似简单的任务，很容易判断，但很难指定。
*   参见 [`https://medium.com/@pavelkordik/recent-developments-in-artificial-intelligence-b64286daa06b`](https://medium.com/@pavelkordik/recent-developments-in-artificial-intelligence-b64286daa06b) 的博客文章，获得关于 DL 最新发展的精彩教程。
*   超分辨率图像处理是一个新的研究领域。Ledig 等人提出了一种基于 GAN 的技术( [`https://arxiv.org/abs/1609.04802`](https://arxiv.org/abs/1609.04802) )，称为超分辨率(SRGAN)，用于实现 4 倍放大因子的真实感自然图像。
*   还是在图像超分辨率方面，Dahl 等人提出了( [`https://arxiv.org/abs/1702.00783`](https://arxiv.org/abs/1702.00783) )像素递归超分辨率模型，在增强图像分辨率的同时，将逼真的细节合成到图像中。使用 PixelCNN 架构，该模型能够通过对低分辨率输入条件下的高分辨率图像像素之间的统计依赖性进行建模来表示多模态条件分布。
*   有几种最近的图像修复技术，这意味着填充从图像中隐藏的片段。例如，参见“使用 DCGAN 进行感知和上下文损失的图像修复:深度卷积生成对抗网络”( [`http://arxiv.org/pdf/1607.07539v1.pdf`](http://arxiv.org/pdf/1607.07539v1.pdf) )。
*   如前所述，DL 机器本质上是黑盒。最近的工作“我为什么应该相信你”( [`https://arxiv.org/abs/1602.04938`](https://arxiv.org/abs/1602.04938) )是一篇非常有趣的论文，它使 DL 机器在从数据中学习到的特征方面更加可解释和透明。参见 [`www.myaooo.com/wp-content/uploads/2017/08/understanding-hidden-memories-camera.pdf`](http://www.myaooo.com/wp-content/uploads/2017/08/understanding-hidden-memories-camera.pdf) 关于如何让 LSTM 变得可译。
*   深度学习也被应用于事件时空数据[DDT<sup>+</sup>16]；亦见 [`https://www.mpi-sws.org/manuelgr/pubs/rmtpp.pdf`](https://www.mpi-sws.org/manuelgr/pubs/rmtpp.pdf) 。根据观察到的事件序列，作者可以预测未来的事件。准确估计临床事件可能发生的时间可以有效地促进针对患者的护理和预防，以降低潜在的未来风险。另见本作关于时空预测: [`https://arxiv.org/pdf/1706.06279.pdf`](https://arxiv.org/pdf/1706.06279.pdf) 。

## 11.4 人工智能在社会中的伦理和影响

随着计算机算法变得越来越复杂，机器开始做出更复杂、影响更大的决定——最终是生死攸关的决定——一些严重的伦理问题将不可避免地出现。例如，如果算法提出的医疗方法出错，或者自动驾驶汽车为了救司机而撞向一群行人，谁应该对这些决定负责？

最大的问题是，软件的复杂性通常意味着不可能准确地找出一个人工智能系统做它所做的事情的原因。微软 Twitter 机器人 Tay 最近的实验展示了善意的技术如何通过与人类的互动而被扭曲。Tay 被设计成从与 Twitter 用户的互动中学习。在中国，这个实验最早启动的地方，机器人是成功的。但是在美国，机器人变得性别歧视、种族歧视和排外( [`https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist`](https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist) )。探索机器人取悦用户的天真“行为”，他们很快利用这一弱点，有意说服机器人否认大屠杀之类的事情。这个实验透视了社会化的重要性和在机器人身上融入伦理的困难。

最近成立了一个新的谷歌研究小组，研究人们如何与人工智能互动，称为“人+人工智能研究倡议”(PAIR)。该小组的目标是让人们更容易与人工智能系统互动，并确保这些系统不会显示偏见或迟钝到没有帮助的地步。PAIR 将汇集人工智能研究人员和工程师；领域专家，如设计师、医生和农民；和日常用户。您可以在 [`https://www.blog.google/topics/machine-learning/pair-people-ai-research-initiative/`](https://www.blog.google/topics/machine-learning/pair-people-ai-research-initiative/) 找到更多关于该集团的信息。

DeepMind 创建了 DeepMind 伦理与社会( [`https://deepmind.com/applied/deepmind-ethics-society/`](https://deepmind.com/applied/deepmind-ethics-society/) )来解决人工智能在社会中的影响。它在博客上写道，“技术不是价值中立的，技术专家必须对他们工作的道德和社会影响负责。在人工智能这样一个复杂的领域，说起来容易做起来难，这就是为什么我们致力于深入研究道德和社会问题，包容许多声音，并持续进行批判性反思。”

以下是其他一些值得注意的资源:

*   中国正在使用图像和语音识别技术来代替卡从自动取款机中取钱； [`www.scmp.com/news/china/money-wealth/article/1813322/china-develops-cash-machines-facial-recognition-feature-curb`见](http://www.scmp.com/news/china/money-wealth/article/1813322/china-develops-cash-machines-facial-recognition-feature-curb)。
*   在 [`www.wired.co.uk/article/creating-transparent-ai-algorithms-machine-learning`](http://www.wired.co.uk/article/creating-transparent-ai-algorithms-machine-learning) 的这篇文章探讨了算法责任的概念，以及算法是否能够摆脱人类偏见。
*   尼克·博斯特罗姆发表了一篇题为“开放在人工智能发展中的战略意义”( [`www.nickbostrom.com/papers/openness.pdf`](http://www.nickbostrom.com/papers/openness.pdf) )的工作论文，对保持人工智能开源的重要性进行了一些思考。
*   高调研究自动驾驶汽车社会困境的作者们发布了道德机器( [`http://moralmachine.mit.edu/`](http://moralmachine.mit.edu/) )。该平台将众包人类对机器在面临道德困境以及道德后果情景时应如何做出决定的意见。这个实验提出了一些棘手的问题。试试看！
*   最近出版的《数学毁灭的武器》( [`https://www.amazon.co.uk/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815`](https://www.amazon.co.uk/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815) )一书指出了机器学习和人工智能另一面的一些非常重要的问题。另见一本对人工智能在社会中的影响提出一些担忧的书:我们的最终发明。
*   关于算法偏见，凯特·克劳福德发起了“现在就开始人工智能”( [`https://artificialintelligencenow.com/`](https://artificialintelligencenow.com/) )倡议，这是一项跨学科的研究倡议，旨在了解人工智能的社会和经济影响。可能掩盖隐藏偏见的算法已经被常规用于做出重要的金融和法律决策。这些算法中的大多数都是专有的，不适合解释。例如，他们可以决定谁可以参加面试，谁可以获得假释( [`https://www.technologyreview.com/s/603763/how-to-upgrade-judges-with-machine-learning/`](https://www.technologyreview.com/s/603763/how-to-upgrade-judges-with-machine-learning/) )，谁可以获得贷款。
*   随着能够生成非常真实的内容、文本、图像甚至视频(例如，参见 [`https://www.youtube.com/watch?v=9Yq67CjDqvw%20list=PLTlqgr7kVS33DF-R5E9MsyVon9h_zCYgc%20index=3`](https://www.youtube.com/watch?v=9Yq67CjDqvw%20list=PLTlqgr7kVS33DF-R5E9MsyVon9h_zCYgc%20index=3) 的假视频)的更复杂的神经网络的出现，检测假内容变得非常困难。例如，芝加哥大学的研究人员已经训练了一个神经网络来生成令人信服的虚假餐厅评论。一些作者声称，假新闻在 2016 年美国大选中发挥了决定性因素。
*   社交媒体新闻是一把双刃剑。一方面，它成本低，容易获取，并能迅速传播信息。另一方面，它可以传播“假新闻”，或故意提供虚假信息的低质量新闻。假新闻的广泛传播有可能对个人和社会产生极其负面的影响。在最近的一份出版物( [`https://arxiv.org/abs/1708.01967`](https://arxiv.org/abs/1708.01967) )中，作者回顾了社交媒体上假新闻的检测方法。

人工智能的一个主要含义是，它将使区分真实内容和生成内容(虚假内容)变得更加困难。在最近的一项工作( [`http://grail.cs.washington.edu/projects/AudioToObama/siggraph17_obama.pdf`](http://grail.cs.washington.edu/projects/AudioToObama/siggraph17_obama.pdf) )中，来自华盛顿大学的一个团队开发了一种能够生成一个人的逼真视频的算法。他们应用了一个循环神经网络，这个网络是根据巴拉克·奥巴马的每周讲话片段训练出来的。然后，他们使用这个网络生成具有令人印象深刻的质量的虚假内容的真实视频，这对人类来说是非常难以区分的。与之前的工作不同，他们不需要扫描主题或语音数据库来包含许多人说预定句子的视频。一切都是从现有的镜头中学来的。`https://www.youtube.com/watch?v=MVBe6_o4cMI`见。

## 11.5 人工智能中的隐私和公共政策

随着神经网络在图像处理方面达到人类水平的精确度，在隐私方面将产生严重的影响。例如，当有可能从无处不在的摄像机中识别个人身份，让政府或公司能够跟踪街上的每个人时，我们可能比我们想象的更接近奥威尔式的反乌托邦。

为全球公司提供人力资源指导的 IBA 全球就业研究所(IBA Global Employment Institute)发布了一份关于人工智能对法律、经济和商业问题的影响的报告( [`https://drive.google.com/drive/folders/0Bxx383wVJ39Pb1p1eGhERTBGVDQ`](https://drive.google.com/drive/folders/0Bxx383wVJ39Pb1p1eGhERTBGVDQ) )，如未来劳动力市场、公司结构、工作时间、薪酬、工作环境、就业形式和劳资关系的变化。

2017 年 9 月，一份关于联合王国人工智能的独立报告( [`https://www.gov.uk/government/publications/growing-the-artificial-intelligence-industry-in-the-uk/recommendations-of-the-review`](https://www.gov.uk/government/publications/growing-the-artificial-intelligence-industry-in-the-uk/recommendations-of-the-review) )发表，为政府提供建议。该报告建议通过建立数据信托来促进数据共享，使用公共资金进行数据创建和共享，并为 ML 创建 300 个新的硕士学位和 200 个博士学位项目(到 2025 年增加到 1600 个博士学位)，以及其他举措。它指出，研究和商业化是英国科技行业的巨大机遇。人工智能可以将 2035 年 GVA 的年增长率从 2.5%提高到 3.9%。

微软首席执行官塞特亚·纳德拉概述了他开发人工智能愿景的三个关键原则:增强人类的能力和经验，而不是取代我们；通过解决隐私、透明和安全问题来赢得用户的信任；技术应该包容并尊重所有用户。然而，特斯拉首席执行官埃隆马斯克(Elon Musk)等其他人提出了对人工智能进行监管的必要性的问题，认为人工智能有失控的风险。

迈尔斯·布伦戴奇发表了一份详尽的文件，名为“人工智能政策和战略工作指南”( [`https://80000hours.org/articles/ai-policy-guide/`](https://80000hours.org/articles/ai-policy-guide/) )。他表示，“我们迫切需要人工智能政策和战略问题的答案，因为 I)实施解决方案可能需要很长时间，ii)当人工智能不太先进，对该主题的观点/兴趣较少时，一些问题会得到更好的解决，iii)我们不知道特定的人工智能能力何时会得到发展，并且不能排除令人惊讶的突然进步的可能性。”

## 11.6 初创公司和风险投资

DL 对创业公司和投资者来说代表着一个巨大的机会。在《经济学人》( [`www.economist.com/news/special-report/21700761-after-many-false-starts-artificial-intelligence-has-taken-will-it-cause-mass`](http://www.economist.com/news/special-report/21700761-after-many-false-starts-artificial-intelligence-has-taken-will-it-cause-mass) )最近的一篇评论中，内森·贝奈希指出，“根据数据分析公司 Quid 的数据，2015 年在人工智能公司上花费了创纪录的 85 亿美元，几乎是 2010 年的四倍。2015 年人工智能公司的投资轮次比前一年增加了 16%，而整个科技行业的投资轮次下降了 3%。”

人工智能创业公司的资金在 2017 年继续上升趋势，投资创下新高；参见 [`https://techcrunch.com/2017/07/11/inside-the-q2-2017-global-venture-capital-ecosystem/`](https://techcrunch.com/2017/07/11/inside-the-q2-2017-global-venture-capital-ecosystem/) (参见图 [11-2](#Fig2) )。根据 CrunchBase 的数据，2017 年上半年，风险投资者、企业投资者和种子投资者已向人工智能和机器学习公司投入了约 36 亿美元。这超过了他们在 2016 年全年的投资，标志着可比时期内向该领域投入的最大金额。

![A454512_1_En_11_Fig2_HTML.jpg](img/A454512_1_En_11_Fig2_HTML.jpg)

图 11-2

Investment in AI from 2014 to mid-2017 (source: CrunchBase [`https://techcrunch.com/2017/07/15/vcs-determined-to-replace-your-job-keep-ais-funding-surge-rolling-in-q2/`](https://techcrunch.com/2017/07/15/vcs-determined-to-replace-your-job-keep-ais-funding-surge-rolling-in-q2/) )

根据 CrunchBase 的报告，人工智能初创公司的股权交易——包括将人工智能解决方案应用于医疗保健、广告和金融等垂直领域的公司以及开发通用人工智能技术的公司——增加了近 6 倍，从 2011 年的约 70 起增加到 2015 年的近 400 起(见图 [11-3](#Fig3) )。

2014 年，使用人工智能的初创公司获得的资金每年增长 65%，这是由 Avant、销售初创公司 InsideSales.com、医疗诊断公司 Butterfly Network 和深度学习初创公司 Sentient Technologies 筹集的四轮超过 1 亿美元的资金推动的。

![A454512_1_En_11_Fig3_HTML.jpg](img/A454512_1_En_11_Fig3_HTML.jpg)

图 11-3

Investment in AI-based startups (source: CrunchBase Insights)

Element.ai 获得 1.02 亿美元 A 轮融资；投资者包括微软、英伟达和英特尔投资，它们都有自己的人工智能雄心。该公司希望通过易于部署的解决方案，将人工智能的访问民主化。

谷歌最近推出了 Gradient Ventures ( [`https://gradient.google/`](https://gradient.google/) )来投资人工智能初创公司。Gradient Ventures 将在 2018 年投资 10 至 15 笔交易，通常每笔交易将投入 100 万至 800 万美元。投资组合公司将有机会获得谷歌的高级人工智能培训和工程帮助。

根据 CrunchBase Insights 的数据，医疗保健是深度学习的领先工业应用，自 2012 年以来，通过 270 笔交易筹集了 18 亿美元。根据市场研究公司 Tractica 的数据，仅医疗保健领域的医学图像分析年收入就将从 2016 年的不到 10 万美元增加到 2025 年的 15 亿美元。

## 11.7 未来

真正的基础技术——如蒸汽机、电力、晶体管或互联网——对世界有着巨大的影响，因为它们创造了新的产业、产品和流程。

深度学习是自互联网以来出现的最重要的基础技术之一。在短短几年内，它已经从学术界走向生产，为全球数十亿人使用的视觉、语音、机器人、医疗保健和各种服务提供动力。根据 ARK Research 的数据，基于深度学习的公司可以在未来 20 年创造超过 17 万亿美元的新市值。

尽管深度学习在 2017 年只有五年的历史，但它在用例、创业公司形成、市场采用和收入方面的增长速度惊人。尽管迄今为止取得了进展，但记忆网络和生成网络等新功能可能会使深度学习更加强大，可能会为人工通用智能提供一座桥梁。在这种情况下，深度学习甚至可以让互联网看起来很小。

人工智能驱动的自动化对社会的影响将是巨大的，因为它可以取代整个行业的活动。例如，仅在美国就有大约 400 万卡车司机面临着他们的工作被自动驾驶卡车取代的风险。

这不仅适用于低技能职业，也适用于高技能职业。全科医生也面临风险，因为机器很快将与病理学家和放射学家竞争。个人助理可能很快会提供比普通家庭医生更准确的诊断。尽管机器还不能进行对话，但目前的技术已经可以接受自然语言的指令，在不久的将来可能会完全对话。

随着大数据、先进的学习算法以及快速 GPU 和 TPU 的结合，深度学习的未来就像你想象的那样光明。在社会上的影响将是巨大的，很多行业将被束缚在基金会上。

以下是数字图书馆未来研究的一些领域。

尽管今天的 DL 在诊断骨折、肺癌或皮肤癌方面可以胜过医生，但是当呈现非常不典型的数据(拐角病例)时，以及当整合不同来源的数据时，这些模型仍然会失败，从而对于看不见的病例给出不准确的结果。此外，CNN 很容易成为敌对例子的目标，这使得它们非常脆弱。需要进一步的研究来弥合这些差距，并整合更多的数据(如基因组学)，以便这些算法发挥其潜力。

为了解码生命机制，遗传学研究仍然需要弥合“基因型-表型鸿沟”。基因组和表型数据丰富。不幸的是，有意义地连接这些数据的现有技术导致了缓慢、昂贵和不准确的过程。为了闭合回路，你需要能够确定称为分子表型的中间表型的系统，分子表型作为从基因型到疾病表型的垫脚石。为此，机器学习必不可少。

CNN 在图像识别任务、分割和对象检测方面已经达到了人类水平的精度。然而，尽管取得了所有的进步，但在能效方面，ANN 仍然远远低于人类大脑(大脑仅消耗 20 瓦，而单个 Titan-X GPU 消耗 200 瓦)。尽管谷歌 TPU 处理器致力于深度学习，但更有效的计算硬件肯定是必要的。

注意机制以及信息反馈循环(自上而下和自下而上)也是一个有前途的途径。有一些受人类视觉系统启发的有趣想法，比如 CortexNet ( [`https://arxiv.org/abs/1706.02735`](https://arxiv.org/abs/1706.02735) )和 Feedbacknet ( [`http://feedbacknet.stanford.edu/`](http://feedbacknet.stanford.edu/) )。这些模型不仅是自下而上的前馈连接，而且还模拟了人类视觉皮层中存在的自上而下的反馈和横向连接。

人工神经网络仍在努力理解人类认为理所当然的东西:常识。我们没有意识到教一台机器发展理解对人类来说非常容易的简单场景的能力有多难，例如重力总是将物体向下推，因此水向下流。

这个问题的解决方案就是更多的数据。为了克服这个困难，最近创建了一个用于对世界进行类似人类视觉理解的大型库( [`https://medium.com/twentybn/learning-about-the-world-through-video-4db73785ac02`](https://medium.com/twentybn/learning-about-the-world-through-video-4db73785ac02) )。它包含两个视频数据集，包含 256，591 个带标签的视频，以教授机器视觉常识。第一个数据集允许机器对物理世界中发生的基本行为进行细粒度的理解。动态手势的第二个数据集实现了人机交互的鲁棒认知模型。

递归网络明显优于前馈模型。更有效的训练方法(包括不可微模型)是研究的重要途径。进化算法是一个有前途的途径。

### 11.7.1 用较少的数据学习

DL 需要数据密集型算法，需要很多人工标注。如果没有该物种的图像，对猫和狗进行分类的人工智能算法将无法识别稀有的狗物种。

另一个主要挑战是增量数据。在这个例子中，如果你试图识别猫和狗，当你第一次部署时，你可以用不同物种的猫和狗的图像来训练你的 AI。虽然新物种可能与其他物种更相似，但这可能需要完全的重新训练和重新评估。你能让人工神经网络更适应这些小变化吗？

### 迁移学习

在迁移学习中，学习是在同一算法中从一个任务转移到另一个任务。在具有较大数据集的一个任务(源任务)上训练的算法可以在修改或不修改的情况下被转移，作为试图在(相对)较小数据集上学习不同任务(目标任务)的算法的一部分。

使用图像分类算法的参数作为不同任务(例如对象检测)中的特征提取器是迁移学习的简单应用。相比之下，它也可以用来执行复杂的任务。谷歌开发的比医生更好地对糖尿病视网膜病变进行分类的算法是利用转移学习制成的。

### 多任务学习

在多任务学习中，多个学习任务同时被解决，同时利用跨领域的共性和差异。有时一起学习两个或更多的任务(也称为多模态学习)可以提高精确度。

在现实应用中看到的多任务学习的一个重要方面是，当训练任何任务变得防弹时，你需要尊重来自许多领域的数据(也称为领域适应)。猫狗用例中的一个例子是一种可以识别不同来源图像的算法(比如 VGA 摄像机和高清摄像机，甚至是红外摄像机)。在这种情况下，可以将域分类的辅助损失(图像来自哪里)添加到任何任务中，然后机器进行学习，使得算法在主任务(将图像分类为猫或狗图像)中变得越来越好，但在辅助任务中故意变得越来越差(这是通过从域分类任务反向传播反向误差梯度来实现的)。其思想是，算法学习主要任务的区别特征，但忘记区分域的特征。

### 对抗式学习

对抗性学习作为一个领域是从伊恩·古德费勒的研究工作发展而来的。对抗学习最流行的应用是生成对抗网络(GANs ),它可以用来生成高质量的图像；不过，还有其他应用。

使用 GAN 损耗可以使域适应游戏变得更好。这里的辅助损失是 GAN 系统而不是纯域分类，其中鉴别器试图对数据来自哪个域进行分类，而生成器组件试图通过将随机噪声呈现为数据来欺骗它。这比简单的领域适配(也比代码更不稳定)更有效。

### 少量学习

少镜头学习是一种技术研究，与传统算法相比，它可以使深度学习算法(或任何机器学习算法)用更少的例子进行学习。一次性学习基本上是用一个类别的例子来学习；归纳起来，k-shot 学习就是用每个类别的 k 个例子进行学习。

少数镜头学习作为一个领域，在所有主要的深度学习会议上都有大量论文涌入，现在有特定的数据集来对结果进行基准测试，就像 MNIST 和 CIFAR 用于正常的机器学习一样。一次性学习在某些图像分类任务中有许多应用，例如特征检测和表示。

有多种方法可用于少量学习，包括迁移学习、多任务学习和元学习作为算法的全部或部分。还有其他方法，如使用巧妙的损失函数、使用动态架构或使用优化技巧。零距离学习使用一类算法，声称可以预测算法甚至没有见过的类别的答案；基本上，它们是可以随新型数据扩展的算法。

### 元学习

元学习最近已经成为深度学习中的一个活跃领域，最常见的是使用超参数和神经网络优化技术，寻找良好的网络架构，使用少量图像识别，以及使用快速强化学习。参考谷歌最近在 [`https://deepmind.com/blog/population-based-training-neural-networks/`](https://deepmind.com/blog/population-based-training-neural-networks/) 的作品。

这被称为用于决定参数和超参数(例如网络架构)的完全自动化。尽管围绕它们有各种宣传，但 metalearners 仍然是算法；换句话说，它们是利用日益复杂和多样的数据来扩展机器学习的途径。

### 神经推理

神经推理是模式识别之上的一步，其中算法正在超越简单识别和分类文本或图像的想法。神经推理是在文本分析或视觉分析中解决更一般的问题。

这套新技术出现在脸书的 bAbi 数据集或最近的 CLEVR 数据集发布之后。破译关系而不仅仅是模式的技术具有巨大的潜力，不仅可以解决神经推理，还可以解决包括少量学习问题在内的其他许多难题。

所有提到的技术都有助于以某种方式用较少的数据解决训练问题。虽然元学习会提供只是塑造数据的架构，但迁移学习是从其他领域获取知识，以弥补数据的减少。少杆学习致力于作为一门科学学科的问题。对抗性学习可以帮助增强数据集。

领域适应(一种多任务学习)、对抗学习和(有时)元学习架构有助于解决数据多样性带来的问题。元学习和少量学习有助于解决增量数据的问题。

神经推理算法在作为元学习者或少量学习者整合时，具有解决现实世界问题的巨大潜力。