# 3.深度神经网络模型

深度学习的概念起源于人工神经网络研究，其中前馈神经网络或具有许多隐藏层的多层感知器(MLPs)通常被称为深度神经网络(DNNs)。

MLP 网络通常由梯度下降算法训练，称为反向传播(BP)。BP 的思路很简单:对于每一组输入/输出，你将神经网络最后一层(输出层)的信号与数据中的真实输出进行比较；区别就是误差。由于您可以计算网络中从输入到输出的信号，因此您可以校正连接各层神经元的权重，以便在下一次迭代中减少误差。为此，通过与误差成比例的度量来更新权重。

对于训练深度网络，仅 BP 就有几个问题，包括非凸目标函数中的局部最优陷阱和消失梯度(当信息通过层反向传播时，输出信号呈指数下降)。为了理解这个问题是如何解决的，首先你将探索人工神经元网络(ann)的一些历史。

## 3.1 神经网络的简史

人工神经网络始于 McCullogh 和 Pitts 的一项工作，他们证明了简单单元(人工神经元)的集合可以执行所有可能的逻辑运算，因此能够进行通用计算。这项工作伴随着冯·诺依曼和图灵，他们首先处理了大脑信息处理的统计方面，以及如何建造一台能够复制它们的机器。Frank Rosembalt 发明了感知器机器来执行简单的模式分类。然而，这种新的学习机无法解决简单的问题，如逻辑异或。1969 年，明斯基和帕普特指出，感知机有无法超越的内在限制，因此对人工神经网络的热情逐渐消退。

1983 年，John Hopfield 提出了一种特殊类型的人工神经网络(Hopfield 网络),并证明它们具有强大的模式完成和记忆特性。

Linnainmaa，S. (1970)首先将反向传播算法描述为算法的累积舍入误差的表示(作为局部舍入误差的泰勒展开)，而不涉及神经网络。1985 年，鲁梅尔哈特、麦克莱兰和辛顿重新发现了这个强大的学习规则，允许他们用几个隐藏单元训练人工神经网络，从而超越了明斯克批评。

表 [3-1](#Tab1) 展示了神经网络发展的概况。

表 3-1

Some Milestones in Neural Networks

<colgroup><col align="left"> <col align="left"> <col align="left"></colgroup> 
| 年 | 捐助者 | 贡献 |
| :-- | :-- | :-- |
| One thousand nine hundred and forty-nine | 唐纳德希伯 | 希伯恩学习法则 |
| One thousand nine hundred and fifty-eight | 罗森布拉特 | 推出了第一台感知器 |
| One thousand nine hundred and sixty-five | 伊瓦赫年科和帕拉 | 介绍了 MLP 的前身——成组方法数据处理(GMDH) |
| One thousand nine hundred and seventy | 城堡的铁匠 | 提出了反向传播算法 |
| One thousand nine hundred and eighty | 拉高 | 自组织映射 |
|   | 福岛幸子 | 出版了新认知神经，CNN 的先驱 |
| One thousand nine hundred and eighty-two | 约翰·霍普菲尔德 | Hopfield 递归网络 |
| One thousand nine hundred and eighty-five | 辛顿和塞诺夫斯基 | 玻尔兹曼机器 |
| One thousand nine hundred and eighty-six | 鲁梅尔哈特和辛顿 | 推广反向传播训练 MLP |
| One thousand nine hundred and ninety | Yann LeCun 先生 | 介绍了 LeNet，展示了深度神经网络在实践中的可能性 |
| One thousand nine hundred and ninety-one | Sepp 高纯度 | 探讨了 BP 算法中的消失梯度和爆炸梯度问题 |
| One thousand nine hundred and ninety-seven | 舒斯特和帕利瓦尔 | 双向递归神经网络 |
|   | 更高的标准 | LSTM；解决了递归神经网络中梯度消失的问题 |
| Two thousand and six | 杰弗里·辛顿 | 深度信念网络；引入分层预训练，开启当前深度学习时代 |
| Two thousand and nine | 萨拉胡季诺夫和辛顿 | 深层玻尔兹曼机器 |
| Two thousand and twelve | 杰弗里·辛顿 | 一种训练神经网络的有效方法——辍学 |
| Two thousand and thirteen | 金玛和韦林 | 引入了变分自动编码器(VAE)，它可能会在深度学习和贝叶斯概率图形模型领域之间架起一座桥梁 |
| Two thousand and fourteen | Bahdanau 等人。 | 介绍注意力模型 |
|   | 伊恩·古德费勒 | 引入生成对抗网络 |
| Two thousand and fifteen | 斯里瓦斯塔瓦和施密德胡伯 | 介绍了高速公路网 |
|   | 他和其他人。 | 介绍了残差块和残差网络，这是目前视觉问题的最新进展 |
| Two thousand and sixteen | Wang 等人。 | 介绍了选择-加法网络，它可能在深度学习领域和因果推理领域之间架起一座桥梁 |
| Two thousand and seventeen | mnh 等人。 | 推出了 RL DNN、Q-learning 和 A3C |

### 3.1.1 多层感知器

多层感知器被提出来解决不可线性分离的问题。换句话说，你不能用一组直线来区分类别。图 [3-1](#Fig1) 显示了一个多层感知器的例子。

![A454512_1_En_3_Fig1_HTML.jpg](A454512_1_En_3_Fig1_HTML.jpg)

图 3-1

The MLP, with inputs, a hidden layer, and outputs. Training consists of finding the best weights, W and v, and bias.

人工神经网络包括一组输入，通过权重 w 连接到一组隐藏单元。隐藏单元通过权重 v 连接到输出。最初，所有权重和偏差项都设置为随机数。网络中的活动通过从输入层到隐藏层的权重向前传播，在隐藏层中计算网络激活的一些函数。通常传递函数是 sigmoid、tanh 或最近的整流线性单位(ReLU)。然后，活动通过更多的权重传播到输出神经元。

必须更新两组权重，即隐藏层和输出层之间的权重以及输入层和隐藏层之间的权重。由第一组权重引起的误差可以通过最小均方规则来计算。为了向后传播由于第二组权重(W)中的误差引起的那部分误差，通常使用反向传播算法。这简单地说明了误差应该与重量贡献成比例。该算法有两个主要参数:学习速率和动量(以避免陷入局部最小值)。此外，隐藏层中单位的数量是一个重要的输入(更多的隐藏单位将增加计算能力，但也可能损害泛化能力)。

网络参数的选择通常通过 k 重交叉验证来执行，固定 k-1 部分训练数据用于训练，剩余部分用于测试，然后交换这些段。

随机梯度下降(SGD)算法是一种用于加速神经网络训练的技术。与通过所有训练样本执行优化的梯度下降相反，在 SGD 中，仅使用训练样本的子集。SGD 收敛更快，因为它在每个时期只使用一小部分训练样本。

## 3.2 什么是深度神经网络？

人们早就知道，具有更多隐藏层(更深)的人工神经网络可能具有更高的计算能力，更适合解决分类或回归问题[AV03，YAP13，BLPL06]。挑战在于如何训练它们，换句话说，学习连接一层神经元和另一层神经元的权重或连接。反向传播算法对于具有单个隐藏层的 ann 工作良好，但是由于所谓的消失梯度问题，它努力推广到更深的体系结构。换句话说，输出端的校正信号在传输到较低层时会消散。

在 2006 年，Hinton 等人[GR06]提出了一种无监督学习算法，该算法使用了一种称为对比发散(CD)的方法，该方法成功地训练了称为深度信念网络(DBNs) [HOT06]的深度生成模型。CD 是一种逐层学习算法，如图 [3-2](#Fig2) 所示。它通常用于无监督的任务，但可以通过将 softmax 层附加到顶层来进行微调，以执行监督学习。

![A454512_1_En_3_Fig2_HTML.jpg](A454512_1_En_3_Fig2_HTML.jpg)

图 3-2

Contrastive divergence (CD) simulated as an MCMC process with k steps. CD–1 stops in stage 1 and ignores further iterations, as the input x is nicely reconstructed as x<sub>1.</sub>

有许多 DL 方法和架构，但大多数 dnn 可以分为五大类。

*   用于无监督学习的网络，旨在通过在相关类别可用时联合捕获统计分布来捕获数据的高阶相关性。贝叶斯规则可以在以后被用来创建一个有辨别能力的学习机器。
*   用于监督学习的网络，设计用于在分类问题中提供最大的辨别能力，并且仅使用标记数据进行训练。所有输出都应贴上标签。
*   混合或半监督网络，目标是使用生成(无监督)模型的输出对数据进行分类。通常，数据用于预先训练网络权重，以加速监督阶段之前的学习过程。图 [3-2](#Fig2) 显示，知道未标记数据 x 的结构，或者用统计学术语来说，知道分布 P(x ),可能比在标记数据中的纯监督学习更有效。
*   强化学习，代理交互并改变环境，只有在一组动作完成后才接收反馈。这种类型的学习通常用于机器人和游戏领域。
*   生成神经网络，其中深度生成模型是无监督和半监督学习的强大方法，目标是在不依赖标签的情况下发现数据中的隐藏结构。由于它们是可生成的，这样的模型可以形成一个丰富的使用它们的世界的图像。这种想象力可以用来探索数据的变化，推理世界的结构和行为，并最终做出决策。这些模型的一个很大的优点是不需要补充外部损失函数，因为它们自主地学习数据的结构。

尽管围绕深度学习进行了各种宣传，但传统模型仍然在解决机器学习问题方面发挥着重要作用，尤其是在数据量不是很大、输入特征相对“干净”的情况下。此外，如果与训练样本的数量相比，变量的数量很大，则支持向量机(SVMs)或集成方法(如随机森林或极端梯度提升树(XGBoost ))可能是更简单、更快速和更好的选择。

最流行的 DNN 架构类型是堆叠去噪自动编码器(SdAEs)、深度信念网络、卷积神经网络(CNN)和递归神经网络(RNNs)。使用 CNN 实现了机器视觉的许多进步，使这种 DNN 类型成为图像处理的标准。然而，根据所使用的架构、连接性、初始化、训练方法和损失函数，有许多类型的 dnn 适用于各种业务应用。

图 [3-3](#Fig3) 总结了这些流行的 DNN 架构。以下部分为所使用的术语和最流行的深度神经网络类型提供了一些指导。

![A454512_1_En_3_Fig3_HTML.jpg](A454512_1_En_3_Fig3_HTML.jpg)

图 3-3

Four of the most popular classes of deep learning architectures in data analysis. A. A CNN has several levels of convolutional and subsampling layers optionally followed by fully connected layers with deep architecture. B. The stacked auto-encoder consisting of multiple sparse auto-encoders. C. A DBN is trained layer-wise by freezing previous layer weights and feeding the output to the next layer. D. The RBM architecture includes one visible layer and one layer of hidden units.

## 3.3 玻尔兹曼机器

玻尔兹曼机器[AHS85]是 Hopfield 网络[Mac03，SA08]的随机版本，具有隐藏单位；它的名字来源于玻尔兹曼分布。

玻尔兹曼机器的能量函数以类似于 Hopfield 网络的方式定义，除了可见单元 v 和隐藏单元 h 具有不同的标签。

![$$ E\left(v,h\right)=-\sum \limits_i\kern0.50em {v}_i{b}_i-\sum \limits_k\ \ {h}_k{b}_k-\sum \limits_{i,j}\ \ {v}_i{v}_j{w}_{ij}-\sum \limits_{i,k}\ \ {v}_i{h}_k{w}_{ik}-\sum \limits_{k,l}\ \ {h}_k{h}_l{w}_{k,l} $$](A454512_1_En_3_Chapter_Equ1.gif)

(3.1)

这里 v 是指可见单位，h 是指隐藏单位，b 是偏差，w <sub>ij</sub> 是单位 I 和 j 之间的权重。

给定该能量函数，可见单元和隐藏单元上的联合配置的概率如下:

![$$ p\left(v,h\right)=\frac{e^{-E\left(v,h\right)}}{\sum \limits_{m,n}\kern0.50em {e}^{-E\left(m,n\right)}} $$](A454512_1_En_3_Chapter_Equ2.gif)

(3.2)

可见/隐藏单元的概率由该联合概率的边缘化来确定。例如，通过边缘化隐藏单元，可以得到可见单元的概率分布。

![$$ p(v)=\frac{\sum \limits_h\kern0.50em {e}^{-E\left(v,h\right)}}{\sum \limits_{m,n}\ \ {e}^{-E\left(m,n\right)}} $$](A454512_1_En_3_Chapter_Equ3.gif)

(3.3)

现在可以利用这一点对可见单位进行采样。

当玻尔兹曼机器被完全训练并且已经达到所谓的热平衡时，概率分布 p(v，h)保持不变，因为能量分布本身是常数。然而，每个可见或隐藏单元的概率可能不同，并且其能量可能不是最小的。

玻尔兹曼机器通过获得使观察数据的可能性最大化的参数来训练。似然函数的对数的梯度下降是通常的目标函数。

该算法按描述运行。首先，计算可见单元的对数似然函数。

![$$ l\left(v;w\right)=\log p\left(v;w\right)=\log \sum \limits_h\kern0.50em {e}^{-{E}_{v,h}}-\log \sum \limits_{m,n}\ \ {e}^{-{E}_{m,n}} $$](A454512_1_En_3_Chapter_Equ4.gif)

(3.4)

现在你把对数似然函数的导数作为 w 的函数，并简化它。

![$$ \frac{\partial l\left(v;w\right)}{\partial w}=-\sum \limits_h\kern0.50em p\left(h|v\right)\frac{\partial E\left(v,h\right)}{\partial w}+\sum \limits_{m,n}\ \ p\left(m,n\right)\frac{\partial E\left(m,n\right)}{\partial w} $$](A454512_1_En_3_Chapter_Equ5.gif)

(3.5)

![$$ =-{\mathbb{E}}_{p\left(h|v\right)}\frac{\partial E\left(v,h\right)}{\partial w}+{\mathbb{E}}_{p\left(m,n\right)}\frac{\partial E\left(m,n\right)}{\partial w} $$](A454512_1_En_3_Chapter_Equ6.gif)

(3.6)

这里，![$$ \mathbb{E} $$](A454512_1_En_3_Chapter_IEq1.gif)表示期待。渐变由两部分组成。第一部分是能量函数相对于条件分布![$$ p\left(h|v\right) $$](A454512_1_En_3_Chapter_IEq2.gif)的预期梯度。第二个是关于所有状态的联合分布的能量函数的期望梯度。

计算这些期望值通常是一个棘手的问题，因为它涉及对大量可能的状态/配置求和。解决这个问题的一般方法是使用马尔可夫链蒙特卡罗(MCMC)来近似这些量。

![$$ \frac{\partial l\left(v;w\right)}{\partial w}=-<{s}_i,{s}_j{>}_{p\left({h}_{data}|{v}_{data}\right)}+<{s}_i,{s}_j{>}_{p\left({h}_{model}|{v}_{model}\right)} $$](A454512_1_En_3_Chapter_Equ7.gif)

(3.7)

这里，![$$ <\cdot > $$](A454512_1_En_3_Chapter_IEq3.gif)表示期待。

等式 3.7 是数据馈入可见状态时状态乘积的期望值与无数据馈入时状态乘积的期望值之差。当可见和隐藏单元由观测数据样本驱动时，通过取能量函数梯度的平均值来计算第一项。

第一项很容易计算，但第二项更难，因为它涉及在所有可能的状态上运行一组马尔可夫链，直到它们达到当前模型的平衡分布，最后取平均能量函数梯度。这种复杂性导致了受限玻尔兹曼机的发明。

### 3.3.1 受限玻尔兹曼机器

受限玻尔兹曼机(RBM)是由 Smolensky [Smo86]发明的。这是一台波尔兹曼机器，在可见单元和隐藏单元之间都没有联系。

图 [3-4](#Fig4) 显示了如何基于玻尔兹曼机实现受限玻尔兹曼机。隐藏单元之间的连接以及可见单元之间的连接都被删除，模型变成了一个二分图。有了这个限制，RBM 的能量函数就简单多了。

![$$ E\left(v,h\right)=-\sum \limits_i\kern0.50em {v}_i{b}_i-\sum \limits_k\ \ {h}_k{b}_k-\sum \limits_{i,k}\ \ {v}_i{h}_k{w}_{ik} $$](A454512_1_En_3_Chapter_Equ8.gif)

(3.8)

![A454512_1_En_3_Fig4_HTML.jpg](A454512_1_En_3_Fig4_HTML.jpg)

图 3-4

Illustration of restricted Boltzmann machine . With the restriction that there are no connections between hidden units (![$$ {h}_j=1\cdots J $$](A454512_1_En_3_Chapter_IEq4.gif) nodes) and no connections between visible units (![$$ {v}_i=1\cdots I $$](A454512_1_En_3_Chapter_IEq5.gif) nodes), the Boltzmann machine turns into a restricted Boltzmann machine. The model now is a bipartite graph.

#### 对比分歧

RBM 仍然可以像波尔兹曼机器一样被训练。由于 RBM 的能量函数要简单得多，用来推断方程 3.7 中第二项的取样方法就变得容易了。尽管相对简单，这种学习过程仍然需要大量的采样步骤来近似模型分布。

为了强调这种采样机制的困难，以及为了简化后续介绍，可以用一组不同的符号重写等式 3.7，如下:

![$$ \frac{\partial l\left(v;w\right)}{\partial w}=-<{s}_i,{s}_j{>}_{p_0}+<{s}_i,{s}_j{>}_{p_{\infty }} $$](A454512_1_En_3_Chapter_Equ9.gif)

(3.9)

这里你用 p <sub>0</sub> 来表示数据分布，用![$$ {p}_{\infty } $$](A454512_1_En_3_Chapter_IEq6.gif)来表示模型分布。其他符号保持不变。因此，上述学习参数的方法的困难在于，它们需要潜在地“无限”多个采样步骤来近似模型分布。

Hinton 通过引入一种叫做对比发散的方法解决了这个问题。根据经验，他发现不必执行“无限”的采样步骤来收敛到模型分布；有限的 k 步采样就足够了。因此，等式 3.9 被有效地改写成这样:

![$$ \frac{\partial l\left(v;w\right)}{\partial w}=-<{s}_i,{s}_j{>}_{p_0}+<{s}_i,{s}_j{>}_{p_k} $$](A454512_1_En_3_Chapter_Equa.gif)

Hinton 等人[Hin02]证明了使用![$$ k=1 $$](A454512_1_En_3_Chapter_IEq7.gif)足以使学习算法收敛。这就是所谓的 CD1 算法。

### 3.3.2 深度信念网络

深度信念网络是由[GR06]引入的，它表明 RBM 可以逐层堆叠并以贪婪的方式训练。

图 [3-5](#Fig5) 展示了一个三层深度信念网络的结构。与堆叠 RBM 相反，DBN 仅允许顶层的双向连接(自上而下和自下而上)。所有剩余的较低层只有单向连接。您可以将 DBN 视为一个多阶段生成模型，其中每个神经元都是一个随机细胞。

![A454512_1_En_3_Fig5_HTML.jpg](A454512_1_En_3_Fig5_HTML.jpg)

图 3-5

Illustration of deep belief networks. The bottom layers (all layers except the top one) do not have the bidirectional connections, but only connections from the top down.

因此，该模型只需要对上层的热平衡进行采样，然后回溯性地将信息传递给可见状态。

使用两步过程来训练 dbn:逐层预训练和参数微调。

逐层预训练包括一次训练一层。训练完第一层后，冻结连接并在第一层上添加新层。第二层以与第一层相同的方式训练，并且该过程根据需要继续进行多层。这种预训练可以视为有效的权重初始化[BLPL06，EBC <sup>+</sup> 10，RG09]。

使用两种不同的微调策略之一来执行微调以进一步优化网络。

*   生成模型的微调:生成模型的微调是通过对比版本的唤醒-睡眠算法[HDFN95]实现的，这是一个受神经科学启发的过程。在唤醒阶段，信息从底层流向上层，以调整自下而上的权重，从而在上层创建表示。在睡眠阶段，情况正好相反；信息向下传播以调整顶部-底部连接。
*   用于判别模型的微调:在这种情况下，通过使用较高层上的数据标签将标准反向传播应用于预训练的网络，可以简单地完成 DBN 的微调。除了提供良好的网络初始化之外，DBN 还有其他重要的特性。首先，所有的数据都可以使用，甚至是未标记的数据集。第二，它可以被视为一个概率生成模型，这在贝叶斯框架内是有用的。第三，过拟合问题可以通过预训练步骤和其他强正则化方法(如 dropout)得到有效缓解。然而，DBN 存在以下问题:
    *   由于“解释”效应，DBNs 中的推理是一个问题。
    *   DBN 只能使用贪婪的再训练，而不能对所有层进行联合优化。
    *   近似推理是前馈的；没有自下而上和自上而下的信息流。

### 3.3.3 深波尔兹曼机器

深玻尔兹曼机是由[RG09]推出的。图 [3-6](#Fig6) 为三层深玻尔兹曼机。DBM 和 DBN 与上一节的区别在于，DBM 信息在底层的双向连接上流动。

![A454512_1_En_3_Fig6_HTML.jpg](A454512_1_En_3_Fig6_HTML.jpg)

图 3-6

Illustration of deep Boltzmann machine (DBM). The deep Boltzmann machine is more like stacking RBMs together. Connections between every two layers are bidirectional (source: [https://​www.​cs.​toronto.​edu/​~rsalakhu/​DBM.​jpg](https://www.cs.toronto.edu/%7Ersalakhu/DBM.jpg)).

能量函数被定义为 RBM(等式 3.8)的能量函数的扩展，如下所示为具有 N 个隐藏层的 DBM:

![$$ E\left(v,h\right)=-\sum \limits_i{v}_i{b}_i-\sum \limits_{n=1}^N\sum \limits_k{h}_{n,k}{b}_{n,k}-\sum \limits_{i,k}{v}_i{w}_{ik}{h}_k-\sum \limits_{n=1}^{N-1}\sum \limits_{k,1}{h}_{n,k}{w}_{n,k,l}{h}_{n+1,l} $$](A454512_1_En_3_Chapter_Equ10.gif)

(3.10)

因为能量函数的相似性，你也可以使用对比散度(CD1)来训练 DBM。

DBN 和 DBM 确实有一些相似之处，因为他们都是受受限玻尔兹曼机器启发的深度神经网络。但是 DBM 的双向结构提供了在数据中学习更复杂模式的能力。

## 3.4 卷积神经网络

CNN 由具有不同类型堆叠层的几个块组成。每个块由一个卷积层和一个池层组成，通常是最大池[SMB10]。这些模块通常一个接一个地堆叠起来，或者在其上堆叠一个 softmax 逻辑层，以形成一个深度模型。CNN 使用了一些技巧，使其非常适合图像处理，如权重共享、自适应滤波器和池化。池将卷积层的子样本提供给下一层，作为一个强大的正则化器。权重共享和池化方案(最常见的是最大池化)允许 CNN 生成像平移不变性这样的守恒属性。细胞神经网络是非常有效的，并已普遍用于计算机视觉和图像识别[AIG12]。

CNN 对信号流而不是特征向量进行操作。也就是说，完全连接的神经网络由绑定到特征向量的所有输入的激活单元组成。每个单元都有一个特定于输入中每个要素的权重。另一方面，卷积层通过在输入向量(或 2D 输入图，因为 CNN 经常用于图像)上滑动一个小的(可训练的)权重滤波器，并使用滤波器卷积每个重叠的输入区域，来利用权重共享。

具有最大池的 CNN 足够强大，可以模仿灵长类动物视觉皮层的低级阶段，并具有生物学上似乎合理的特征检测器，如 Gabor 滤波器[CHY <sup>+</sup> 14]。然而，一旦经过训练，CNN 就像一台简单的前馈机器，具有固定的权重。最近，Stollenga 等人提出了一种具有后处理行为的迭代版本的 CNN，称为深度注意力选择网络(dasNet) [SMGS15]。这种架构能够模拟 CNN 中的选择性注意力，允许每一层通过调制卷积滤波器活动的特殊连接(自下而上和自上而下)在图像上连续传递时影响所有其他层。这些特殊连接的权重实现了一种控制策略，该策略是在 CNN 已经通过监督学习以通常的方式被训练之后通过强化学习来学习的。给定一个输入图像，注意力策略可以在多次传递中增强或抑制特征，以改善初始监督训练没有捕捉到的困难病例的分类。dasNet 架构允许自动检查内部 CNN 过滤器，防止手动检查。

## 3.5 深度自动编码器

自动编码器是一种将输入数据本身作为输出的 DNN。如果用一些添加的噪声对它们进行训练，这些架构可以充当生成模型，并被称为去噪自动编码器。自动编码器可以用贪婪的逐层模式进行训练，就像 DBNs 一样，以形成深度模型[VLBM08]。

通过将下一层中的自动编码器的输出作为上一层的输入转发，自动编码器可以被堆叠以形成深度网络。无监督的预训练一次完成一层，并且训练每一层以最小化其输入重构中的误差。经过预训练后，网络可以通过添加 softmax 层和应用监督反向传播进行微调，就好像它们是多层感知器一样。

堆叠去噪自动编码器(SdAE)是 AE 的随机版本，通过将噪声添加到输入来获得，以防止同一性映射的学习。他们试图对输入进行编码，同时消除破坏的影响，捕捉输入中的统计相关性。

![A454512_1_En_3_Fig7_HTML.jpg](A454512_1_En_3_Fig7_HTML.jpg)

图 3-7

Different types of networks architectures (source: [`http://www.asimovinstitute.org/neural-network-zoo/`](http://www.asimovinstitute.org/neural-network-zoo/) )

## 3.6 递归神经网络

传统的 ML 方法，如支持向量机、逻辑回归和前馈网络，已被证明是有用的，无需通过将时间投影为空间来显式地对时间过程中的时间进行建模。然而，这种假设不能模拟长期依赖性，并且在复杂的时间模式中具有有限的可用性。递归神经网络是一个丰富的端到端可微分的模型族，因此适合于基于梯度的训练，随后通过标准技术进行正则化，如丢弃或噪声注入。重现是解决语言等难题的关键，因为它似乎存在于大多数大脑机制中。图 [3-7](#Fig7) 给出了几种类型神经网络的图表说明，包括循环网络。

RNNs 的第一个结构是由 Jordan [Jor90]提出的，作为具有用特殊单元扩展的单个隐藏层的前馈网络。输出节点值被提供给特殊单元，然后特殊单元在下一时间步将这些值提供给隐藏节点。如果输出值是动作，则特殊单位允许网络记住在先前时间步采取的动作。此外，Jordan 网络中的特殊单元是自连接的。

Elman [Elm90]介绍的架构更简单。与隐藏层中的每个单元相关联的是上下文单元。每个这样的单元沿着固定权重的边，将相应的隐藏节点在前一时间步的状态作为输入。然后，该值沿着标准边反馈到相同的隐藏节点 j 中。这种架构相当于一个简单的 RNN，其中每个隐藏节点都有一条自连接的递归边。使隐藏节点自连接的固定权重循环边的想法是 LSTM 网络后续工作的基础[HS97]。

rnn 是一类无监督或有监督的架构，用于学习时间或顺序模式。RNN 可用于使用先前的数据样本预测序列中的下一个数据点。例如，在文本中，前一个单词上的滑动窗口用于预测句子中的下一个单词或一组单词。rnn 通常使用 Schmidhuber 等人[HS97]提出的长短期记忆(LSTM)算法或门控递归单元(GRUs)进行训练。另一方面，由于众所周知的梯度消失或梯度爆炸问题，以及优化超参数时需要非常小心，因此很难训练它们捕捉长期相关性。

![A454512_1_En_3_Fig8_HTML.jpg](A454512_1_En_3_Fig8_HTML.jpg)

图 3-8

Topologies of recurrent networks (source: [`http://karpathy.github.io/2015/05/21/rnn-effectiveness/`](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) )

RNN 最近变得非常受欢迎，特别是随着几个技巧的引入，例如双向学习(向前和向后序列预测)和允许使用动态大小滑动窗口的注意力机制，这对构建语言模型特别有用。

图 [3-8](#Fig8) 描述了在输入和输出向量序列上运行的几个 rnn。每个矩形是一个向量；自下而上，输入向量在底部，输出向量在顶部，中间的矩形保存 RNN 状态。

一个很好的教程可以在 [`http://blog.echen.me/2017/05/30/exploring-lstms/?utm_content=buffer1bdf8`](http://blog.echen.me/2017/05/30/exploring-lstms/?utm_content=buffer1bdf8) 访问，关于可视化 LSTMs。另外，请参见 Andrej Karpathy 关于在 [`https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks`](https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks) 训练 RNNs 的视频教程。

### 3.6.1 强化学习的 rnn

强化学习(RL)通过使用延迟的奖励信号来调整学习机的参数。对于 RL 来说，最大的挑战是环境状态仅部分可观测且必须考虑隐藏状态的任务，即所谓的非马尔可夫任务或部分可观测马尔可夫决策过程。许多现实世界的任务都属于这一类，比如迷宫导航任务。然而，隐藏状态使问题变得更加困难，因为代理不仅要学习从环境状态到动作的映射，还需要在每个位置确定他们处于哪个环境状态。

用 LSTM 训练的 rnn 特别适合于处理这些复杂的任务，尤其是在没有先验环境模型的情况下。人们可以在线建立一个模型，学习预测观察和奖励，从而学习推断环境或将其分解为一组马尔可夫子任务，每个子任务都可以通过将观察映射到行动的反应式控制器来解决[WS98]。另一种无模型方法是试图通过使选择的动作不仅依赖于当前的观察，而且依赖于观察和动作的历史的某种表示来解决隐藏状态。总的想法是，当前的观察连同历史的这种表示可以产生马尔可夫状态信号。

如果事件之间存在长期相关性，所有这些方法在迷宫导航任务中可能会面临困难，在迷宫导航任务中，T 形接头看起来相同，区分它们的唯一方法是考虑先前的事件序列。对于这些情况，没有直接的方法将任务分解成马尔可夫子任务，代理必须记住相关信息。Schmidhuber 提出了 LSTM 单位，通过结合从数据中学习到的记忆状态和遗忘项来帮助解决这个问题[HS97]；参见图 [3-9](#Fig9) 。

![A454512_1_En_3_Fig9_HTML.jpg](A454512_1_En_3_Fig9_HTML.jpg)

图 3-9

An LSTM cell with forgetting memory gate (source: [`https://arxiv.org/pdf/1506.00019.pdf`](https://arxiv.org/pdf/1506.00019.pdf) )

强化学习，即代理学习在给定环境中应该采取的行动，以最大化累积奖励，通过利用深度学习进行特征表示，已经取得了进展。

在[`https://arxiv.org/pdf/1604.06778.pdf`](https://arxiv.org/pdf/1604.06778.pdf)【DCH<sup>+</sup>最近的一项工作中，作者提出了一种新的标准化和挑战性的测试床，用于评估连续控制领域中的算法，其中数据是高维的，并且经常使用无模型方法。该框架由 31 个连续的控制任务组成，从基本到运动到分层，将理想地帮助研究人员了解他们算法的优势和局限性。

彼得·阿比尔(来自 openAI)在 [`https://www.youtube.com/watch?v=evq4p1zhS7Q`](https://www.youtube.com/watch?v=evq4p1zhS7Q) 的视频演示很好地概述了 DL 如何从一个新的角度来解决机器人技术中的强化学习问题。

### LSTMs

RNNs 的吸引力之一是它能够连接以前的信息来解决实际的任务，例如使用以前的单词来预测句子中的下一个单词。

LSTM 网络是一种特殊类型的 RNN，能够学习长期依赖性。它们是由 Hochreiter 和 Schmidhuber 在 1997 年[HS97]提出的，后来经过改进，现在已经广泛应用于从语言翻译到视频处理的各种问题。

LSTMs 被设计用于解决长期依赖性以及消失和梯度爆炸问题。LSTM 中的重复模块包含四个交互层:输入、输出、单元状态和遗忘门。LSTM 具有删除或添加信息到细胞状态的能力，由控制信息流的门来调节。门由一个 sigmoid 或 tanh 神经神经元和一个逐点乘法运算组成。

LSTM 的每个记忆单元都包含一个节点，该节点具有固定权重 1 的自连接递归边，确保梯度可以穿过许多时间步长而不消失或爆炸。

简单的递归神经网络具有长期记忆(在训练期间缓慢变化的权重)和作为激活的短期记忆，这些记忆从每个节点传递到连续的节点。LSTM 有一种中间类型的存储方式，即存储单元。存储单元由几个元件形成。

*   输入节点:这个单元是一个节点，它从上一个时间步(t–1)的隐藏层激活当前时间步的输入层。求和的加权输入通过一个双曲正切激活函数。
*   输入门:门是一个 s 形单元，它从当前数据 x(t)以及前一时间步的隐藏层获取激活。但是，它的值用于乘以(而不是相加)另一个节点的值。如果其值为零，则来自其他节点的流被断开。
*   内部状态:这是一个自连接的递归边，具有固定的单位权重。因为此边以恒定权重跨越相邻时间步长，所以误差可以在时间步长间流动，而不会消失或爆炸。
*   忘记门:这些对于网络释放内部状态的内容是至关重要的。
*   输出门:存储单元中的值是内部状态乘以输出门的值。内部状态首先通过 tanh 激活函数传输，因为这使每个单元的输出具有与普通 tanh 隐藏单元相同的动态范围。

LSTM 非常适合于分类和预测演化时间序列，并且在许多应用中通常优于隐马尔可夫模型和其他序列学习方法。然而，它们在计算上是昂贵的。

gru 是由 Felix Gers 介绍的，他最初称之为[忘记盖茨](ftp://ftp.idsia.ch/pub/juergen/FgGates-NC.pdf)。它们将遗忘门和输入门合并成一个“更新门”它还合并了单元格状态和隐藏状态，并进行一些其他更改。由此产生的模型比标准的 LSTM 模型更简单，并且越来越受欢迎。Greff 等人(2015 年)对流行的变体进行了比较，发现它们几乎无法区分。

然而，根据这份报告，香草 LSTM 在自然语言处理和机器翻译方面一直优于 GRUs。

大多数问题可以通过无政府的 LSTM 来解决。在无状态模式下，LSTM 不会记住前几批的内容。如果有状态，批次中索引 I 处每个样本的最后状态将用作下一批次中索引 I 处样本的初始状态。因此，要了解序列之间的依赖关系，您必须使用有状态的 LSTM，在 LSTM Keras 层中作为布尔标志给出。

关于 LSTM 如何工作的详细解释，见 [`http://colah.github.io/posts/2015-08-Understanding-LSTMs/`](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) 的博文，其中有一个[使用 Keras 的分步示例](https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/)。

截至 2017 年 8 月，五大公司(苹果、谷歌、微软、亚马逊和脸书)正在大规模地将 LSTM 添加到他们的产品中，用于语音、图像或自动翻译。

*   脸书在 2017 年 8 月宣布，它正在使用 LSTM 每天进行高达 45 亿次翻译，每秒超过 5 万次。
*   LSTM 还被用于改善近 10 亿部 iPhones 上的苹果 Siri 和 QuickType。
*   LSTM 已经学会了基于生成序列到序列模型来创建亚马逊 Alexa 的答案。
*   位于 LSTM 的系统还学会了控制机器人、分析图像、总结文档、识别视频和笔迹、运行聊天机器人和智能助手、预测疾病、点击率和股市，以及作曲。
*   百度和其他亚洲公司也在大量使用 LSTM，它正渗透到现代世界。你可能一直在用 LSTM。但其他深度学习方法也大量使用。下面是引用众多的概览页面: [`http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html`](http://people.idsia.ch/%7Ejuergen/impact-on-most-valuable-companies.html) 。

## 3.7 生成模型

理查德·费曼曾经说过，“我不能创造的，我不理解。”能够生成数据远比简单地对数据进行分类要强大得多。我们可能低估了我们的大脑包含了多少关于这个世界的隐含信息。我们知道重力总是把我们往下推，汽车不会飞，物体不会溶解到稀薄的空气中，等等。然而，这些知识大部分在我们的日常生活中完全被忽略了，如果我们想将其表达为规则，我们会很挣扎，因为可能性的数量可能会爆炸。此外，这些规则中的大多数都有例外，更糟糕的是，其中一些规则可能会相互矛盾。

生成模型是实现这一目标的最有前途的方法之一。要训练生成模型，首先要收集某个领域(图像、视频、声音)的大量数据，然后训练模型生成类似的数据。所使用的神经网络被迫发现数据的潜在压缩表示，以便生成它。

生成模型假设你有一组潜在的(未观察到的)变量，解释观察到的数据 x .潜在变量 z 的一个向量，可以按照某个概率密度函数 P(z)进行采样。然后你假设你有一族函数 f(z；θ)，其中θ是参数的向量。你想优化θ使得 f(z；θ)在从 P(z)采样 z 时，对于数据集中的每个 X，以高概率产生类似 X 的样本。形式上，你最大化训练集中每个 X 的概率。

![$$ P(X)=\int P\left(X|z;\theta \right)\ P(z) dz $$](A454512_1_En_3_Chapter_Equb.gif)T2】

这里，![$$ P\left(X|z;\theta \right) $$](A454512_1_En_3_Chapter_IEq8.gif)是 f(z；θ)导致所谓的最大似然。

有几种类型的生成模型。深度卷积生成对抗网络是由拉德福德等人发明的。在这个工作中，这个例子将从一个均匀分布(潜在变量)中抽取的 100 个随机数作为输入，并输出一个图像(在这个例子中，右边是 64×64×3 的绿色图像)。随着代码的不断变化，生成的图像也会随之变化。这表明模型已经学会了描述世界看起来是什么样子的特征，而不仅仅是记忆一些例子。

你可以在 [`http://shakirm.com/slides/DLSummerSchool_Aug2016_compress.pdf`](http://shakirm.com/slides/DLSummerSchool_Aug2016_compress.pdf) 找到 Deepmind 的 Shakir Mohamed 关于生成模型的很好的演示，也可以在 [`https://blog.openai.com/generative-models/`](https://blog.openai.com/generative-models/) 找到 OpenAI 的博客帖子。

### 3.7.1 可变自动编码器

变分自动编码器(VAE)是最简单的生成模型之一。它是自动编码器[Doe16]的更高级版本，增加了对正在学习的编码表示的约束。它学习关于输入数据的变量 z 的潜在变量模型和从潜在变量近似采样的函数，从而使它成为一个易处理的问题。不是让神经网络学习任意函数，而是学习对数据 P(x)建模的概率分布的参数。通过从潜在分布 P(z)中采样点，VAE 生成与训练数据匹配的新输入数据样本。

该模型的参数通过两个损失函数来训练:重建损失，其迫使解码样本匹配初始输入(就像普通的自动编码器一样)，以及学习的潜在分布和先前分布之间的 KL 散度，用作正则化项，使用重新参数化技巧。可以排除后一项，尽管它确实有助于学习结构良好的潜在空间并减少对训练数据的过度拟合。参见 [`https://jaan.io/what-is-variational-autoencoder-vae-tutorial/`](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/) 处的教程以及应用于 [`https://blog.keras.io/building-autoencoders-in-keras.html`](https://blog.keras.io/building-autoencoders-in-keras.html) 处的 MNIST 数据集的一些代码示例。

在 VAEs 中，这种输出分布的选择通常是高斯分布。

![$$ P\left(X|z;\theta \right)=N\left(X|f\left(z;\theta \right),{\sigma}^2\ast I\right) $$](A454512_1_En_3_Chapter_Equ11.gif)

(3.11)

为了求解这个方程，VAEs 必须处理两个问题:如何定义潜在变量代表什么信息，以及如何计算 z 上难以处理的积分？VAE 对第一个问题的处理方法是简单地假设潜在变量没有明确的解释。第二个问题(由于潜在空间 z 的高维性而产生)在 VAE 框架中通过随机梯度下降优化一个近似分布![$$ Q\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq9.gif)来解决，该近似分布预测 z 的哪些值可能产生 x。VAEs 给出了两个问题的答案。

与稀疏自动编码器不同，通常没有调整参数，并且与去噪自动编码器不同，您可以直接从 P(X)采样(无需执行马尔可夫链蒙特卡罗[MCMC])。VAEs 假设 z 的维数没有简单的解释，而是断言 z 的样本可以从简单的分布中抽取；换句话说，![$$ \mathcal{N}\left(0,I\right) $$](A454512_1_En_3_Chapter_IEq10.gif)，其中 I 是单位矩阵。

变分自动编码器背后的关键思想是试图对可能产生 X 的 z 值进行采样，并根据它们计算 P(X)。说 z 是用 p.d.f. Q(z)从任意分布中采样的，不是![$$ \mathcal{N}\left(0,I\right) $$](A454512_1_En_3_Chapter_IEq11.gif)。我们试着把![$$ {E}_{z\sim Q}P\left(X|z\right) $$](A454512_1_En_3_Chapter_IEq12.gif)和 P(X)联系起来。

联系![$$ {E}_{z\sim Q}P\left(X|z\right) $$](A454512_1_En_3_Chapter_IEq13.gif)和 P(X)的一种方法是从![$$ P\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq14.gif)和 Q(z)之间的 Kullback-Leibler 散度(KL 散度或 D)的定义开始。

![$$ \mathcal{D}\left[Q(z)\Big\Vert P\left(z|X\right)\right]={E}_{z\sim Q}\left[\log Q(z)-\log P\left(z|X\right)\right] $$](A454512_1_En_3_Chapter_Equ12.gif)

(3.12)

通过对![$$ P\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq16.gif)应用贝叶斯规则，可以将 P(X)和![$$ P\left(X|z\right) $$](A454512_1_En_3_Chapter_IEq15.gif)都代入这个等式。

![$$ {\displaystyle \begin{array}{l}\mathcal{D}\left[Q(z)\Big\Vert P\left(z|X\right)\right]={E}_{z\sim Q}\left[\log Q(z)-\log P\left(X|z\right)-\log P(z)\right]\\ {}+\log P(X)\end{array}} $$](A454512_1_En_3_Chapter_Equ13.gif)

(3.13)

在这里，log P(X)出于预期，因为它不依赖于 z。对两边取反，重新排列，并将![$$ {E}_{z\sim Q} $$](A454512_1_En_3_Chapter_IEq17.gif)的一部分收缩成 KL-divergence 项，得到如下:

![$$ \log P(X)-\mathcal{D}\left[Q(z)\Big\Vert P\left(z|X\right)\right]={E}_{z\sim Q}\left[\log P\left(X|z\right)\right]-\mathcal{D}\left[Q(z)\Big\Vert P(z)\right] $$](A454512_1_En_3_Chapter_Equ14.gif)

(3.14)

注意 X 是固定的，Q 可以是任意分布。既然你对推断 P(X)感兴趣，那么用 X 构造 Q 是有意义的，它将被写成![$$ Q\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq18.gif))这样![$$ \mathcal{D}\left[Q(z)\kern0.50em \ \Big\Vert\ \ \ |P\left(z|X\right)\right] $$](A454512_1_En_3_Chapter_IEq19.gif)将会很小。

![$$ {\displaystyle \begin{array}{l}\log P(X)-\mathcal{D}\left[Q\left(z|X\right)\Big\Vert P\left(z|X\right)\right]={E}_{z\sim Q}\left[\log P\left(X|z\right)\right]\\ {}-\mathcal{D}\left[Q\left(z|X\right)\Big\Vert P(z)\right]\end{array}} $$](A454512_1_En_3_Chapter_Equ15.gif)

(3.15)

这个方程是变分自动编码器的基础。从左侧开始，您将 log P(X)最大化，同时将![$$ \mathcal{D}\left[Q\left(z|X\right)\Big\Vert \kern0.50em \ |P\left(z|X\right)\right] $$](A454512_1_En_3_Chapter_IEq20.gif)最小化。![$$ P\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq21.gif)不是你可以分析计算出来的；它描述了在图 [3-10](#Fig10) 的模型下可能产生类似 X 的样本的 z 值。然而，左边的第二个任期正在拉着![$$ Q\left(z|x\right) $$](A454512_1_En_3_Chapter_IEq22.gif)去配合![$$ P\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq23.gif)。假设您对![$$ Q\left(z|x\right) $$](A454512_1_En_3_Chapter_IEq24.gif)使用任意高容量模型，那么![$$ Q\left(z|x\right) $$](A454512_1_En_3_Chapter_IEq25.gif)将理想地实际匹配![$$ P\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq26.gif)，在这种情况下，KL 散度项将为零，并且您将直接优化 log P(X)。作为额外的奖励，你让棘手的![$$ P\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq27.gif)变得容易处理。你可以用![$$ Q\left(z|x\right) $$](A454512_1_En_3_Chapter_IEq28.gif)来计算它。

![A454512_1_En_3_Fig10_HTML.jpg](A454512_1_En_3_Fig10_HTML.jpg)

图 3-10

Encoder and decoder in a variational auto encoder (source: [Jaan AltoSaar blog](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/))

因此，作为随机梯度下降的标准，你取 z 的一个样本，并把 z 的![$$ P\left(X|z\right) $$](A454512_1_En_3_Chapter_IEq29.gif)作为![$$ {E}_{z\sim Q}\left[\log P\left(X|z\right)\right] $$](A454512_1_En_3_Chapter_IEq30.gif)的近似。

你要优化的全方程如下:

![$$ {\displaystyle \begin{array}{l}{E}_{X\sim D}\left[\log P(X)-\mathcal{D}\left[Q\left(z|X\right)\Big\Vert P\left(z|X\right)\right]\right]=\\ {}\ {E}_{X\sim D}\left[{E}_{z\sim Q}\left[\log P\left(X|z\right)\right]-\mathcal{D}\left[Q\left(z|X\right)\Big\Vert P(z)\right]\right]\end{array}} $$](A454512_1_En_3_Chapter_Equ16.gif)

(3.16)

您可以从分布![$$ Q\left(z|X\right) $$](A454512_1_En_3_Chapter_IEq31.gif)中采样 X 的单个值和 z 的单个值，并计算梯度如下:

![$$ \log P\left(X|z\right)-\mathcal{D}\left[Q\left(z|X\right)\Big\Vert P(z)\right] $$](A454512_1_En_3_Chapter_Equ17.gif)

(3.17)

然后你可以在 X 和 z 的任意多个样本上平均这个函数的梯度，结果收敛于方程 3.16 的梯度。

### 3.7.2 生成敌对网络

生成网络是以无人监督的方式训练的，因为你对生成的数据没有任何明确的期望目标；它们应该尽可能真实。

以监督方式训练生成网络的一种有趣的方法是生成对抗网络。gan 于 2014 年由 Ian Goodfellow 等人引入。它们由一个鉴别器网络(在图像的情况下，是标准的卷积神经网络)组成，该网络被训练来区分真实的输入图像和由生成器(通常也是 CNN)创建的生成图像。这两个网络被锁定在一个 min-max 游戏中:鉴别器试图区分真实图像和虚假图像，生成器试图创建图像，使鉴别器相信它们是真实的。最终，生成器网络创建的图像与真实图像无法区分。

生成器(G)试图捕捉从中提取数据的模型，从而从随机噪声输入中生成图像，而鉴别器(D)是传统的 CNN，它试图区分真实数据(训练数据)和由 G 生成的数据，从而估计后验概率 P(标签|数据)，其中标签指的是“假”或“真”。

在训练期间，向 D 呈现来自训练数据的真实图像和由 G 生成的虚假图像的混合，并且其损失函数是正确地分离正确和虚假输入。两个网络都将与相反的目标竞争，训练将不断发展，直到达到平衡。

GAN 训练是一个两人游戏，其中生成器最小化其生成分布和数据分布之间的差异，而鉴别器试图区分来自生成器分布的样本和真实数据样本。当鉴别器的表现不比随机猜测好的时候，你说生成器“赢”了。训练 GANs 是困难的，因为系统动力学经常偏离平衡。

基本 GAN 的优化问题是最小-最大问题，由以下等式给出，其中 V 是值函数，x 是观测值，z 是潜在变量。

![$$ {\displaystyle \begin{array}{l}\left[{G}_{\mathrm{min}}\right]\left[{D}_{\mathrm{max}}\right]V\left(D,G\right)={E}_{x\sim {P}_{data}(x)}\left[\log D(x)\right]+\\ {}\kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ \kern0.50em \ {E}_{x\sim {P}_z(z)}\left[\log \left(1-D\left(G(z)\right)\right)\right]\end{array}} $$](A454512_1_En_3_Chapter_Equ18.gif)

(3.18)

最近，瓦瑟斯坦距离[被引入](https://arxiv.org/pdf/1701.07875v1.pdf)来测量两个分布之间的差异。Wasserstein 是一个更一致的指标，并已被证明能够创造更好的收敛性。更多信息参见 [`https://casmls.github.io/general/2017/04/13/gan.html`](https://casmls.github.io/general/2017/04/13/gan.html) 。

![A454512_1_En_3_Fig13_HTML.jpg](A454512_1_En_3_Fig13_HTML.jpg)

图 3-13

Generating rooms from noise with several types of GANs (source: [`https://casmls.github.io/general/2017/04/13/gan.html`](https://casmls.github.io/general/2017/04/13/gan.html) )

![A454512_1_En_3_Fig12_HTML.jpg](A454512_1_En_3_Fig12_HTML.jpg)

图 3-12

Model of a GANs

![A454512_1_En_3_Fig11_HTML.gif](A454512_1_En_3_Fig11_HTML.gif)

图 3-11

Cumulative number of papers referring to GANs (source: [`https://github.com/hindupuravinash/the-gan-zoo`](https://github.com/hindupuravinash/the-gan-zoo) )

图 [3-11](#Fig11) 描述了 GANs 文件在创建后的最后几年中的累积活动。图 [3-12](#Fig12) 展示了一个 GANN 的主要模块组件模型。图 [3-13](#Fig13) 显示了几种模型 GANs 在从噪声中生成房间图像中的应用。

Makhzani 等人[引入了](https://arxiv.org/abs/1511.05644)对抗性自动编码器(AAE)的概念。AE 是一种概率自动编码器，它使用生成式对抗网络来执行变分推理。将聚集后验值与先验值相匹配确保了从先验空间的任何部分产生有意义的样本。AAE 可用于半监督分类、理清图像的风格和内容、无监督聚类、维度缩减和数据可视化。

您可以在 [`https://deephunt.in/the-gan-zoo-79597dc8c347`](https://deephunt.in/the-gan-zoo-79597dc8c347) 找到到目前为止提出的所有类型的 gan 的更新列表。

当很少有样本可用于训练时，GANS 可以非常有效地进行数据扩充和数据生成，从而避免了使用深度学习的困难。在最近的一次实验中(见 [`https://arxiv.org/abs/1606.03498`](https://arxiv.org/abs/1606.03498) )，作者仅使用了 MNIST 数据集上 10 位数字中的每一位的 50 个例子来生成带有 GAN 的训练数据集，从而实现了 1.5%的错误率，相比之下，使用原始的 50，000 个例子的错误率为 0.5%。

文本到图像合成是 GANs(称为 stack GANs)的一个有趣的应用，用于从文本描述中生成鸟和花的图像。检查 GitHub 上可用的 Torch [中的代码。](https://github.com/reedscot/icml2016)

伊恩·古德菲勒在 [`http://on-demand.gputechconf.com/gtc/2017/video/s7502-ian-goodfellow-generative-adversarial-networks.mp4`](http://on-demand.gputechconf.com/gtc/2017/video/s7502-ian-goodfellow-generative-adversarial-networks.mp4) 有一篇关于甘斯的精彩教程。