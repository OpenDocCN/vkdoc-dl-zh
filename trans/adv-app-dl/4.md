# 4.高级 CNN 和迁移学习

在这一章中，我们来看看在开发 CNN 时通常使用的更高级的技术。特别是，我们将看到一个非常成功的新卷积网络，称为*初始网络*，它基于并行而不是顺序完成几个卷积运算的思想。然后，我们将看看如何使用多重成本函数，其方式与多任务学习中的方式类似。下一节将向您展示如何使用 Keras 提供的预训练网络，以及如何使用迁移学习来针对您的特定问题调整这些预训练网络。在本章的最后，我们将研究一种实现迁移学习的技术，这种技术在处理大数据集时非常有效。

## 多通道卷积

在前一章中，你学习了卷积是如何工作的。在示例中，我们已经明确描述了当输入是二维矩阵时如何执行它。但现实并非如此。例如，输入张量可以表示彩色图像，因此将具有三维:在 *x* 方向上的像素数量(沿着 *x* 轴的分辨率)、在 *y* 方向上的像素数量(沿着 *y* 轴的分辨率)、以及颜色通道的数量，当处理 RGB 图像时是三个(一个通道用于红色，一个用于绿色，一个用于蓝色)。情况可能会更糟。一个具有 32 个核的卷积层，每个核为 5 × 5，当期望输入每个为 28 × 28 的图像时(参见上一章中的 MNIST 示例)，将具有维数为( *m* ，32，24，24)的输出，其中 *m* 是训练图像的数量。这意味着我们的卷积必须用 32 × 24 × 24 的张量来完成。那么我们如何对三维张量进行卷积运算呢？嗯，其实很简单。从数学上讲，如果内核 *K* 有维度*n*<sub>*K*×*n*<sub>*K*</sub>×*n*<sub>*c*</sub>，输入张量 *A* 有维度 *n* <sub>*x* 【T39</sub></sub>

![$$ \sum \limits_{i=1}^{n_x}\sum \limits_{j=1}^{n_y}\sum \limits_{k=1}^{n_c}{K}_{ijk}{A}_{ijk} $$](../images/470317_1_En_4_Chapter/470317_1_En_4_Chapter_TeX_Equa.png)

这意味着我们将对通道维度求和。在 Keras 中，当您在 2D 定义卷积层时，可以使用以下代码:

```py
Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation="relu")

```

其中第一个数字(32)是过滤器的数量，而(5，5)定义了内核的尺寸。Keras 没有告诉你的是，它自动取核 *n* <sub>*c*</sub> × 5 × 5 其中 *n* <sub>*c*</sub> 是输入张量的通道数。这就是为什么你需要给第一层`input_shape`参数。该信息中包含通道数。但是这三个数字哪个是正确的呢？Keras 怎么知道在这种情况下正确的是 1 而不是 28？

让我们更深入地看看我们在前一章中看到的具体例子。假设我们用以下代码导入 MNIST 数据集:

```py
(X_train, y_train), (X_test, y_test) = mnist.load_data()

```

在前一章中，我们用

```py
X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')

```

您会注意到，我们在 28 的 *x* 和 *y* 维度之前添加了一个维度 1。1 是图像中的通道数:因为它是灰度图像，所以只有一个通道。但是我们也可以在 28 的 *x* 和 *y* 尺寸之后增加通道的数量。这是我们的选择。我们可以用我们在第 [3](3.html) 章中讨论的代码告诉 Keras 采用哪个维度:

```py
K.set_image_dim_ordering('th')

```

这一行很重要，因为 Keras 需要知道哪一个是信道维度，以便能够为卷积运算提取正确的信道维度。记住，对于内核，我们只指定了 *x* 和 *y* 维度，所以 Keras 需要自己找到第三维:在这个例子中是 1。你会记得，`'th'`的值会期望通道尺寸在 *x* 、 *y* 尺寸之前，而`'tf'`的值会期望通道尺寸是最后一个。所以，这只是一个保持一致的问题。您用上面的代码告诉 Keras，通道维度在哪里，然后相应地修改您的数据。让我们考虑几个额外的例子来使这个概念更加清晰。

让我们假设当使用 MNIST 图像作为输入时，我们考虑具有`set_image_dim_ordering('th')`(我们将忽略观察数量的维度 *m* )的以下网络:

```py
Input tensors shape: 1×28×28
Convolutional Layer 1 with 32 kernels, each 5×5: output shape 32×24×24
Convolutional Layer 2 with 16 kernels, each 3×3: output shape 16×22×22

```

第二卷积层中的核将具有 32 × 3 × 3 的维度。来自第一卷积层(32)的信道数量在确定第二卷积层的输出维度中不起作用，因为我们对该维度求和。事实上，如果我们将第一层中的内核数量更改为 128，我们会得到以下维度:

```py
Input tensors shape: 1×28×28
Convolutional Layer 1 with 32 kernels, each 5×5: output shape 128×24×24
Convolutional Layer 2 with 16 kernels, each 3×3: output shape 16×22×22

```

如您所见，第二层的输出尺寸没有任何变化。

### 注意

Keras 在创建过滤器时会自动推断通道尺寸，因此您需要使用`set_image_dim_ordering()`告诉 Keras 哪个是正确的尺寸，然后相应地调整您的数据。

### 为什么 1 × 1 卷积会降低维数

在这一章中，我们将研究初始网络，我们将使用 1 × 1 核，理由是这样可以降低维数。乍一看，这似乎有悖常理，但您需要记住上一节的讨论，即过滤器总是有第三维的。考虑以下一组层:

```py
Input tensors shape: 1 × 28 × 28
Convolutional Layer 1 with 32 kernels, each 5 × 5: output shape 128 × 24 × 24
Convolutional Layer 2 with 16 kernels, each 1 × 1: output shape 16 × 24 × 24

```

注意具有 1 × 1 核的层是如何降低前一层的维度的。它将尺寸从 128 × 24 × 24 更改为 16 × 24 × 24。1 × 1 内核不会改变张量的 *x* 、 *y* 维度，但会改变通道维度。这就是为什么，如果你阅读关于盗梦空间网络的博客或书籍，你会读到这些核被用来减少张量的维数。

核 1 × 1 不改变张量的 *x* 、 *y* 维度，但会改变通道维度。这就是为什么它们经常被用来降低流经网络的张量的维数。

## 初始网络的历史和基础

初始网络最初是在 Szegedy 等人的一篇著名论文中提出的，这篇论文的标题是*用卷积深入*。 <sup>[1](#Fn1)</sup> 我们将详细讨论的这种新架构是在不增加计算预算的情况下，努力在图像识别任务中获得更好结果的结果。 <sup>[2](#Fn2)</sup> 添加越来越多的层将创建具有越来越多参数的模型，这将越来越困难并且训练缓慢。此外，作者希望找到一些方法，可以用在功能可能不如大型数据中心中使用的机器上。正如他们在论文中所述，他们的模型被设计为保持“推理时 15 亿乘加的计算预算”。重要的是，推断是廉价的，因为这样就可以在功能不那么强大的设备上进行；比如在手机上。

请注意，本章的目标不是分析关于初始网络的整篇原始论文，而是解释已经使用的新构建模块和技术，并向您展示如何在您的项目中使用它们。为了开发初始网络，我们将需要开始使用功能性 Keras APIs，使用多个损失函数，并使用并行而非顺序评估的层对数据集执行操作。我们也不会查看该架构的所有变体，因为这只会要求我们列出一些论文的结果，而不会给读者带来任何额外的价值(阅读原始论文会更好)。如果你有兴趣，我能给你最好的建议就是下载下来，研究一下原论文。你会在那里找到很多有趣的信息。但在本章结束时，你将拥有真正理解这些新网络的工具，并能够用 Keras 开发一个。

让我们回到“经典的”CNN。通常，这些都有一个标准的结构:堆叠的卷积层(当然有池)，后面是一组密集层。很容易通过增加层数、内核数量或大小来获得更好的结果。这导致过拟合问题，因此需要大量使用正则化技术(如 dropout)来解决这个问题。更大的尺寸(在层数和内核尺寸和数量方面)当然意味着更大数量的参数，因此需要越来越高的计算资源。总而言之，“经典”CNN 的一些主要问题如下:

*   获得正确的内核大小非常困难。每个图像都不一样。一般来说，较大的内核适合于全球分布的信息，较小的内核适合于本地分布的信息。

*   深度 CNN 容易过度拟合。

*   具有许多参数的网络的训练和推断是计算密集型的。

### 初始模块:天真的版本

为了克服这些困难，Szegedy 和论文合著者的主要思想是并行地执行与多尺寸核的卷积，以便能够同时检测不同尺寸的特征，而不是一层接一层地顺序添加卷积。据说这些类型的网络会变得更宽，而不是更深，而不是 T2。

比如我们可能同时并行的用 1 × 1，3 × 3，5 × 5 核做卷积，甚至 max pooling，而不是一个接一个的加几个卷积层。在图 [4-1](#Fig1) 中，你可以看到不同的卷积是如何在所谓的天真的*初始模块中并行完成的。*

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig1_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig1_HTML.jpg)

图 4-1

并行完成不同内核大小的不同卷积。这是在初始网络中使用的基本模块，称为初始模块。

在图 [4-1](#Fig1) 的例子中，1 × 1 内核将查看非常本地化的信息，而 5 × 5 内核将能够发现更多的全局特征。在下一节中，我们将看看如何使用 Keras 来开发这一功能。

### 初始模块中的参数数量

让我们看看盗梦空间和经典 CNN 在参数数量上的差异。假设我们考虑图 [4-1](#Fig1) 中的例子。假设“前一图层”是包含 MNIST 数据集的输入图层。为了便于比较，我们将对所有层或卷积运算使用 32 个内核。在初始模块中，每个卷积运算的参数数量为

*   1 × 1 卷积:64 个参数 <sup>[3 个](#Fn3)T3】</sup>

*   3 × 3 卷积:320 个参数

*   5 × 5 卷积:832 个参数

请记住，最大池操作没有可学习的参数。我们总共有 1216 个可学习的参数。现在，让我们假设我们创建了一个具有三个卷积层的网络，一个接一个。第一个具有 32 个 1 × 1 核，然后一个具有 32 个 3 × 3 核，最后一个具有 32 个 5 × 5 核。现在，各层中的参数总数将为(记住，例如，具有 32 个 3 × 3 内核的卷积层将具有 32 个 1 × 1 内核的卷积层的输出作为输入):

*   1 × 1 卷积层:64 个参数

*   具有 3 × 3 卷积的层:9248 个参数

*   具有 5 × 5 卷积的层:25632 个参数

总共有 34944 个可学习参数。参数数量大约是初始版本的 30 倍。您可以很容易地看到，这种并行处理大大减少了模型必须学习的参数数量。

### 具有降维的初始模块

在天真的初始模块中，相对于经典 CNN，我们得到的可学习参数数量较少，但实际上我们可以做得更好。我们可以在适当的地方使用 1 × 1 卷积(主要是在高维卷积之前)来降低维数。这允许我们在不增加计算预算的情况下使用越来越多的这种模块。在图 [4-2](#Fig2) 中，你可以看到这样一个模块的样子。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig2_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig2_HTML.jpg)

图 4-2

降维的初始模块示例

看到我们在这个模块中有多少可学习的参数是有益的。为了了解降维真正有帮助的地方，让我们假设前一层是前一个操作的输出，并且它的输出具有 256、28、28 的维度。现在让我们比较一下原始模块和图 [4-2](#Fig2) 中所示的降维模块。

天真模块:

*   8 核 1 × 1 卷积:2056 个参数 <sup>[4 个](#Fn4)</sup>

*   8 核 3 × 3 卷积:18440 个参数

*   8 核 5 × 5 卷积:51208 个参数

总共有 71704 个可学习参数。

降维模块:

*   8 核 1 × 1 卷积:2056 个参数

*   1 × 1 后跟 3 × 3 卷积:2640 个参数

*   1 × 1 后跟 5 × 5 卷积:3664 个参数

*   3 × 3 最大池，后跟 1 × 1 卷积:2056 个参数

总共有 10416 个可学习参数。对比一下可学习参数的数量，就能看出为什么说这个模块降维了。由于 1 × 1 卷积的智能放置，我们可以防止可学习参数的数量不受控制地激增。

一个初始网络简单地通过一个接一个地堆叠这些模块来构建。

## 多重成本函数:GoogLeNet

在图 [4-3](#Fig3) 中，你可以看到赢得`imagenet`挑战的 GoogLeNet 网络的主要结构。正如在开始引用的论文中所描述的，这个网络一个接一个地堆叠了几个初始模型。问题是，正如原始论文的作者很快发现的那样，中间层往往会“死亡”。这意味着他们在学习中不再扮演任何角色。为了让它们免于“死亡”，作者沿着网络引入了分类器，如图 [4-3](#Fig3) 所示。

网络的每个部分(图 [4-3](#Fig3) 中的部分 1、部分 2 和部分 3)将被训练为独立的分类器。这三个部分的训练不是独立发生的，而是同时发生的，与多任务学习中发生的非常相似(MTL)。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig3_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig3_HTML.jpg)

图 4-3

谷歌网络的高层架构

为了防止网络的中间部分变得不那么有效并逐渐消失，作者沿着网络引入了两个分类器，如图 [4-3](#Fig3) 中黄色方框所示。他们引入了两个中间损失函数，然后将总损失函数计算为辅助损失的加权和，有效地使用了通过以下公式评估的总损失:

```py
Total Loss = Cost Function 1 + 0.3 * (Cost Function 2) + 0.3 * (Cost Function 3)

```

其中`Cost Function 1`是用第一部分评估的成本函数，`Cost Function 2`是用第二部分评估的，`Cost Function 3`是用第三部分评估的。测试表明，这是非常有效的，你会得到一个比简单地训练整个网络作为一个单一的分类器更好的结果。当然，辅助损失仅用于训练，而不用于推理。

作者开发了几个版本的初始网络，模块越来越复杂。如果你感兴趣，你应该阅读原文，因为它们很有教育意义。在 [`https://arxiv.org/pdf/1512.00567v3.pdf`](https://arxiv.org/pdf/1512.00567v3.pdf) 可以找到作者的第二篇更复杂架构的论文。

## Keras 中的初始模块示例

使用 Keras 的功能 API 使得构建一个初始模块变得非常容易。让我们看看必要的代码。出于空间原因，我们将不使用数据集构建完整的模型，因为这将占用太多空间，并且会分散对主要学习目标的注意力，即了解如何使用 Keras 构建一个具有并行评估而非顺序评估的图层的网络。

为了这个例子，让我们假设我们的训练数据集是`CIFAR10`。 <sup>[5](#Fn5)</sup> 这是用图像做的，都是 32 × 32 带三个通道(图像是彩色的)。因此，首先我们需要定义网络的输入层:

```py
from keras.layers import Input
input_img = Input(shape = (32, 32, 3))

```

然后我们简单地定义一层接一层:

```py
from keras.layers import Conv2D, MaxPooling2D
tower_1 = Conv2D(64, (1,1), padding="same", activation="relu")(input_img)
tower_1 = Conv2D(64, (3,3), padding="same", activation='relu')(tower_1)
tower_2 = Conv2D(64, (1,1), padding="same", activation="relu")(input_img)
tower_2 = Conv2D(64, (5,5), padding="same", activation="relu")(tower_2)
tower_3 = MaxPooling2D((3,3), strides=(1,1), padding="same")(input_img)
tower_3 = Conv2D(64, (1,1), padding="same", activation="relu")(tower_3)

```

这段代码将构建如图 [4-4](#Fig4) 所示的模块。Keras 功能 API 易于使用:您可以将层定义为另一层的功能。每个函数返回适当维数的张量。好的一面是你不用担心尺寸问题；你可以简单地定义一层又一层。只要注意使用正确的输入即可。例如，用这一行:

```py
tower_1 = Conv2D(64, (1,1), padding="same", activation="relu")(input_img)

```

您定义了一个名为`tower_1`的张量，它是在使用`input_img`张量和 64 个 1 × 1 核进行卷积运算后计算的。然后这一行:

```py
tower_1 = Conv2D(64, (3,3), padding="same", activation="relu")(tower_1)

```

定义一个新的张量，它是通过 64 个 3 × 3 核与前一行的输出进行卷积而获得的。我们取输入张量，与 64 个 1 × 1 核进行卷积，然后再次与 64 个 3 × 3 核进行卷积。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig4_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig4_HTML.jpg)

图 4-4

从给定代码构建的初始模块

层的连接很容易:

```py
from keras.layers import concatenate
from tensorflow.keras import optimizers
output = concatenate([tower_1, tower_2, tower_3], axis = 3)

```

现在让我们添加几层文章:

```py
from keras.layers import Flatten, Dense
output = Flatten()(output)
out    = Dense(10, activation="softmax")(output)

```

然后我们最终创建模型:

```py
from keras.models import Model
model = Model(inputs = input_img, outputs = out)

```

然后可以像往常一样编译和训练这个模型。用法的一个例子可能是

```py
epochs = 50
model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)

```

假设训练数据集由数组`(X_train`和`y_train)`组成，验证数据集由`(X_test, y_test)`组成。

### 注意

在 inception 模块的所有卷积运算中，您必须使用`padding='same'`选项，因为卷积运算的所有输出必须具有相同的维数。

本节简要介绍了如何使用 Keras 的功能 API 开发更复杂的网络架构。现在你应该对盗梦空间网络的工作原理和基本构件有了基本的了解。

## 题外话:喀拉斯的风俗损失

有时，在 Keras 中开发自定义损失是很有用的。来自官方的 Keras 文档( [`https://keras.io/losses/`](https://keras.io/losses/) ):

> *您可以传递现有损失函数的名称，也可以传递 TensorFlow/Theano 符号函数，该函数为每个数据点返回一个标量，并采用以下两个参数:*

> `y_true` *:真标签。tensorlow/theano tensor。*

> `y_pred` *:预言。与* `y_true` *形状相同的 TensorFlow/Theano 张量。*

假设我们想要定义一个损失来计算预测的平均值。我们需要写这个

```py
import keras.backend as K
def mean_predictions(y_true, y_pred):
    return K.mean(y_pred)

```

然后我们可以简单地在编译调用中使用它，如下所示:

```py
model.compile(optimizer='rmsprop',
              loss=mean_predictions,
              metrics=['accuracy'])

```

尽管这与其说是损失，不如说是有意义的。现在这开始变得有趣了，损失函数可以仅使用特定层的中间结果来评估。但要做到这一点，我们需要使用一个小技巧。因为根据官方文档，该函数只能接受真实的标签和预测作为输入。为此，我们需要创建一个函数，返回一个只接受真实标签和预测的函数。看起来很复杂。让我们看一个例子来理解它。假设我们有这个模型:

```py
inputs = Input(shape=(512,))
x1 = Dense(128, activation=sigmoid)(inputs)
x2 = Dense(64, activation=sigmoid)(x1)
predictions = Dense(10, activation="softmax")(x2)
model = Model(inputs=inputs, outputs=predictions)

```

我们可以用这个代码 <sup>[6](#Fn6)</sup> 定义一个依赖于`x1`的损失函数(损失在做什么无关):

```py
def custom_loss(layer):
    def loss(y_true,y_pred):
        return K.mean(K.square(y_pred - y_true) + K.square(layer), axis=-1)
    return loss

```

那么我们可以像以前一样简单地使用损失函数:

```py
model.compile(optimizer='adam',
              loss=custom_loss(x1),
              metrics=['accuracy'])

```

这是一种开发和使用定制损耗的简单方法。如初始网络中所述，有时能够训练具有多个损失的模型也是有用的。Keras 已经准备好了。定义损失函数后，可以使用以下语法

```py
model.compile(loss = [loss1,loss2], loss_weights = [l1,l2], ...)

```

Keras 将用作损失函数

```py
l1*loss1+l2*loss2

```

考虑到每个损失只会影响输入和损失函数之间路径上的权重。在图 [4-5](#Fig5) 中，你可以看到一个分成不同部分的网络:`A`、`B`和`C`。使用`B`的输出和`C`的`loss2`计算`loss1`。因此，`loss1`只会影响`A`和`B`中的权重，而`loss2`会影响`A`、`B`和`C`中的权重，如图 [4-5](#Fig5) 所示。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig5_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig5_HTML.jpg)

图 4-5

多个损失函数对不同网络部分影响的示意图

顺便提一下，这种技术在所谓的*多任务学习* (MTL)中被大量使用。 <sup>[7](#Fn7)</sup>

## 如何使用预先训练的网络

Keras 提供预先训练的深度学习模型供您使用。这些被称为*应用*的模型可以用来预测新数据。这些模型已经在大数据集上进行了训练，因此不需要大数据集或长时间的训练。您可以在 [`https://keras.io/applications/`](https://keras.io/applications/) 的官方文档中找到所有申请信息。在撰写本文时，有 20 种型号可用，每一种都是以下型号之一的变体:

*   Xception

*   VGG16

*   VGG19

*   瑞斯网

*   ResNetV2

*   ResNeXt

*   不规则 3

*   InceptionResNetV2

*   MobileNet(移动网络)

*   MobileNetV2

*   DenseNEt

*   纳西网

让我们看一个例子，同时，让我们讨论函数中使用的不同参数。前期准备好的型号都在`keras.applications`包里。每个型号都有自己的包装。比如 ResNet50 在`keras.applications.resnet50`里。假设我们有一个想要分类的图像。我们可以使用 VGG16 网络，这是一个在图像识别方面非常成功的著名网络。我们可以从下面的代码开始

```py
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input , decode_predictions

import numpy as np

```

然后我们可以简单地用一行代码加载模型

```py
model = VGG16(weights='imagenet')

```

`weights`参数非常重要。如果权重为`None`，则权重被随机初始化。这意味着你得到了 VGG16 架构，你可以自己训练它。但是要知道，它大约有 1.38 亿个参数，所以你需要一个非常大的训练数据集和足够的耐心(以及非常强大的硬件)。如果您使用值`imagenet`，权重是通过使用`imagenet`数据集训练网络获得的。 <sup>[8](#Fn8)</sup> 如果你想要一个预先训练好的网络，你应该使用`weights = 'imagenet'`。

如果您在 Mac 上收到关于证书的错误信息，有一个简单的解决方案。上面的命令将尝试通过 SSL 下载权重，如果您刚刚从`python.org`安装了 Python，那么安装的证书将无法在您的机器上运行。只需打开一个 Finder 窗口，导航到`Applications/Python 3.7`(或者你已经安装的 Python 版本)，双击`Install Certificates.command`。将会打开一个终端窗口，并运行一个脚本。之后，`VGG16()`调用将正常工作，不会出现错误消息。

之后，我们需要告诉 Keras 图像在哪里(假设您将它放在 Jupyter 笔记本所在的文件夹中)并加载它:

```py
img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size = (224, 224))

```

你可以在 GitHub 库的第 4 章的文件夹中找到这个图片。之后我们需要

```py
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

```

首先，将图像转换为数组，然后需要扩展它的维度。意思如下:该模型处理成批图像，这意味着它将期望输入具有四个轴的张量(成批图像中的*索引*、沿 x 方向的*分辨率*、沿 y 方向的*分辨率*、*通道数量*)。但是我们的图像只有三个维度，水平和垂直分辨率以及通道的数量(在我们的例子中是三个，用于 RGB 通道)。我们需要为*样本*维度添加一个维度。更具体地说，我们的图像有维度(224，244，3)，但模型期望一个维度(1，224，224，3)的张量，所以我们需要添加第一个维度。

这可以用 numpy 函数`expand_dims()`来完成，它只是在张量中插入一个新的轴。 <sup>[9](#Fn9)</sup> 作为最后一步，您需要预处理输入图像，因为每个模型期望与`preprocess_input(x)`调用略有不同的东西(在+1 和-1 之间，或者在 0 和 1 之间，等等)。

现在，我们准备让模型预测图像的类别，如下所示:

```py
preds = model.predict(x)

```

要获得预测的前三类，我们可以使用`decode_predictions()`函数。

```py
print('Predicted:', decode_predictions(preds, top=3)[0])

```

它将产生(我们的图像)以下预测:

```py
Predicted: [('n02504013', 'Indian_elephant', 0.7278206), ('n02504458', 'African_elephant', 0.14308284), ('n01871265', 'tusker', 0.12798567)]

```

`decode_predictions()`以`(class_name, class_description, score).`的形式返回元组。第一个隐含的字符串是内部类名，第二个是描述(我们感兴趣的)，最后一个是概率。根据 VGG16 网络，我们的图像似乎有 72.8%的可能性是印度大象。我不是大象方面的专家，但我会相信这个模型。要使用不同的预训练网络(例如 ResNet50)，您需要更改以下导入:

```py
from keras.applications.resnet50 import ResNet50
from keras.applications.resnet50 import preprocess_input, decode_predictions

```

你定义模型的方式:

```py
model = ResNet50(weights='imagenet')

```

代码的其余部分保持不变。

## 迁移学习:导论

迁移学习是一种技术，在这种技术中，为解决特定问题而训练的模型被重新用于与第一个问题相关的新挑战。假设我们有一个多层网络。通常在图像识别中，第一层将学习检测一般特征，而最后一层将能够检测更具体的特征。 <sup>[11](#Fn11)</sup> 记住，在一个分类问题中，最后一层将有 *N* 个 softmax 神经元(假设我们正在分类 *N* 个类)，因此必须学会针对你的问题非常具体。你可以通过下面的步骤直观地理解迁移学习，这里我们介绍一些我们将在接下来的章节中使用的符号。假设我们有一个有 n 层*<sub>*L 层*</sub> 的网络。*

1.  *我们在与我们的问题相关的大数据集(称为*基础数据集*)上训练一个*基础网络*(或者得到一个预训练的模型)。例如，如果我们想要对狗的图像进行分类，我们可以在这个步骤中在`imagenet`数据集上训练一个模型(因为我们基本上想要对图像进行分类)。重要的是，在这一步，数据集有足够的数据，并且任务与我们想要解决的问题相关。让一个网络接受语音识别训练将不会擅长狗的图像分类。这个网络可能不适合你的特定问题。*

**   我们得到一个新的数据集，我们称之为*目标数据集*(例如，狗的品种图像)，这将是我们新的训练数据集。通常，该数据集将比步骤 1 中使用的数据集小得多。

     *   然后你训练一个新的网络，在*目标数据集*上叫做*目标网络***。目标网络通常会有相同的第一个 *n* <sub>*k*</sub> (与*n*<sub>*k*</sub><*n*<sub>*L*</sub>)层我们的基础网络。前几层的可学习参数(假设 1 到 *n* <sub>*k*</sub> ，带*n*<sub>*k*</sub><*n*<sub>*L*</sub>)继承自步骤 1 中训练的基网络，在目标网络的训练过程中不改变。仅训练最后的和新的层(在我们的例子中从层 *n* <sub>*K*</sub> 到 *n* <sub>*L*</sub> )。其想法是，从 1 到 *n* <sub>*k*</sub> (来自基础网络)的层将在步骤 1 中学习足够的特征来区分狗和其他动物，并且 *n* <sub>*k*</sub> 到 *n* <sub>*L*</sub> (在目标网络中)的层将学习所需的特征有时，您甚至可以使用从基础网络继承的权重作为权重的初始值来训练整个目标网络，尽管这需要更强大的硬件。*** 

 ***### 注意

如果目标数据集很小，最佳策略是冻结从基础网络继承的图层，因为否则很容易使小数据集过拟合。

这背后的想法是，你希望在步骤 1 中，基本网络已经学会足够好地从图像中提取一般特征，因此你希望使用这种学到的知识，并避免再次学习的需要。但是，为了更好地进行预测，您需要针对具体情况对网络的预测进行微调，优化目标网络提取与问题相关的特定要素(通常发生在网络的最后一层)的方式。

换句话说，你可以这样想。要识别狗的品种，你必须遵循以下步骤:

1.  你看着一张图片，决定它是不是一只狗。

2.  如果你在观察一只狗，你把它分成几大类(例如，梗)。

3.  之后，你把它们分成子类(例如，威尔士梗或西藏梗)。

迁移学习基于这样的想法，即步骤 1 和可能的步骤 2 可以从来自基本网络的大量通用图像(例如从`imagenet`数据集)中学习，并且步骤 3 可以在步骤 1 和步骤 2 中所学内容的帮助下通过小得多的数据集学习。

当目标数据集远小于基本数据集时，这是一个非常强大的工具，有助于避免训练数据集过拟合。

这种方法在用于预训练模型时非常有用。例如，使用在`imagenet`上训练的 VGG16 网络，然后仅重新训练最后几层通常是解决特定图像识别问题的极其有效的方式。您可以免费获得许多功能检测功能。请记住，在`imagenet`网络上训练这样的网络需要花费几千个 GPU 小时。对于没有必要的硬件和技术的研究人员来说，这通常是不可能的。在下一节中，我们将研究如何做到这一点。有了 Keras，这真的很容易，它将允许您解决图像分类问题的准确性，否则是不可能的。在图 [4-6](#Fig6) 中，你可以看到迁移学习过程的示意图。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig6_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig6_HTML.jpg)

图 4-6

迁移学习过程的示意图

## 狗和猫的问题

了解迁移学习在实践中如何工作的最好方法是在实践中尝试。我们的目标是能够尽可能地对狗和猫的图像进行分类，尽可能地用最少的努力(在计算资源上)。为了做到这一点，我们将使用狗和猫的图像数据集，你可以在 [`https://www.kaggle.com/c/dogs-vs-cats`](https://www.kaggle.com/c/dogs-vs-cats) 的 Kaggle 上找到这些图像。警告:下载差不多 800MB。在图 [4-7](#Fig7) 中，你可以看到一些我们需要分类的图像。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig7_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig7_HTML.jpg)

图 4-7

包含在狗对猫数据集中的图像的随机样本

### 迁移学习的经典方法

解决这个问题的简单方法是创建一个 CNN 模型，并用图像训练它。首先，我们需要加载图像并调整它们的大小，以确保它们都具有相同的分辨率。如果检查数据集中的图像，您会注意到每个图像都有不同的分辨率。要做到这一点，让我们调整所有的图像到(150，150)像素。在 Python 中，我们会这样使用:

```py
import glob
import numpy as np
import os

img_res = (150, 150)

train_files = glob.glob('training_data/*')
train_imgs = [img_to_array(load_img(img, target_size=img_res)) for img in train_files]
train_imgs = np.array(train_imgs)
train_labels = [fn.split('/')[1].split('.')[0].strip() for fn in train_files]

validation_files = glob.glob('validation_data/*')
validation_imgs = [img_to_array(load_img(img, target_size=img_res)) for img in validation_files]
validation_imgs = np.array(validation_imgs)
validation_labels = [fn.split('/')[1].split('.')[0].strip() for fn in validation_files]

```

假设我们在名为`training_data`的文件夹中有 3000 张训练图像，在名为`validation_data`的文件夹中有 1000 张验证图像，`train_imgs`和`validation_imgs`的形状如下:

```py
(3000, 150, 150, 3)
(1000, 150, 150, 3)

```

像往常一样，我们将需要正常化的图像。现在每个像素的值在 0 到 255 之间，并且是一个整数。首先，我们将数字转换为浮点型，然后除以 255 进行归一化，这样每个值现在都在 0 和 1 之间。

```py
train_imgs_scaled = train_imgs.astype('float32')
validation_imgs_scaled  = validation_imgs.astype('float32')
train_imgs_scaled /= 255
validation_imgs_scaled /= 255

```

如果你检查`train_labels`，你会看到它们是字符串:`'dog'`或`'cat'`。我们需要将标签转换成整数，特别是 0 和 1。为此，我们可以使用名为`LabelEncoder`的 Keras 函数。

```py
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(train_labels)
train_labels_enc = le.transform(train_labels)
validation_labels_enc = le.transform(validation_labels)

```

我们可以用以下代码检查标签:

```py
print(train_labels[10:15], train_labels_enc[10:15])

```

这将给出:

```py
['cat', 'dog', 'cat', 'cat', 'dog'] [0 1 0 0 1]

```

现在我们已经准备好构建我们的模型了。我们可以通过下面的代码轻松做到这一点:

```py
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras import optimizers

model = Sequential()

model.add(Conv2D(16, kernel_size=(3, 3), activation="relu",
                 input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, kernel_size=(3, 3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, kernel_size=(3, 3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(512, activation="relu"))
model.add(Dense(1, activation="sigmoid"))

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.RMSprop(),
              metrics=['accuracy'])

```

这是一个小型网络，其结构如下:

```py
Layer (type)                 Output Shape              Param #
==============================================================
conv2d_3 (Conv2D)            (None, 148, 148, 16)      448
______________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 74, 74, 16)        0
______________________________________________________________
conv2d_4 (Conv2D)            (None, 72, 72, 64)        9280
______________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0
______________________________________________________________
conv2d_5 (Conv2D)            (None, 34, 34, 128)       73856
______________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 17, 17, 128)       0
______________________________________________________________
flatten_1 (Flatten)          (None, 36992)             0
______________________________________________________________
dense_2 (Dense)              (None, 512)               18940416
______________________________________________________________
dense_3 (Dense)              (None, 1)                 513
==============================================================
Total params: 19,024,513
Trainable params: 19,024,513
Non-trainable params: 0
______________________________________________________________

```

在图 [4-8](#Fig8) 中，您可以看到网络的示意图，以便了解层序列。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig8_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig8_HTML.jpg)

图 4-8

网络的示意图，让您了解层序列

此时，我们可以使用以下内容训练网络:

```py
batch_size = 30
num_classes = 2
epochs = 2
input_shape = (150, 150, 3)
model.fit(x=train_imgs_scaled, y=train_labels_enc,
                    validation_data=(validation_imgs_scaled, validation_labels_enc),
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1)

```

通过两个时期，我们达到了大约 69%的验证准确率和 70%的训练准确率。不是一个好结果。让我们看看我们能否在短短两个时代内做得比这更好。在两个时期内这样做的原因仅仅是为了快速检查不同的可能性。对这样的网络进行多次训练只需几个小时。请注意，该模型过度拟合了训练数据。当训练更多的纪元时，这变得清晰可见，但这里的主要目标不是获得最佳模型，而是看看如何使用预训练的模型来获得更好的结果，所以我们将忽略这个问题。

现在我们来导入 VGG16 预训练网络。

```py
from tensorflow.keras.applications import vgg16
from tensorflow.keras.models import Model
import tensorflow.keras as keras

base_model=vgg16.VGG16(include_top=False, weights="imagenet")

```

请注意，`include_top=False`参数删除了网络的最后三个完全连接的层。这样，我们可以将自己的层附加到基本网络中，代码如下:

```py
from tensorflow.keras.layers import Dense,GlobalAveragePooling2D
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dense(1024,activation='relu')(x)
preds=Dense(1,activation='softmax')(x)
model=Model(inputs=base_model.input,outputs=preds)

```

我们添加了一个 pooling 层，然后是一个有 1024 个神经元的`Dense`层，然后是一个有一个神经元的输出层，这个神经元有一个 softmax 激活函数，做二分类。我们可以使用以下内容检查结构:

```py
model.summary()

```

输出很长，但是最后你会发现:

```py
Total params: 15,242,050
Trainable params: 15,242,050
Non-trainable params: 0

```

目前所有的 22 层都是可训练的。为了能够真正进行迁移学习，我们需要冻结 VGG16 基础网络的所有层。为此，我们可以做到以下几点:

```py
for layer in model.layers[:20]:
    layer.trainable=False
for layer in model.layers[20:]:
    layer.trainable=True

```

该代码将前 20 层设置为不可训练状态，后两层设置为可训练状态。然后我们可以如下编译我们的模型:

```py
model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

```

注意，我们使用了`loss='sparse_categorical_crossentropy'`来使用标签，而不必对它们进行热编码。正如我们之前所做的，我们现在可以训练网络:

```py
model.fit(x=train_imgs_scaled, y=train_labels_enc,
                    validation_data=(validation_imgs_scaled, validation_labels_enc),
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1)

```

请注意，虽然我们只训练了网络的一部分，但这将比我们之前尝试的简单网络需要更多的时间。结果将是两个时期内惊人的 88%。比以前好得多的结果！您的输出应该如下所示:

```py
Train on 3000 samples, validate on 1000 samples
Epoch 1/2
3000/3000 [==============================] - 283s 94ms/sample - loss: 0.3563 - acc: 0.8353 - val_loss: 0.2892 - val_acc: 0.8740
Epoch 2/2
3000/3000 [==============================] - 276s 92ms/sample - loss: 0.2913 - acc: 0.8730 - val_loss: 0.2699 - val_acc: 0.8820

```

这要归功于预先训练好的第一层，这为我们节省了很多工作。

### 迁移学习实验

如果我们想为目标网络尝试不同的体系结构，并且想再增加几层并重试，该怎么办？前一种方法有一个小小的缺点:我们需要在每次事件中训练整个网络，尽管只需要训练最后几层。从上一节可以看出，一个时期大约需要 4.5 分钟。我们能更有效率吗？事实证明我们可以。

考虑图 [4-9](#Fig9) 中描述的配置。

![../images/470317_1_En_4_Chapter/470317_1_En_4_Fig9_HTML.jpg](../images/470317_1_En_4_Chapter/470317_1_En_4_Fig9_HTML.jpg)

图 4-9

实践中一种更灵活的迁移学习方式的示意图

我们的想法是生成一个新的数据集，我们称之为带有冻结图层的*要素数据集* ***、*** 。由于它们不会因训练而改变，这些层将总是生成相同的输出。我们可以使用这个特征数据集作为一个小得多的网络(我们称之为*目标子网*)的新输入，该网络仅由我们在上一节中添加到基础层的新层构成。我们只需要训练几层，这样会快很多。生成要素数据集将需要一些时间，但这必须只进行一次。此时，您可以为目标子网测试不同的架构，并为您的问题找到最佳配置。让我们看看如何在 Keras 做到这一点。基础数据集准备与之前相同，因此我们不再重复。

让我们像以前一样导入 VGG16 预训练网络:

```py
from tensorflow.keras.applications import vgg16
from tensorflow.keras.models import Model
import tensorflow.keras as keras

vgg = vgg16.VGG16(include_top=False, weights="imagenet",
                                     input_shape=input_shape)

output = vgg.layers[-1].output
output = keras.layers.Flatten()(output)
vgg_model = Model(vgg.input, output)

vgg_model.trainable = False
for layer in vgg_model.layers:
    layer.trainable = False

```

其中`input_shape`为`(150, 150, 3)`。

我们可以简单地用几行代码生成`features`数据集(使用`predict`功能):

```py
def get_ features(model, input_imgs):
    features = model.predict(input_imgs, verbose=0)
    return features

train_features_vgg = get_features(vgg_model, train_imgs_scaled)
validation_features_vgg = get_features(vgg_model, validation_imgs_scaled)

```

请注意，在现代笔记本电脑上，这将需要几分钟时间。在现代的 MacBook Pro 上，这将需要 40 分钟的 CPU 时间，这意味着如果你有更多的核心/线程，它将占用其中的一小部分。在我的笔记本电脑上，只需要 4 分钟。请记住，由于我们使用了参数`include_top = False`，网络末端的三个`dense`层已经被移除。`train_features_vgg`将只包含基本网络最后一层的输出，而没有最后三个`dense`层。此时，我们可以简单地构建我们的目标子网:

```py
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from tensorflow.keras.models import Sequential
from tensorflow.keras import optimizers

input_shape = vgg_model.output_shape[1]

model = Sequential()
model.add(InputLayer(input_shape=(input_shape,)))
model.add(Dense(512, activation="relu", input_dim=input_shape))
model.add(Dropout(0.3))
model.add(Dense(512, activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(1, activation="sigmoid"))

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.Adam(lr =1e-4),
              metrics=['accuracy'])

model.summary()

```

训练这个网络会比以前快很多。您将在几秒钟内获得 90%的准确率(请记住，这次您已经创建了一个新的训练数据集)。但是现在你可以改变这个网络，测试不同的架构会快得多。这一次，一个历元只需要 6 秒钟，而前一个例子需要 4.5 分钟。这个方法比前一个效率高得多。我们将培训分为两个阶段:

1.  创建要素数据集。只做过一次。(在我们的示例中，这需要大约四分钟。)

2.  使用要素数据集作为输入，将新图层训练为独立网络。(每个时期需要 6 秒钟。)

如果我们想训练我们的网络 100 个纪元，用这种方法我们需要 14 分钟。使用上一节描述的方法，我们将需要 7.5 小时！缺点是您需要为每个想要使用的数据集创建新的要素数据集。在我们的例子中，我们需要为训练和验证数据集这样做。

<aside class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

原文可以在 arXiv 档案上通过以下链接获得: [`http://toe.lt/4`](http://toe.lt/4) 。

  [2](#Fn2_source)

通过计算预算，我们可以确定执行特定计算(例如，训练网络)所需的时间和硬件资源。

  [3](#Fn3_source)

记住在这种情况下，我们有一个权重和一个偏差。

  [4](#Fn4_source)

记住在这种情况下，我们有一个权重和一个偏差。

  [5](#Fn5_source)

您可以在 [`https://www.cs.toronto.edu/~kriz/cifar.html`](https://www.cs.toronto.edu/%257Ekriz/cifar.html) 找到数据集的所有信息。

  [6](#Fn6_source)

代码的灵感来自 [`http://toe.lt/7`](http://toe.lt/7) 。

  [7](#Fn7_source)

你可以在 [`https://en.wikipedia.org/wiki/Multi-task_learning`](https://en.wikipedia.org/wiki/Multi-task_learning) 找到更多信息

  [8](#Fn8_source)

[T2`http://www.image-net.org`](http://www.image-net.org)

  [9](#Fn9_source)

您可以在 [`http://toe.lt/5`](http://toe.lt/5) 查看该功能的官方文档。

  [10](#Fn10_source)

这个术语已经被洋辛基用在了 [`https://arxiv.org/abs/1411.1792`](https://arxiv.org/abs/1411.1792) 中。

  [11](#Fn11_source)

你可以在 [`https://arxiv.org/abs/1411.1792`](https://arxiv.org/abs/1411.1792) 找到 Yosinki 等人关于这个主题的一篇非常有趣的论文。

 </aside>***