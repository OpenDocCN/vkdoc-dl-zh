# 1.深度学习和 Keras 简介

在这一章中，我们将探索深度学习(DL)领域，并对其进行简要介绍，然后再看一看 DL 开发可用框架的流行选择。我们还将进一步了解 Keras 生态系统，以了解它的特殊之处，并查看示例代码，了解该框架对于开发 DL 模型有多简单。

让我们开始吧。

## 数字图书馆简介

我们将首先从一个正式的定义开始，然后处理一个简单的方法来描述这个主题。

> DL 是人工智能(AI)中机器学习(ML)的一个子领域，它处理从大脑的生物结构和功能中受到启发的算法，以帮助机器获得智能。

也许这是太高的水平，或者可能很难消费，所以让我们一步一步地分解它。我们在定义中看到三个重要的术语，按照特定的顺序:DL、ML 和 AI。让我们先从人工智能开始，逐个解决这些流行词。

### 揭开流行语的神秘面纱

人工智能最一般的形式可以被定义为引入机器的智能质量。机器通常是愚蠢的，所以为了让它们更聪明，我们在它们身上引入某种智能，让它们能够独立做出决定。一个例子是洗衣机，它可以决定正确的用水量以及浸泡、洗涤和脱水所需的时间；也就是说，当提供特定输入时，它会做出决定，因此以更智能的方式工作。同样，自动提款机可以根据机器中可用的正确纸币组合来支付你想要的金额。这种智能是以人工方式在机器中诱导出来的，因此得名 AI。

另一点需要注意的是，这里的智能是显式编程的，比如一个 if-else 规则的综合列表。设计系统的工程师仔细考虑了所有可能的组合，并设计了一个基于规则的系统，该系统可以通过遍历定义的规则路径来做出决策。如果我们需要在没有显式编程的情况下在机器中引入智能，可能是机器可以自己学习的东西，会怎么样？那就是我们和 ML 接触的时候。

> *机器学习可以定义为在没有显式编程的情况下，将智能引入系统或机器的过程。*
> 
> —安德鲁·吴，斯坦福大学兼职教授

ML 的例子可以是通过从历史测试结果和学生属性中学习来预测学生是否会在测试中失败或通过的系统。在这里，系统并没有用一个所有可能的规则的综合列表来编码，这些规则可以决定一个学生是通过还是失败；相反，系统根据从历史数据中学习到的模式自行学习。

那么，DL 在这种情况下处于什么位置呢？虽然 ML 对于各种问题都非常有效，但它在一些对人类来说似乎非常简单的特定情况下却表现不佳:例如，将图像分类为猫或狗，区分音频剪辑是男性还是女性的声音，等等。ML 在处理图像和其他非结构化数据类型时表现不佳。在研究这种糟糕表现的原因时，一个灵感导致了模仿人类大脑生物过程的想法，人类大脑由数十亿个神经元连接和协调组成，以适应学习新事物。与此同时，神经网络已经成为一个研究课题好几年了，但是由于当时计算和数据的限制，只取得了有限的进展。当研究人员到达 ML 和神经网络的尖端时，出现了 DL 领域，它是通过开发深度神经网络(DNNs)来构建的，即具有许多更多层的临时神经网络。DL 擅长于 ML 落后的新领域。在适当的时候，额外的研究和实验导致了对我们可以在哪里利用 DL 来完成所有 ML 任务的理解，并且期望更好的性能，只要有剩余的数据可用性。因此，DL 成为解决预测问题的一个无处不在的领域，而不仅仅局限于计算机视觉、语音等领域。

今天，我们可以利用 DL 来处理几乎所有早期使用 ML 解决的用例，并期望超越我们以前的成就，只要有多余的数据。这种认识导致了基于数据区分字段的顺序。建立了一个新的经验法则:在某个阈值之后，ML 不能通过增加训练数据来提高性能，而 DL 能够更有效地利用剩余数据来提高性能。几年前统计模型和 ML 之间的争论也是如此。下图展示了上述三个字段的数据大小对模型性能的总体影响。

![img/475458_1_En_1_Figa_HTML.jpg](img/475458_1_En_1_Figa_HTML.jpg)

现在，如果我们重新审视形式定义，你可能会更好地理解 ML 的 AI 子场是由人脑的生物学方面激发的这一说法。我们可以使用简单的文氏图简化这三个字段，如下所示。

![img/475458_1_En_1_Figb_HTML.jpg](img/475458_1_En_1_Figb_HTML.jpg)

综合起来，我们可以说，AI 是人工地将智能诱导到机器或系统中的领域，有或没有显式编程。人工智能是人工智能中的一个子领域，其中智能是在没有显式编程的情况下诱导的。最后，DL 是 ML 中的一个领域，在这里，智能被引入到系统中，而无需使用算法的显式编程，这些算法是由人脑的生物功能所启发的。

### DL 在当今市场上解决了哪些经典问题？

今天，我们可以在数字世界的日常生活中看到 DL 的应用。如果你在社交媒体上很活跃，你可能已经注意到脸书建议你在上传照片时给你的朋友加标签。还要注意特斯拉汽车中的自动驾驶模式，你的 iOS 或 Android 手机上的消息系统中的下一个单词的预测，Alexa，Siri 和谷歌助手对你作为人类的回应，等等。如果我们试图分析我们可以使用 DL 解决的用例类型，我们已经可以在当今世界中使用的几乎任何系统中见证 DL 的力量。

### 分解 DL 模型

在其最基本的形式中，使用神经网络架构来设计 DL 模型。神经网络是神经元(类似于大脑中的神经元)与其他神经元连接的分层组织。这些神经元根据收到的输入向其他神经元传递消息或信号，并形成一个复杂的网络，通过某种反馈机制进行学习。

下面是一个基本神经网络的简单表示。

![img/475458_1_En_1_Figc_HTML.jpg](img/475458_1_En_1_Figc_HTML.jpg)

正如您在前面的图中所看到的，输入数据被第一个隐藏层中的神经元所消耗，然后向下一层提供输出，依此类推，最终得到最终的输出。每层可以有一个或多个神经元，每个神经元将计算一个小函数(例如，激活函数)。连续层的两个神经元之间的连接将具有相关联的权重。权重定义了输入对下一个神经元的输出的影响，以及最终对整个最终输出的影响。在神经网络中，初始权重在模型训练期间都是随机的，但是这些权重被迭代更新以学习预测正确的输出。分解网络，我们可以定义几个逻辑构建块，如神经元、层、权重、输入、输出、神经元内部的激活函数来计算学习过程，等等。

为了直观的理解，让我们举一个人类大脑如何学习识别不同人的例子。当你第二次遇见一个人时，你就能认出他。这是怎么发生的？人在整体结构上有相似之处；两只眼睛，两只耳朵，一个鼻子，嘴唇，等等。每个人都有相同的结构，但我们能够很容易地区分人，对不对？

大脑中学习过程的本质是相当直观的。大脑不是学习面部的结构来识别人，而是学习与普通面部的偏差(例如，个人的眼睛与参考眼睛有多不同)，然后可以量化为具有定义强度的电信号。同样，它从一个参考基准中学习人脸所有部分的偏差，并将这些偏差组合成新的维度，最后给出一个输出。所有这一切发生得如此之快，以至于我们没有人意识到我们的潜意识实际上做了什么。

同样，上图中展示的神经网络试图使用数学方法来模拟相同的过程。输入由第一层中的神经元消耗，并且在每个神经元内计算激活函数。基于一个简单的规则，它将输出转发给下一个神经元，类似于人脑学习的偏差。神经元的输出越大，输入维度的重要性就越大。然后，这些维度在下一层中组合起来，形成额外的新维度，我们可能无法理解这些维度。但是系统凭直觉学习。这一过程，当乘以几倍，发展成一个复杂的网络与几个连接。

现在已经了解了神经网络的结构，让我们来了解学习是如何发生的。当我们向已定义的结构提供输入数据时，最终输出将是一个预测，它可能是正确的，也可能是不正确的。基于输出，如果我们向网络提供反馈，以通过使用一些手段来进行更好的预测而更好地适应，则系统通过更新连接的权重来学习。为了实现提供反馈和定义下一步以正确的方式做出改变的过程，我们使用了一种称为“反向传播”的漂亮的数学算法随着越来越多的数据，逐步迭代该过程几次，有助于网络适当地更新权重，以创建一个系统，在该系统中，它可以根据它通过权重和连接为自己创建的规则来做出预测输出的决策。

“深度神经网络”这个名称是从使用更多隐藏层演变而来的，使其成为学习更复杂模式的“深度”网络。DL 的成功故事在最近几年才浮出水面，因为训练网络的过程计算量很大，需要大量数据。只有当计算机和数据存储变得更容易获得和负担得起时，这些实验才最终得以实现。

## 探索流行的 DL 框架

鉴于 DL 的采用已经以惊人的速度发展，生态系统的成熟度也有了显著的提高。多亏了许多大型技术组织和开源项目，我们现在有了太多的选择。在我们深入研究各种框架的细节之前，让我们理解为什么我们本质上需要一个框架，以及什么可以作为替代。

让我们从理解软件行业如何在框架中发展开始。

如果你观察软件业的发展，你会明白今天开发高端软件比几年前容易得多。这归功于可用的工具，它们以简单易用的方式自动化或抽象了复杂的问题。技术兄弟会在贡献伟大的想法方面是仁慈的和创新的。我们在以前服务的基础上构建新的服务，最终将创建一个复杂的服务，它将能够编排服务集合，同时又是安全的和可伸缩的。鉴于目前可用的软件工具的成熟度，我们可以抽象出后台发生的一些复杂性。这些工具只不过是软件系统的构建模块。你在技术上不需要从头开始；相反，你可以依靠已经非常成熟的强大工具来处理一些软件构建服务。

类似地，在 DL 中，有一组代码块可以被不同类型的用例重用。具有不同参数值的相同算法可以用于不同的用例，那么为什么不将算法打包成一个简单的函数或类呢？DL 的几个方面已经被开发成可重用的代码，现在可以从框架中直接使用，这些框架在抽象概念方面做得很好。DL 模型中的构件包括神经元、激活函数、优化算法、数据扩充工具等等。你真的可以用大约 1000 行代码从零开始开发一个 DNN，比如用 C++、Java 或 Python，或者使用一个框架，用 10-15 行代码重用可用的工具。话虽如此，让我们来看看当今业界使用的 DL 框架的流行选择。

### 低级 DL 框架

给定框架提供的抽象级别，我们可以将其分类为低级或高级 DL 框架。虽然这绝不是业界公认的术语，但是我们可以使用这种分离来更直观地理解框架。下面是一些流行的 DL 底层框架。

#### 提亚诺

Theano 是第一批广受欢迎的 DL 库之一。它是由蒙特利尔大学的蒙特利尔学习算法研究所(MILA)开发的。Theano 是一个开源 Python 库，于 2007 年推出；上一个主要版本由 MILA 于 2017 年底发布。

更多详细信息，请访问

*   [T2`http://deeplearning.net/software/theano/`](http://deeplearning.net/software/theano/)

*   [T2`https://github.com/Theano/Theano/`](https://github.com/Theano/Theano/)

#### 火炬

Torch 是另一个基于 Lua 编程语言的流行 ML 和 DL 框架。它最初是由 Ronan Collobert，Koray Kavukcuoglu 和 Clement Farabet 开发的，但后来由脸书用一组扩展模块作为开源软件进行了改进。

更多详细信息，请访问

*   [T2`http://torch.ch/`](http://torch.ch/)

#### PyTorch

PyTorch 是 Python 的开源 ML 和 DL 库，由脸书人工智能研究团队开发。PyTorch 比 Torch 更受欢迎，因为任何对 Python 有基本了解的人都可以开始开发 DL 模型。此外，PyTorch 对于 DL 开发来说更加容易和透明。

更多详细信息，请访问

*   [T2`https://pytorch.org/`](https://pytorch.org/)

#### mxnet 系统

MxNet 发音为“mix-net”，代表“混合”和“最大化”，由来自 CMU、NYU、新加坡国立大学、麻省理工学院和其他机构的研究人员开发。这个想法被简化为将声明性和命令性编程结合在一起(混合)以最大化效率和生产力。它支持使用多个 GPU，并得到了 AWS 和 Azure 等主要云提供商的广泛支持。

更多详细信息，请访问

*   [T2`https://mxnet.apache.org/`](https://mxnet.apache.org/)

#### TensorFlow

TensorFlow 无疑是 DL 兄弟会中最流行、使用最广泛的 DL 框架之一。它由 Google 开发并开源，支持跨 CPU、GPU 以及移动和边缘设备的部署。它于 2015 年 11 月发布，随后在行业内的采用率大幅上升。

*   [T2`www.tensorflow.org/`](http://www.tensorflow.org/)

DL 框架的列表很长，讨论所有这些超出了本书的范围。您还可以研究其他一些流行的框架，如 Caffe、Microsoft CNTK、Chainer、PaddlePaddle 等等。讨论一个框架相对于另一个框架的利弊是另一个有趣且永无止境的争论。我强烈建议您探索并理解每个框架所能提供的改进。

这将是一个很好的起点:

*   [T2`https://blogs.technet.microsoft.com/machinelearning/2018/03/14/comparing-deep-learning-frameworks-a-rosetta-stone-approach/`](https://blogs.technet.microsoft.com/machinelearning/2018/03/14/comparing-deep-learning-frameworks-a-rosetta-stone-approach/)

### 高级 DL 框架

前面提到的框架可以被定义为 DL 模型的第一级抽象。您仍然需要编写相当长的代码和脚本来准备好您的 DL 模型，尽管这比只使用 Python 或 C++要少得多。使用第一级抽象的优点是它在设计模型时提供了灵活性。

然而，为了简化 DL 模型的过程，我们有工作在第二级抽象上的框架；也就是说，我们可以在现有框架的基础上使用新的框架，从而进一步简化 DL 模型开发，而不是直接使用前面提到的框架。

最流行的高级 DL 框架是 Keras，它为 DL 模型开发提供了二级抽象。也有其他框架，如 Gluon、Lasagne 等，但 Keras 是被最广泛采用的一个。

### 注意

虽然 Gluon 在 MxNet 上工作，Lasagne 在 Theano 上工作，但 Keras 可以在 TensorFlow、Theano、MxNet 和 Microsoft CNTK 上工作。这个列表一直在积极地扩展，很可能在你读这本书的时候，会有更多的列表被添加进来。

Keras 是一个用 Python 编写的高级神经网络 API，可以帮助您用不到 15 行代码开发一个全功能的 DL 模型。因为它是用 Python 编写的，所以它有更大的用户和支持者群体，并且非常容易上手。Keras 的简单之处在于，它帮助用户快速开发 DL 模型，并提供大量的灵活性，同时仍然是一个高级 API。这确实使 Keras 成为一个特殊的工作框架。此外，考虑到它支持其他几个框架作为后端，它增加了灵活性，可以根据需要为不同的用例利用不同的低级 API。到目前为止，Keras 最广泛采用的用法是将 TensorFlow 作为后端(即，Keras 作为高级 DL API，TensorFlow 作为其低级 API 后端)。简而言之，您在 Keras 中编写的代码被转换为 TensorFlow，然后在计算实例上运行。

你可以在这里阅读更多关于 Keras 及其最近的发展: [`https://keras.io/`](https://keras.io/)

## 先睹为快 Keras 框架

既然我们已经了解了可用于 DL 的不同框架以及使用其中一个的需要，在我们结束本章之前，我们可以先睹为快为什么 Keras 在 DL 开发中具有不公平的优势。我们肯定会在下一章更深入地了解 Keras 所提供的东西，但是在我们结束这一章之前看看 Keras 的美丽是很有趣的。

看看下面展示的 DNN。

![img/475458_1_En_1_Figd_HTML.jpg](img/475458_1_En_1_Figd_HTML.jpg)

是的，这就是我们之前在探索主题“分解 DL 模型”时看到的同一个图如果我们试图定义这个网络，我们可以说它是一个 DNN，有两个隐藏层，分别有五个和四个神经元。第一隐藏层接受具有三维的输入数据，并在具有两个神经元的输出层中给出输出。

为了更直观地理解这一点，我们可以假设这是一个简单的 DNN，用于解决基于一些输入数据预测学生是否会通过或失败的问题。

假设我们有年龄、学习的小时数以及他作为输入数据点出现的所有先前测试的平均分(满分为 100)。

在 Keras 中构建神经网络就像下面的脚本一样简单。此刻不理解后面的全部代码是绝对没问题的；我们将在下一章一步一步更详细地探讨这一点。

```py
#Import required packages
from keras.models import Sequential
from keras.layers import Dense
import numpy as np

# Getting the data ready
# Generate train dummy data for 1000 Students and dummy test for 500
#Columns :Age, Hours of Study &Avg Previous test scores
np.random.seed(2018). #Setting seed for reproducibility
train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))
#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)
labels = np.random.randint(2, size=(1000, 1))

#Defining the model structure with the required layers, # of neurons, activation function and optimizers
model = Sequential()
model.add(Dense(5, input_dim=3, activation="relu"))
model.add(Dense(4, activation="relu"))
model.add(Dense(1, activation="sigmoid"))
model.compile(loss='binary_crossentropy', optimizer="adam", metrics=['accuracy'])

#Train the model and make predictions
model.fit(train_data, labels, epochs=10, batch_size=32)
#Make predictions from the trained model
predictions = model.predict(test_data)

```

前面的代码可以分为三个部分。

### 准备好数据

通常，我们会花一些时间来导入和研究数据内容，并对数据进行必要的扩充，作为模型的输入。在这里，由于这是一个虚拟用例，我们只是使用 Python 的 numpy 包中的随机数生成器来为 1000 名学生创建一个虚拟训练数据集，为 500 名学生创建另一个虚拟测试数据集，最后是学生的标签或实际输出(即，他们是通过还是失败)。

### 定义模型结构

一旦我们以必要的格式准备好数据，我们将需要首先设计 DNN 的结构。我们定义了层的数量和类型、每层中神经元的数量、所需的激活函数、要使用的优化器以及其他一些网络属性。

### 训练模型并进行预测

一旦定义了网络，我们就可以使用带有正确预测的训练数据，通过模型的“拟合”方法来训练网络。最后，一旦模型被训练，我们可以使用训练好的模型对新的测试数据集进行预测。

虽然这个例子过于简单，但我希望它能让您理解使用 Keras 框架开发 DL 模型是多么容易。如果在这一点上理解代码是压倒性的，那绝对没问题。我们将在下一章一步一步地详细讨论代码。

## 摘要

在本章中，我们通过简单的介绍学习了数字图书馆的基础知识，并探索了一些在日常数字生活中利用数字图书馆的常见使用案例。然后，我们研究了使用 DL 框架开发模型的必要性，并探索了行业中可用的一些低级和高级框架。然后我们看了 Keras，这是本书的首选框架，用一个简单的虚拟例子来说明创建 DL 模型的简单性。

在下一章中，我们将深入了解 Keras 及其提供的各种构建模块。我们将尝试使用 Keras 和 Python 开发一个简单的 DL 模型，并进行动手练习。