# 5.调整和部署深度神经网络

到目前为止，在本书的旅程中，我们主要讨论了如何为一个给定的用例开发一个 DNN，并且查看了一些策略和经验法则来绕过我们在这个过程中可能面临的障碍。在这一章中，我们将讨论开发初始模型之后的旅程，探索当开发的模型没有达到您的期望时，您需要实现的方法和途径。我们将讨论正则化和超参数调整，在本章的最后，我们还将对调整后部署模型的过程有一个高层次的了解。然而，我们实际上不会讨论部署的实现细节；这只是一个概述，提供了在这一过程中取得成功的指南。让我们开始吧。

## 过度拟合的问题

在开发和训练 ML 和 DL 模型的过程中，您经常会遇到这样的情况:经过训练的模型在训练数据集上表现良好，但在测试数据集上表现不佳。在数据科学中，这种现象被称为“过度拟合”。从字面上看，你的模型过度拟合了数据。虽然你在本书的前面已经遇到过这个术语，但是到目前为止我们还没有详细讨论过这个话题。让我们试着用一种更简化的方式来理解这种现象。

训练一个模型的过程叫做“拟合数据”；神经网络学习数据中的潜在模式，并在数学上改进模型权重/结构，以适应它在学习过程中发现的模式。简而言之，训练模型会调整其结构(权重)以适应数据(模式)，从而提高其性能。当它发现的模式在现实中仅仅是噪音时，这个美丽的过程就变得复杂了。不幸的是，数学方程并不具有总是区分信号和噪声的能力(对于噪声，我们指的是不代表训练样本但由于随机机会而出现的数据点)。当它失败时，它也学习噪声并调整它的权重以适应新的信号，这实际上是噪声。

为了理解这个过程，我们举一个简单的例子。比如说一个五岁的孩子爱吃妈妈烤的蛋糕。他要求每天在家烤蛋糕。他的母亲礼貌地拒绝了这些要求，但向他保证，她会在某些场合烤蛋糕。小男孩现在期待着每一个新的一天，希望这将是他妈妈烤蛋糕的一个机会。另一方面，他的母亲并不想找机会烤蛋糕。她每周日下班后都会烤一个蛋糕。这个五岁的孩子继续每天观看，慢慢地知道他的妈妈会在每个星期天烤一个蛋糕。所以，他学会了下面的模式:“如果 day == Sunday，那么妈妈会烤蛋糕。”一个晴朗的星期天，他的母亲不得不出差，没有时间烤蛋糕。这个五岁的孩子无法理解他的模式被打破了。因此，为了适应新的事件，他修改了他的规则，制定了新的模式如下:“如果 day == Sunday，那么妈妈将烤一个蛋糕，但如果这一天是在一个月的最后一周，那么没有蛋糕。”事实上，他妈妈错过烤蛋糕的那个星期天是一个噪音。理想情况下，他应该忽略这一点，并保持他之前学到的模式不变。但不幸的是，他未能区分信号和噪音，从而使他的规则过于复杂，数据过于拟合。

类似地，当 DL 模型从噪声中学习并通过调整权重来适应噪声时，它会过度拟合数据。这个问题变得很严重，因为学习噪声会导致模型性能的显著下降。这就是为什么您会观察到模型在训练数据上的性能和在看不见的数据上的性能之间有很大的差距。通过正则化，可以在很大程度上(尽管不是完全)避免这个问题，并定制模型的学习过程，以仅适应信号(或真实模式)而不是噪声。

## 那么，什么是正规化呢？

简而言之，正则化是一个减少过度拟合的过程。这是一种数学方法，当模型适应噪声时，将警告引入模型的学习过程。为了给出更现实的定义，这是一种在过度拟合的情况下惩罚模型权重的方法。

让我们用一种非常简单的方式来理解这个过程。在 DL 中，神经元连接的权重在每次迭代后更新。当模型遇到有噪声的样本并假设该样本是有效样本时，它会尝试通过更新与噪声一致的权重来适应该模式。在真实的数据样本中，噪声数据点不像任何接近常规数据点的东西；他们离他们很远。因此，权重更新也将与噪声同步(即，权重的变化将是巨大的)。正则化过程将边缘的权重添加到定义的损失函数中，并且整体上表示更高的损失。然后，网络调整自身以减少损失，从而使权重在正确的方向上更新；这是通过忽略噪音而不是在学习过程中适应噪音来实现的。

正则化的过程可以表示为

*成本函数=* ***损失*** *(如模型定义)+* ***超参数***×****权重****】**

 *超参数表示为![$$ \frac{\lambda }{2m} $$](img/475458_1_En_5_Chapter_TeX_IEq1.png)，λ的值由用户定义。

基于如何将权重添加到损失函数，我们有两种不同类型的正则化技术:L1 和 L2。

### L1 正则化

在 L1 正则化中，绝对权重被添加到损失函数中。为了使模型更一般化，权重的值被减少到 0，因此当我们试图压缩模型以进行更快的计算时，这种方法是非常优选的。

该等式可以表示为

成本函数=损失(定义)+ ![$$ \frac{\lambda }{2m}\ast \sum \left\Vert Weights\right\Vert $$](img/475458_1_En_5_Chapter_TeX_IEq2.png)

在 Keras 中，通过向“内核正则化”参数提供“正则化”对象，可以将 L1 损失添加到图层中。以下代码片段演示了如何将 L1 正则化器添加到 Keras 中的密集图层。

```py
from keras import regularizers
from keras import Sequential

model = Sequential()
model.add(Dense(256, input_dim=128, kernel_regularizer=regularizers.l1(0.01))

```

值 0.01 是我们为λ设置的超参数值。

### L2 正则化

在 L2 正则化中，平方权重被添加到损失函数中。为了使模型更一般化，权重值被减少到接近 0(但实际上不是 0)，因此这也被称为“权重衰减”方法。在大多数情况下，L2 比 L1 更能减少过度拟合。

该等式可以表示为

成本函数=损失(定义)+ ![$$ \frac{\lambda }{2m}\ast {\left\Vert Weights\right\Vert}^2 $$](img/475458_1_En_5_Chapter_TeX_IEq3.png)

我们可以像 L1 一样给 DL 模型添加一个 L2 正则化子。以下代码片段演示了如何向密集图层添加 L2 正则化因子。

```py
model = Sequential()
model.add(Dense(256, input_dim=128, kernel_regularizer=regularizers.l2(0.01))

```

值 0.01 是我们为λ设置的超参数值。

### 辍学正规化

除了 L1 和 L2 正则化，在 d L 中还有另一种流行的技术来减少过拟合。这种技术使用了一种退出机制。在这种方法中，模型在每次迭代过程中任意删除或停用一层的几个神经元。因此，在每一次迭代中，该模型会查看自身稍有不同的结构进行优化(因为一些神经元和连接会被停用)。假设我们有两个连续的层，H1 和 H2，分别有 15 和 20 个神经元。在这两层之间应用丢弃技术将导致 H1 随机丢弃一些神经元(基于定义的百分比)，从而减少 H1 和 H2 之间的连接。这个过程在每次迭代中随机重复，因此如果模型已经学习了一批并更新了权重，下一批可能会有一组完全不同的权重和连接来训练。该过程不仅由于减少的计算而有效，而且在减少过拟合方面直观地起作用，因此提高了整体性能。

使用下图可以直观地理解辍学的概念。我们可以看到，规则网络的所有神经元和两个连续层之间的连接都完好无损。使用 dropout，每次迭代都会通过任意停用或丢弃一些神经元及其关联的权重连接来引入一定程度的随机性。

![img/475458_1_En_5_Figa_HTML.jpg](img/475458_1_En_5_Figa_HTML.jpg)

在 Keras 中，我们可以按照以下约定对层使用 dropout:

```py
keras.layers.Dropout(rate, noise_shape=None, seed=None)

```

以下代码片段展示了添加到密集隐藏层的 dropout。参数值 0.25 表示退出率(即要退出的神经元的百分比)。

```py
from keras import Sequential
from keras.layers.core import Dropout, Dense

model = Sequential()
model.add(Dense(100, input_dim= 50, activation="relu"))
model.add(Dropout(0.25))
model.add(Dense(1,activation="linear"))

```

## 超参数调谐

超参数是定义模型整体结构和学习过程的参数。我们也可以将超参数作为模型的元参数。它不同于模型的实际参数，模型的实际参数是在训练过程中学习的(例如，模型权重)。与模型参数不同，超参数无法学习；我们需要用不同的方法来调优它们，以获得更好的性能。

为了更好地理解这个话题，让我们以一种更简化的方式来看这个定义。当我们设计一个 DNN 时，模型的架构是由一些高级工件定义的。这些工件可以是层中神经元的数量、隐藏层的数量、激活函数、优化器、架构的学习速率、时期的数量、批量大小等等。所有这些参数共同用于设计网络，它们对模型的学习过程及其最终性能有着巨大的影响。这些参数不能被训练；事实上，它们需要用经验和判断来选择，就像我们在第 [3](3.html) 章学到的规则一样，来决定架构的大小。定义模型整体架构的参数统称为超参数。选择正确的超参数是一个密集和迭代的过程，但随着经验的积累，它会变得更容易。用超参数的不同值进行试验以改进整个模型过程的过程称为模型调整或超参数调整。

### DL 中的超参数

让我们看看 DL 模型可用的不同超参数，并研究可供选择的选项。然后，我们将研究为模型选择正确的超参数集的各种方法。

#### 一层中的神经元数量

对于大多数使用表格横截面数据的分类和回归用例，可以通过调整网络的宽度(即一层中神经元的数量)来增强 DNNs 的鲁棒性。通常，选择第一层神经元数量的简单经验法则是参考输入维度的数量。如果给定训练数据集中输入维度的最终数量(这也包括一次性编码的特征)是 x，我们应该至少使用最接近 2x 的 2 次方的数字。假设您的训练数据集中有 100 个输入维度:最好从 2 × 100 = 200 开始，取最接近的 2 的幂，即 256。神经元的数量最好是 2 的幂，因为这有助于网络的计算更快。此外，神经元数量的最佳选择是 8、16、32、64、128、256、512、1024 等等。根据输入尺寸的数量，取最接近尺寸两倍的数字。所以，当你有 300 个输入维度时，试着用 512 个神经元。

#### 层数

的确，仅仅增加几层通常会提高性能，至少是略微提高。但问题是，随着层数的增加，训练时间和计算量显著增加。此外，要看到有希望的结果，您需要更多的历元数。不使用更深的网络并不总是一个选项；在必要的情况下，尝试使用一些最佳实践。

如果您正在使用一个非常大的网络，比方说超过 20 层，请尝试使用一个逐渐变小的架构(即，随着深度的增加，逐渐减少每层中的神经元数量)。因此，如果您使用 30 层架构，每层有 512 个神经元，请尝试慢慢减少层中神经元的数量。一个改进的架构是前 8 层有 512 个神经元，接下来的 8 层有 256 个，接下来的 8 层有 128 个，依此类推。对于最后一个隐藏层(不是输出层)，尝试将神经元的数量至少保持在输入大小的 30–40%左右。

或者，如果您使用更宽的网络(即，不减少较低层的神经元数量)，请始终使用 L2 正则化或丢弃率约为 30%的丢弃层。过度拟合的机会大大减少。

![img/475458_1_En_5_Figb_HTML.jpg](img/475458_1_En_5_Figb_HTML.jpg)

#### 时代数

有时，仅仅增加模型训练的历元数就能获得更好的结果，尽管这是以增加计算和训练时间为代价的。

#### 重量初始化

初始化网络的权重也会对整体性能产生巨大影响。好的权重初始化技术不仅加速了训练过程，而且避免了模型训练过程中的死锁。默认情况下，Keras 框架使用 glorot 统一初始化，也称为 Xavier 统一初始化，但这可以根据您的需要进行更改。我们可以使用内核初始化参数初始化层的权重，也可以使用偏差初始化参数初始化偏差。

可供选择的其他常用选项有“He Normal”和“He Uniform”初始化以及“lecun normal”和“lecun uniform”初始化。在 Keras 中也有相当多的其他选择，但上述选择是最受欢迎的。

以下代码片段展示了一个使用`random_uniform`在 DNN 的图层中初始化权重的示例。

```py
from keras import Sequential
from keras.layers import Dense
model = Sequential()
model.add(Dense(64,activation="relu", input_dim = 32, kernel_initializer = "random_uniform",bias_initializer = "zeros"))
model.add(Dense(1,activation="sigmoid"))

```

#### 批量

使用适度的批量总是有助于实现模型的更平滑的学习过程。在大多数情况下，不管数据集大小和样本数量如何，32 或 64 的批量大小将提供平滑的学习曲线。即使在您的硬件环境具有大 RAM 内存来容纳更大的批处理大小的情况下，我仍然建议保持 32 或 64 的批处理大小。

#### 学习率

学习率是在优化算法的上下文中定义的。它定义了每一步的长度，或者简单地说，在每次迭代中可以对权重进行多大的更新。在本书中，我们忽略了设置或改变学习率，因为我们使用了各自优化算法的默认值，在我们的例子中是 Adam。默认值为 0.001，这是大多数情况下的最佳选择。然而，在一些特殊的情况下，您可能会遇到一个用例，在这个用例中，学习率较低或者稍高可能会更好。

#### 激活功能

我们对神经元的激活功能有很多选择。在大多数情况下，ReLU 可以完美地工作。您几乎总是可以将 ReLU 作为任何用例的激活来进行，并获得良好的结果。在 ReLU 可能不会提供很好的结果的情况下，尝试 PReLU 是一个很好的选择。

#### 最佳化

类似于激活函数，对于网络的优化算法，我们也有相当多的选择。虽然最推荐的是 Adam，但在 Adam 可能无法为您的架构提供最佳结果的情况下，您可以探索 Adamax 以及 Nadam 优化器。对于像单词嵌入这样的参数更新很少的架构来说，Adamax 通常是更好的选择，单词嵌入通常用于自然语言处理技术。我们在书中没有涉及这些高级主题，但是在探索各种体系结构时记住这些要点是有好处的。

### 超参数调谐方法

到目前为止，我们已经讨论了可用于 DL 模型的各种超参数，并且还研究了针对一般情况的最推荐选项。然而，根据数据和问题类型为超参数选择最合适的值更像是一门艺术。这门艺术也是艰巨而缓慢的。DL 中超参数调整的过程几乎总是很慢并且资源密集。然而，基于为超参数选择值和进一步调整模型性能的方式，我们可以将不同类型的方法大致分为四大类:

*   手动搜索

*   网格搜索

*   随机搜索

*   贝叶斯优化

在上述四种方法中，我们将简要介绍前三种。贝叶斯优化是一个漫长而困难的话题，超出了本书的范围。让我们简单看一下前三种方法。

#### 手动搜索

顾名思义，手动搜索是为 DL 模型中所需的超参数选择最佳候选值的一种完全手动的方式。这种方法需要在训练网络方面有丰富的经验，以便使用最少的实验次数为所有期望的超参数获得正确的候选值集。通常这种方法效率很高，前提是你有使用它们的丰富经验。开始手动搜索的最佳方法是简单地利用给定超参数的所有推荐值，然后开始训练网络。结果可能不是最好的，但绝对不会是最差的。对于该领域的任何新手来说，尝试几个风险最低的超参数候选者都是一个很好的起点。

#### 网格搜索

在网格搜索方法中，您实际上是在为一组定义的超参数值试验所有可能的组合。“网格”这个名称实际上来源于每个超参数所提供值的网格状组合。下面是一个示例视图，展示了逻辑网格如何寻找三个超参数，每个超参数中有三个不同的值。

![img/475458_1_En_5_Figc_HTML.jpg](img/475458_1_En_5_Figc_HTML.jpg)

方法是尝试为每个组合开发一个模型，如前面所示。“x”表示将使用该特定超参数值开发的模型。例如，对于学习率(0.1)，垂直列显示将使用不同的优化器和批处理大小值开发的不同模型。类似地，如果您查看超参数“batch-size”= 32 的水平行，该行所有单元格中的“x”表示将使用不同的学习率和优化器值开发的不同模型。因此，在一个只有三个超参数和三个值的网格中，我们正在开发太多的模型。如果我们正在开发相当大的网络并使用更大的训练数据样本，这个过程将会非常漫长。

这种方法的优点是，它为超参数的定义网格提供了最佳模型。然而，缺点是如果你的网格没有很好的选择，你的模型也不会是最好的。简单地假设，研究模型的科学家对哪些模型可能是给定超参数的最佳候选模型有一个合理的想法。

Keras 没有直接提供在模型上执行网格搜索调优的方法。但是，我们可以使用自定义 for 循环和已定义的训练值，或者使用 Keras 提供的 sklearn 包装器将模型打包到 sklearn 类型对象中，然后利用 sklearn 中的网格搜索方法来完成结果。下面的代码片段展示了通过使用虚拟模型的 Keras 包装器从 sklearn 包中使用网格搜索的方法。

```py
from keras import Sequential
from sklearn.model_selection import GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier
from keras.layers import Dense
import numpy as np

#Generate dummy data for 3 features and 1000 samples
x_train = np.random.random((1000, 3))

#Generate dummy results for 1000 samples: 1 or 0
y_train = np.random.randint(2, size=(1000, 1))

#Create a python function that returns a compiled DNN model
def create_dnn_model():
    model = Sequential()
    model.add(Dense(12, input_dim=3, activation="relu"))
    model.add(Dense(1, activation="sigmoid"))
    model.compile(loss='binary_crossentropy', optimizer="adam", metrics=['accuracy'])
    return model

#Use Keras wrapper to package the model as an sklearn object
model = KerasClassifier(build_fn=create_dnn_model)

# define the grid search parameters
batch_size = [32,64,128]
epochs = [15, 30, 60]

#Create a list with the parameters
param_grid =  {"batch_size":batch_size, "epochs":epochs}
#Invoke the grid search method with the list of hyperparameters
grid_model = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)
#Train the model
grid_model.fit(x_train, y_train)

#Extract the best model grid search
best_model = grid_model.best_estimator_

```

#### 随机搜索

网格搜索的一个改进的替代方法是随机搜索。在随机搜索中，我们可以从一个分布中随机选择一个值，而不是从一个定义的数字列表中为超参数选择一个值，如学习率。然而，这仅适用于数值超参数。因此，代替尝试 0.1、0.01 或 0.001 的学习率，它可以从我们用一些属性定义的分布中选择一个随机值作为学习率。该参数现在有更大范围的值可以试验，并且获得更好性能的机会也更大。它通过引入随机性为更好的超参数选择带来机会，克服了人为猜测限定在限定范围内的超参数的最佳值的缺点。在现实中，对于大多数实际情况，随机搜索大多优于网格搜索。

#### 进一步阅读

要探索一些更具体的例子和贝叶斯优化的简要指南，请参考以下内容:

*   [T2`https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f`](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f)

*   [T2`https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/`](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)

## 模型部署

现在，我们终于可以讨论一些关于模型部署的重要问题了。我们从学习 Keras 和 DL 开始，用实际的 dnn 进行回归和分类实验，然后讨论调整超参数以提高模型性能。我们现在可以讨论一些在生产环境中部署 DL 模型的指导方针。我想澄清的是，我们实际上不会作为软件工程师学习在生产中部署模型的过程，或者讨论大型企业项目的 DL 软件管道和架构。相反，我们将重点关注在部署实际模型时需要记住的几个重要方面。

### 裁剪测试数据

在本书的整个过程中，我们已经看到测试数据与训练数据完全同步。在本书和任何 ML/DL 学习指南中，实验总是在模型训练开始前准备好测试数据。我们通常将现有数据分为训练样本和测试样本，然后使用我们这边的测试数据来验证模型的真实性能。这是一个公平的过程，只要你的目标是培训和开发一个模型。一旦你训练好的模型在软件中投入使用，你实际上并不能访问测试数据。为了实际使用该模型，需要以预期的格式定制数据，以便该模型可以预测并返回预测结果。这个过程实际上是艰巨的，需要精心设计生产软件的数据角力和转换管道。

我们用一个例子来理解这个过程。假设您已经设计并开发了一个 DNN，使用监督分类模型来预测信用卡交易是“真实的”还是“欺诈的”。开发模型时，您可以访问客户数据、交易、销售点属性、时间相关属性、地理属性等。所有这些数据点都存在于不同的来源中。对于模型的开发，您将努力从这些不同的来源获取数据，并以统一的形式呈现出来。对于您的实验，这实际上是一次性的工作。实际上，一旦模型投入使用，整个流程的设计方式就需要能够复制给定客户的数据摄取以及来自不同来源的所有其他必要属性，将其统一并转换为模型预测所需的形式，然后进行大规模的推理。想象一下一家大型银行，其中的实时应用程序同时处理全球数千笔交易。从模型中获取用于推理的定制数据需要真正合理的工程原则，以使模型能够无故障地工作。

设置将实时计算查询请求的数据库或群集/节点的设计原则需要考虑您在训练数据集上完成的数据工程和转换，因为每次使用模型进行预测时都需要执行完全相同的过程。这种动态定制数据以做出推论的过程本身是一种完全不同的艺术，需要精心的工程来构建。通常，数据科学家最不担心这部分问题。我们认为这是软件和数据工程师的工作，我们可以不去管它。这个神话最终会被打破，因为需要建立一个严肃的和谐来解决这个难题。这两个团队，即数据科学家和软件工程师，需要携手合作来完成这项任务。一个数据科学家在理解软件工程师的需求时所面临的困难，反之亦然，这导致了一个新的行业角色 ML engineer 的出现。一个 ML 工程师是一个对这两个领域的交叉有很好理解的候选人。

### 将模型保存到内存中

在本章的过程中，我们没有讨论的另一个有用的点是将模型作为文件保存到内存中，并在其他时间点重用它。这在 DL 中变得极其重要的原因是训练大型模型所消耗的时间。当你遇到连续几周在超级计算机上训练模型的 DL 工程师时，你不应该感到惊讶。包含图像、音频和非结构化文本数据的现代 DL 模型耗费了大量的训练时间。在这种情况下，一个方便的做法是能够暂停和恢复 DL 模型的训练，并保存中间结果，以便在某个时间点之前执行的训练不会浪费。这可以通过一个简单的回调(Keras 中的一个过程，可以在训练的不同阶段应用于模型)来实现，回调会在定义的里程碑之后将模型的权重与模型结构一起保存到一个文件中。这个保存的模型可以在以后您想要恢复训练时再次导入。这个过程就像你希望的那样继续。我们需要做的就是在一个时期之后或者当我们有了最佳模型时，保存模型结构以及权重。Keras 提供了在每个时期后保存模型或在多个时期的训练期间保存最佳模型的能力。

下面的代码片段显示了在大量时期的训练期间保存模型的最佳权重的示例。

```py
from keras.callbacks import ModelCheckpoint

filepath = "ModelWeights-{epoch:.2f}-{val_acc:.2f}.hdf5"
checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor="val_acc")

model.fit(x_train, y_train, callbacks=[checkpoint],epochs=100, batch_size=64)

```

正如您在这个代码片段中看到的，我们用期望的参数定义了一个`callbacks`对象。我们定义何时保存模型，度量什么指标，以及在哪里保存模型。文件路径使用命名约定，将模型权重存储到文件中，文件名描述纪元编号和相应的精度度量。最后，`callbacks`对象作为列表传递给模型拟合方法。

或者，您也可以在完成训练后使用`save_model`方法保存整个模型，然后使用`load_model`方法将其加载到内存中(可能是第二天)。下面的代码片段显示了一个示例。

```py
from keras.models import load_model
#Train a model for defined number of epochs
model.fit(x_train, y_train, epochs=100, batch_size=64)

# Saves the entire model into a file named as  'dnn_model.h5'
model.save('dnn_model.h5')

# Later, (maybe another day), you can load the trained model for prediction.
model = load_model('dnn_model.h5')

```

### 用新数据重新训练模型

当您将模型部署到生产中时，生态系统将继续生成更多数据，这些数据可用于再次训练您的模型。比方说，对于信用卡欺诈用例，您使用 10 万个样本训练您的模型，并获得了 93%的准确率。您觉得性能足够好，可以开始使用，所以您将模型部署到生产中。在一个月的时间内，可以从客户的新交易中获得额外的 10K 样本。现在，您会希望您的模型利用这些新的可用数据，并进一步提高其性能。要实现这一点，你不需要重新训练整个模型；你可以使用暂停再继续的方法。您所需要做的就是使用已经训练好的模型的权重，并提供几个时期的附加数据来传递和迭代新样本。它已经学会的权重不需要被处理掉；您可以简单地使用暂停-恢复公式，继续处理增量数据。

### 在线模型

在理解了重新训练模型的过程之后，您可能会思考的一个直接问题是，您应该多长时间进行一次这样的训练:每天、每周还是每月进行一次重新训练是一个好的方法吗？正确的答案是你想多频繁就多频繁。只要所需的计算不是瓶颈，每次有新的数据点可用时，递增地训练您的模型是无害的。一个好的做法是，一旦有新的一批样本可用，就迭代一个训练实例。因此，如果您将`batch_size`设置为 64，您可以自动进行模型训练，以获取最新可用的一批数据，并通过自动执行软件基础架构来为每一批新的数据样本训练模型，从而进一步提高未来预测的性能。将模型性能保持在最佳状态的一个非常积极的方法是，用每个新的数据点进行增量训练，并添加以前的样本作为该批次的剩余样本。这种方法计算量极大，而且回报也较少。这种对每个新样本而不是一批样本进行超实时和增量训练的方法通常不被推荐。

这种模型被称为在线模型，当新的一批数据可用时，它总是在学习。最受欢迎的在线模型的例子可以在你的手机上看到。像预测文本和自动更正这样的功能会随着时间的推移而显著改进。如果你通常以一种特定的风格打字，比如结合两种语言或者缩短几个单词或者使用俚语等等，你会注意到手机非常积极地倾向于适应你的风格。这纯粹是因为手机的操作系统在后台启动了在线模型不断学习和改进的机制。

### 将您的模型作为 API 交付

如今，将模型作为服务交付给更大的软件堆栈的最佳实践是将其作为 API 交付。这是非常有用和有效的，因为它完全摆脱了技术栈的需求。您的模型可以轻松地在软件生态系统中各种复杂的组件之间进行协作，您可以更少地担心用于开发模型的语言或框架。通常，当您开发 ML 或 DL 模型时，交付模型的选择仅仅由两个简单的点驱动:

*   用软件工程师理解的语言构建模型

或者

*   使用 API

虽然 Python 和 Keras 在今天的现代技术堆栈中几乎是通用的，但我们仍然可以期待一些例外情况，在这些情况下，这种选择可能不是集成的简单选择。因此，我们总是可以选择 API 作为 DL 模型的首选部署模式，并适当地定义数据需求和 API 的调用方式。

有两个非常有用且易于操作的选项可以将您的服务部署为 API。您可以使用 Flask(一种轻量级 Python web 框架)或 Amazon Sagemaker(在 AWS 上可用)。还有其他的选择，我鼓励你去探索它们。Keras 博客上有一篇关于使用 Flask 部署 DL 模型的文章写得非常好。

你可以在这里了解更多: [`https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html`](https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html) 。

此外，您可以在这里通过几个步骤探索如何使用 AWS Sagemaker 将您的模型部署为 API:[`https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html`](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)。

### 把所有的拼图拼在一起

最后，我们可以把上一节学到的所有这些小组件收集起来，放入一个简单的(小)架构中，如下图所示。

![img/475458_1_En_5_Figd_HTML.jpg](img/475458_1_En_5_Figd_HTML.jpg)

对于生产你的模型来说，这绝对是一个过于简单的解释；我建议您以一种更合适的方式探索您的用例的改进架构。当您的规模、数据量、安全性和可用性达到更高水平时，很多事情都会发生变化。前面的视觉展示了一个适用于小型软件的架构。一旦您完成了模型构建过程，您就可以设置您的大部分逻辑来预测、定制数据、定期测量性能、自动化在线学习、日志记录等，并将其放入一个小 Flask 应用程序中，在服务器上运行，并将其作为 API 进行部署。软件客户端可以是 web 客户端或运行在同一服务器上的另一个服务，它可以通过调用定义格式的 API 来利用该模型。这种架构适用于小型概念验证(POC ),不建议用于生产企业应用程序。讨论 DL 模型的大规模部署、动态定制数据的艺术、支持在线学习以及扩展整个服务基本上还需要几本书。

## 摘要

在这一章中，我们讨论了当模型性能与您的期望不一致时可以期待的方法和策略。简而言之，我们研究了当您的 DL 模型运行不佳时的整合方法。我们讨论了正则化和超参数调整，还探索了可以用来调整超参数并获得改进模型的不同策略。最后，我们讨论了在部署模型时需要解决的几个原则。我们对模型预测的数据裁剪过程进行了概述，了解了如何使用暂停-恢复方法训练模型，并研究了在线模型和重新训练它们的方法。最后，我们还查看了可用于部署模型的选项，并研究了使用 Flask 部署模型的小型架构。*