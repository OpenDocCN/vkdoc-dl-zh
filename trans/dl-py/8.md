# 8.深度学习的最新进展

到目前为止，这本书已经讨论了深度学习领域的重要主题:前馈网络，卷积神经网络和递归神经网络。我们描述了它们的实际方面，包括使用 PyTorch 改进的实现、培训、验证和调优模型。尽管我们在基础方面覆盖了很多领域，但仍有大量领域没有触及。深度学习领域最近见证了研究、贡献者和业界对尖端解决方案的采用的巨大增长。更新和变化的绝对速度(增量的和突破性的)是巨大的。即使你一直在读这本书，也可能有几篇突破性的研究论文发表，为深度学习领域的下一门课程量身定制。

在这最后一章，我们介绍了一些与深度学习相关的额外主题，这些主题应该可以帮助你以更有意义的方式研究这个主题。本章仅作为简要介绍，并不深入任何实现细节。建议您探索与这些主题相关的其他资源，以加强您的学术、个人和行业职业感兴趣的领域。

让我们开始吧。

## 超越计算机视觉中的分类

在第 [5](5.html) 章中，我们研究了使用卷积神经网络解决的深度学习中的计算机视觉问题。这个想法是新颖的和开创性的。第 5 章[只关注一个关键领域——分类。我们研究了 MNIST 手写数字的经典例子，其中我们将给定的图像分类为 0-9 之间的数字[10 类]。在另一个练习中，我们看了猫和狗之间的二元分类。虽然使用计算技术将图像分类为有意义的标签的能力确实很有价值，但更进一步，它打开了几个对现代用例有深远价值的用例。](5.html)

本节通过进一步扩展卷积神经网络的概念来探索一些可能性。

### 目标检测

*物体检测*，一种与计算机视觉相关的技术，试图区分一幅图像或视频中的一个或多个物体。例如，在猫与狗的分类练习中，对象检测将更进一步，并预测最能捕捉感兴趣对象的矩形边界框。在更复杂的用例中，对象检测可以用于检测图像/视频中的几个对象。

图 [8-1](#Fig1) 显示了一个复杂的物体检测算法。每个被识别的对象都有边界框来区分它们。

![img/478491_2_En_8_Fig1_HTML.jpg](img/478491_2_En_8_Fig1_HTML.jpg)

图 8-1

计算机视觉图像中的物体检测来源-[https://github . com/face book research/detectron 2](https://github.com/facebookresearch/Detectron2)

针对每个人(多个人被识别)的边界框是来自对象检测的结果。

物体检测的现实使用案例包括从 CCTV 视频流中识别汽车，从而跟踪重要路线上的交通状况，在智能手机上使用面部检测，以便自动对焦可以精确地聚焦在重要物体上，从而改善照片，等等。

### 图象分割法

继物体检测之后，计算机视觉的下一个逻辑步骤是图像分割。*图像分割*是一种标记技术，将给定的图像分割成多个片段(一组像素)，以更精确地定义物体。图像分割和对象检测之间的区别在于，在图像分割下，在图像中识别的对象的定义更精确。也就是说，我们将拥有物体的实际像素轮廓，而不是像物体检测中那样的矩形边界框(见图 [8-2](#Fig2) )。

![img/478491_2_En_8_Fig2_HTML.jpg](img/478491_2_En_8_Fig2_HTML.jpg)

图 8-2

计算机视觉中的图像分割图片来源-[https://github . com/face book research/detectron 2](https://github.com/facebookresearch/Detectron2)

取代了边界框，我们现在有了更精细的轮廓来捕捉实际的物体。图像分割的实际应用包括交通监控、医疗成像、智能手机相机中的人像模式(数字模拟散景效果——识别人物以模糊背景)。

现代智能手机实现了*语义图像分割*——识别图像中的对象，并根据所识别的对象类型进一步处理它们。例如，一张脸将被处理以获得美感(平滑瑕疵/阴影等)。);添加模糊效果后，天空会变得不那么清晰；大自然将被彩色处理，以具有一种充满活力的感觉；诸如此类。

要了解更多关于语义图像分割的信息，请访问 [`https://developer.apple.com/videos/play/wwdc2019/225/`](https://developer.apple.com/videos/play/wwdc2019/225/) 。

### 姿态估计

*姿态估计*是一种预测和跟踪人或物体位置的计算机视觉技术。本质上，姿态估计使用给定人/物体的姿态和方向的组合从图像或视频预测人的身体部分或关节位置。

姿势估计的更复杂版本——也是更难解决的计算机视觉问题——是*多人姿势估计*(见图 [8-3](#Fig3) )。

![img/478491_2_En_8_Fig3_HTML.jpg](img/478491_2_En_8_Fig3_HTML.jpg)

图 8-3

多人姿势估计图片来源-[https://github . com/face book research/detectron 2](https://github.com/facebookresearch/Detectron2)

姿态估计的实际应用类似于图像分割和对象检测，尽管姿态估计的应用更有意义和针对性——例如，跟踪人的活动，如跑步、骑自行车等。活动跟踪使安全监控更上一层楼。姿态估计的另一个重要应用涉及电影和增强现实领域。将人类的动作捕捉转换为三维图形角色，其中动作被精确捕捉和转换(称为 VFX 或 VFX)，经常用于电影。

要了解更多关于姿态估计的信息，请访问 [`http://neuralvfx.com/tag/facial-pose-estimation/`](http://neuralvfx.com/tag/facial-pose-estimation/) 。

### 生成计算机视觉

除了分类、对象检测、图像分割和姿态估计，我们在计算机视觉中还有另一个热门领域— *生成对抗网络* (GANs)。计算机视觉中的生成模型首先学习训练集的分布，然后生成一些具有小变化的新样本。这些新图像是由模型在监督设置中使用随机噪声和先前学习的模型权重合成生成的。图 [8-4](#Fig4) 为 GAN 模型生成的图像样本示例。

![img/478491_2_En_8_Fig4_HTML.jpg](img/478491_2_En_8_Fig4_HTML.jpg)

图 8-4

GAN 生成的样本图像

大多数图像看起来相当逼真，易于辨认，例如马、船、汽车等。训练 GANs 一直是个难题，通常需要大量的计算资源。制作更大尺寸的图像会进一步增加复杂性。然而，GANs 是近年来计算机视觉领域最大的发展之一。ACM 图灵感知奖获得者 Yann LeCun 将它们描述为“过去 10 年机器学习中最有趣的想法”。

gan 的实际应用是无限的。最简单的应用程序是基于文本描述渲染图像的产品。例如，键入“设计一个白天人比车多的繁忙街道的图像”将得到显示这些事情的图像。反之亦然——即，输入图像并接收关于该图像的基于文本的自然语言描述。科技公司百度设计了一种原型设备，它通过一个用自然语言描述周围环境的摄像头来帮助盲人。欲了解更多关于原型的信息，请访问 [`https://www.youtube.com/watch?v=Xe5RcJ1JY3c`](https://www.youtube.com/watch%253Fv%253DXe5RcJ1JY3c) 。

一些新兴的电子商务企业正在利用 GANs 设计图形 t 恤。例如，流行的照片编辑应用 Prisma 和 FaceApp，一个有争议但直观的应用，可以将你现有的照片变成你更老或更年轻的自己，在 2019 年席卷了互联网。

Deepfake 视频现在(或即将)是互联网上的一个主要问题。Deepfakes 可以制作几乎真实的视频，让名人用真实的语音和手势讲述您的输入内容。

## 具有深度学习的自然语言处理

第 [7](7.html) 章讨论了递归神经网络(RNNs)和长短期记忆(LSTM)网络，它们可以用来解决现代自然语言处理(NLP)问题。序列模型在语音识别和自然语言处理中的相关任务中也非常有效。近年来，语音数字助理有了显著的进步，比如苹果的 Siri 和亚马逊的 Alexa。这些助手现在可以理解更多带有地域影响和各种口音的语言和讲话，并以非常真实的声音做出回应。他们也能理解并区分你的声音和其他人的声音，当然，准确性的问题仍然存在。在早期，这些改进是通过 LSTM 和门控循环单元(GRUs)，另一种类似于 LSTM 的变体。

LSTM 和 GRU 模型仍然有局限性。它们在计算上非常昂贵，并且顺序地处理输入。长期依赖问题仍然存在，尽管这比普通的 RNN 要好得多。

### 变压器型号

2017 年底，谷歌发表了关于 Transformer network 的研究结果，这是 NLP 的一个开创性的深度学习模型。这篇名为“注意力是你所需要的全部”( [`https://arxiv.org/pdf/1706.03762.pdf`](https://arxiv.org/pdf/1706.03762.pdf) )的论文揭示了语言模型研究领域的一个新转变。

有一段时间，rnn 是处理顺序数据的最佳选择。然而，顺序处理和相对较差的长期依赖性能给大型 NLP 任务带来了各种挑战。变压器网络在这类用例中发挥着至关重要的作用。变压器网络可以并行训练，从而大幅减少计算时间。它们基于自我关注机制，完全免除了递归和卷积(因此，计算速度更快)。

Transformer 模型在 WMT 2014 年英德翻译任务中获得了 28.4 的双语评估替角(BLEU)分数，比现有的最佳结果(包括合奏)提高了两个 BLEU 以上。

### 来自变压器的双向编码器表示

2018 年，在发布 Transformer networks 一年后，谷歌人工智能语言的研究人员从 Transformers (BERT)开源了一项名为*双向编码器表示的 NLP 新技术。*

BERT 依赖于一个变压器，但有一些变化。标准变压器由编码器和解码器架构组成；编码器读取文本输入，而解码器产生预测。然而，BERT 只利用编码器部分。因为 BERT 的目标是生成一个语言表示模型，所以这是理想的。BERT 的独特优势之一是其半监督设置。在这种情况下，该过程首先集中在预训练(无监督的)，其中使用大量文本数据(主要通过互联网获得)来训练语言表示模型。接下来，针对感兴趣的特定用例，以受监督的方式对模型进行训练和微调。我们在第 [7](7.html) 章探索的情感分类用例就是一个例子。

你可以在 [`https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html`](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) 找到更多关于伯特的细节。

BERT 使用两种策略进行训练:掩蔽语言建模和下一句预测。对于屏蔽语言建模，在将单词序列输入 BERT 时，每个序列中大约有 15%的单词被替换为[MASK]标记。然后，该模型试图根据序列中其他未屏蔽单词提供的上下文来预测屏蔽单词的原始值。

AllenNLP 发布了一个在后台使用 BERT 的有趣工具(见 [`https://demo.allennlp.org/masked-lm`](https://demo.allennlp.org/masked-lm) )。图 [8-5](#Fig5) 展示了一个简单的演示；该模型以 72%的概率将[MASK]中的单词预测为 car。

![img/478491_2_En_8_Fig5_HTML.jpg](img/478491_2_En_8_Fig5_HTML.jpg)

图 8-5

allennlp 演示

## 格罗涅特

我们到目前为止所探讨的计算机视觉课题都与单任务学习有关。也就是说，我们专门设计了一个具有一个损失函数和一个期望结果的网络——将一幅图像分成 n 个不同的类别。数字时代的现代问题有更复杂的要求，需要更全面的方法。考虑一个电子商务市场。当用户上传一张图片来列出一个待售产品时，他们可能不会添加关于该产品的详细和全面的描述。在大多数情况下，上传者会为产品添加一行描述和一个宽泛的类别(这可能不完全正确)。

为了更好地理解这个问题，考虑一个椅子的样本产品列表:*“出售一把结实的椅子，仅用了一年，状况像新的一样*”这种用户起草的描述缺乏大量信息，而这些信息可能是买家做出更明智决策的理想信息。对买方(以及市场)来说理想的信息属性包括椅子的颜色、椅子的品牌和型号、制造年份等。从工程的角度来看，根据针对提要的基于用户的搜索查询对这样的产品列表进行排序将是一项困难的任务，因为它可能不匹配大多数相关的信息字段。

这个问题的解决方案是通过几个单独的计算机视觉任务来增加额外的信息，例如，一个将图像分类到一个大的类别(家具/工具/车辆/书籍等)的任务。)，然后使用另一个型号在一个垂直方向(品牌和型号年份)内进行更具体的分类，依此类推。可能还会出现为每个垂直产品(例如，服装、家具、书籍等)提供个性化模型的需求。考虑到广泛的可能性，我们可能经常面临构建和维护数百个不同模型的挑战。

考虑到 Facebook Marketplace 是一个问题，该公司发布了 *GrokNet* ，这是一个单一、统一的模型，全面覆盖所有产品。借助统一的模型，该公司能够减少维护和计算成本，并通过消除对每个垂直应用程序的单独模型的需求来提高覆盖率。GrokNet 利用多任务学习方法来训练单个计算机视觉主干。该模型使用 80 个分类损失函数和 3 个嵌入损失，在几个商业垂直行业的 7 个不同数据集上进行训练。

最终模型对给定图像预测如下:

*   *对象类别*:“吧台凳”、“围巾”、“地毯”等。

*   *家居属性*:物品颜色、材质、装饰风格等。

*   *时尚属性*:款式、颜色、材质、袖长等。

*   *车辆属性*:品牌、型号、外观颜色、年代等。

*   *搜索查询*:用户可能用来在市场搜索中找到产品的文本短语

*   *图片嵌入*:一个 256 位的哈希码，用于识别确切的产品，查找相似的产品并进行排序，提高搜索质量

有了对给定图像的如此丰富的预测，给定用户的搜索结果的市场馈送可以用高度相关的结果来定制和定制。预测的图像嵌入可以进一步用于呈现相似的产品列表，使得用户可以做出更明智的决定。此外，整个增强任务是由单个模型而不是模型的集合来执行的。

欲了解更多关于 GrokNet 的信息，请访问 [`https://ai.facebook.com/research/publications/groknet-unified-computer-vision-model-trunk-and-embeddings-for-commerce/`](https://ai.facebook.com/research/publications/groknet-unified-computer-vision-model-trunk-and-embeddings-for-commerce/) 。

## 其他值得注意的研究

本节描述了一些与深度学习领域相关的研究出版物，这些出版物非常令人兴奋，可供人们独立探索，作为该领域的下一步发展。讨论这项研究的任何细节都超出了本书的范围，因此鼓励读者独立探索以下研究论文:

1.  **点唱机:音乐的生成模型**

    Jukebox 是一个神经网络，它生成音乐，包括基本的歌唱，作为各种流派和艺术家风格的原始音频。OpenAI 发布了模型的权重和代码，以及一个探索生成样本的工具。

    论文: [`https://arxiv.org/abs/2005.00341`](https://arxiv.org/abs/2005.00341)

    代码: [`https://github.com/openai/jukebox/`](https://github.com/openai/jukebox/)

2.  **图像 GPT–生成相干图像完成**

    经过语言训练的基于转换器的模型可以生成连贯的文本。在像素序列上训练的相同模型可以生成连贯的图像完成和样本。

    论文: [`https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf`](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)

    代码: [`https://github.com/openai/image-gpt`](https://github.com/openai/image-gpt)

3.  **通用音乐翻译网**

    一种基于深度学习的跨乐器和风格翻译音乐的方法。该技术基于多域波网自动编码器的无监督训练，具有共享编码器和在波形上端到端训练的域独立潜在空间。

    论文: [`https://arxiv.org/abs/1805.07848`](https://arxiv.org/abs/1805.07848)

4.  **视频中的实时人脸去识别**

    该方法使用前馈编码器-解码器网络架构，以人的面部图像的高级表示为条件，在全自动设置中以高帧速率对实况视频进行面部去识别。

    论文: [`https://arxiv.org/abs/1911.08348`](https://arxiv.org/abs/1911.08348)

## 总结想法

我们想感谢你，读者，感谢你花时间和兴趣通过阅读这本书来研究深度学习的主题。我们真诚地感谢您为这本书付出的努力，并希望我们能够满足您的期望。

深度学习的主题是如此广泛和动态，以至于人们需要进行持续的研究以跟上创新的步伐。我们对这本书的关注一直是传递关于这个主题的抽象而直观的信息的健康组合(用最少的数学运算；抱歉，如果方程是压倒性的)，同时使用业界和学术界的领先工具(PyTorch)将急需的实际实现与真实数据集相结合。

我们将感谢您的想法和反馈！