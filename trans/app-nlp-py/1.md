# 一、什么是自然语言处理？

深度学习和机器学习继续在各个行业中扩散，并彻底改变了我希望在本书中讨论的主题:自然语言处理(NLP)。NLP 是计算机科学的一个子领域，致力于让计算机像人类一样以“自然”的方式理解语言。通常，这将涉及诸如理解文本的情感、语音识别和生成对问题的响应之类的任务。

NLP 已经成为一个快速发展的领域，其应用代表了人工智能(AI)突破的很大一部分。使用深度学习实现的一些例子是处理客户服务请求的聊天机器人，手机上的自动拼写检查，以及智能手机上的人工智能助手，如 Cortana 和 Siri。对于那些有机器学习和深度学习经验的人来说，自然语言处理是个人应用技能最令人兴奋的领域之一。然而，为了给更广泛的讨论提供背景，让我们讨论自然语言处理作为一个领域的发展。

## 自然语言处理的历史

自然语言处理可以被归类为更广泛的语音和语言处理领域的子集。正因为如此，NLP 与计算语言学等平行学科有相似之处，计算语言学关注的是使用基于规则的模型对语言进行建模。NLP 的出现可以追溯到 20 世纪 40 年代计算机科学的发展，随着语言学的进步向前发展，导致了形式语言理论的构建。简而言之，形式语言理论在日益复杂的结构和这些结构的规则上模拟语言。例如，字母表是最简单的结构，因为它是可以形成称为*单词*的字符串的字母集合。正式语言是一种有规则的、上下文无关的和正式的语法的语言。除了整个计算机科学的发展，人工智能的进步也在我们对 NLP 的持续理解中发挥了作用。

在某种意义上，单层感知器(SLP)被认为是机器学习/人工智能的开端。图 [1-1](#Fig1) 显示了这款车型的照片。

![img/463133_1_En_1_Fig1_HTML.jpg](img/463133_1_En_1_Fig1_HTML.jpg)

图 1-1

单层感知器

SLP 是由神经生理学家沃伦·麦卡洛克和逻辑学家沃尔特·皮特设计的。它是今天大量使用的更高级的神经网络模型的基础，例如多层感知器。SLP 模型被认为部分源于艾伦·图灵在 20 世纪 30 年代末对计算的研究，该研究启发了其他科学家和研究人员发展不同的概念，如形式语言理论。

向前移动到二十世纪下半叶，NLP 开始分成两个不同的思想组:(1)支持语言建模的符号方法的人，和(2)支持随机方法的人。前一组主要由语言学家组成，他们使用简单的算法来解决 NLP 问题，通常利用模式识别。后者主要由统计学家和电气工程师组成。在第二组受欢迎的许多方法中，有贝叶斯统计。随着二十世纪的发展，NLP 作为一个领域扩大了，包括自然语言理解(NLU)到问题空间(允许计算机对命令做出准确的反应)。例如，如果有人对聊天机器人说话，并要求它“在我附近寻找食物”，聊天机器人会使用 NLU 将这句话转化为切实的行动，以产生理想的结果。

跳到现在，我们发现在过去的 20 年里，随着机器学习的使用激增，NLP 经历了兴趣的激增。除了计算能力的提高之外，这部分是由于标记数据集的大型存储库变得更加可用。这种计算能力的提升很大程度上归功于 GPU 的发展；尽管如此，它已经被证明对人工智能作为一个领域的发展至关重要。因此，对指导数据科学家和工程师如何利用各种人工智能算法的材料的需求增加了，这也是本书的部分原因。

现在你已经知道了 NLP 的历史，因为它与今天相关，我将给出一个你应该期望学习的简要概述。然而，重点主要是讨论深度学习如何影响 NLP，以及如何利用深度学习和机器学习技术来解决 NLP 问题。

## 机器学习和深度学习综述

你会对重要的机器学习概念感到耳目一新，特别是深度学习模型，如*多层感知器*(MLPs)*循环神经网络*(RNNs)*长短期记忆* (LSTM)网络。在处理任何特定的 NLP 问题之前，您将会看到利用玩具示例的深度模型。

### 使用 Python 的 NLP、机器学习和深度学习包

与理解 NLP 理论同等重要的是在实际环境中应用它的能力。这本书利用了 Python 编程语言，以及用 Python 编写的包。Python 已经成为数据科学家的通用语言，对 NLP、机器学习和深度学习库的支持非常丰富。在解决示例问题和讨论一般概念时，我会参考许多这样的软件包。

假设本书的所有读者都对 Python 有一个大致的了解，这样你就有能力用这种语言编写软件。如果您不熟悉这种语言，但您熟悉其他语言，那么在给定相同数据集的情况下，本书中的概念对于用于解决问题的方法是可移植的。尽管如此，这本书并不打算指导用户学习 Python。现在，让我们讨论一些对理解深度学习最重要的技术。

#### TensorFlow

除了机器学习之外，开源软件的突破性版本之一无疑是谷歌的 TensorFlow。它是深度学习的开源库，是类似机器学习库 Theano 的继任者。两者都利用数据流图进行计算。具体来说，我们可以认为计算依赖于特定的单个操作。TensorFlow在功能上通过用户首先定义图形/模型来操作，然后通过用户也创建的TensorFlow会话来操作。

使用数据流图而不是另一种计算格式计算背后的原因是多方面的，但是更简单的好处之一是能够将模型从一种语言移植到另一种语言。图 [1-2](#Fig2) 说明了一个数据流图。

![img/463133_1_En_1_Fig2_HTML.png](img/463133_1_En_1_Fig2_HTML.png)

图 1-2

数据流图表

例如，您可能正在从事一个项目，由于延迟原因(例如，高频交易)，Java 是最适合生产软件的语言；但是，您希望利用神经网络在生产系统中进行预测。不用处理在 Java 中为TensorFlow图建立训练框架的耗时任务，可以相对快速地用 Python 编写一些东西，然后可以通过利用 Java 在生产系统中加载权重来恢复图/模型。TensorFlow 代码类似于 Theano 代码，如下所示。

```py
    #Creating weights and biases dictionaries
    weights = {'input': tf.Variable(tf.random_normal([state_size+1, state_size])),
        'output': tf.Variable(tf.random_normal([state_size, n_classes]))}
    biases = {'input': tf.Variable(tf.random_normal([1, state_size])),
        'output': tf.Variable(tf.random_normal([1, n_classes]))}

    #Defining placeholders and variables
    X = tf.placeholder(tf.float32, [batch_size, bprop_len])

    Y = tf.placeholder(tf.int32, [batch_size, bprop_len])
    init_state = tf.placeholder(tf.float32, [batch_size, state_size])
    input_series = tf.unstack(X, axis=1)
    labels = tf.unstack(Y, axis=1)
    current_state = init_state
    hidden_states = []

    #Passing values from one hidden state to the next
    for input in input_series: #Evaluating each input within the series of inputs
        input = tf.reshape(input, [batch_size, 1]) #Reshaping input into MxN tensor
        input_state = tf.concat([input, current_state], axis=1) #Concatenating input and current state tensors
        _hidden_state = tf.tanh(tf.add(tf.matmul(input_state, weights['input']), biases['input'])) #Tanh transformation
        hidden_states.append(_hidden_state) #Appending the next state
        current_state = _hidden_state #Updating the current state

```

然而，TensorFlow 并不总是最容易使用的库，因为玩具示例的文档与真实世界的示例之间经常存在严重的差距，真实世界的示例合理地引导读者通过实现深度学习模型的复杂性。

在某些方面，TensorFlow 可以被认为是 Python 内部的一种语言，因为读者在无缝编写应用程序(如果有的话)之前必须了解语法上的细微差别。从某种意义上说，Keras 回答了这些问题。

#### 硬

由于 TensorFlow、Theano 和类似的深度学习框架中的应用程序开发过程缓慢，Keras 是为原型应用程序开发的，但它也用于生产工程中的各种问题。它是 TensorFlow、Theano、MXNet 和 DeepLearning4j 的包装器。与这些框架不同，定义计算图相对容易，如下面的 Keras 演示代码所示。

```py
def create_model():
    model = Sequential()
    model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                       input_shape=(None, 40, 40, 1),
                       padding='same', return_sequences=True))
    model.add(BatchNormalization())

    model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                       padding='same', return_sequences=True))
    model.add(BatchNormalization())

    model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                       padding='same', return_sequences=True))
    model.add(BatchNormalization())

    model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                       padding='same', return_sequences=True))
    model.add(BatchNormalization())

    model.add(Conv3D(filters=1, kernel_size=(3, 3, 3),
                   activation='sigmoid',
                   padding='same', data_format="channels_last"))
    model.compile(loss='binary_crossentropy', optimizer="adadelta")
    return model

```

尽管在实施解决方案方面，Keras 具有易用性和速度方面的额外优势，但与 TensorFlow 相比，它也有相对的缺点。最广泛的解释是，Keras 用户对其计算图形的控制远不如 TensorFlow 用户。使用 Keras 时，您在沙盒的范围内工作。TensorFlow 更擅长支持更复杂的操作，并提供各种算法的最前沿实现。

#### 提亚诺

虽然这本书没有涉及，但在深度学习的进展中讨论这个问题是很重要的。该库类似于 TensorFlow，为开发者提供了各种计算功能(加法、矩阵乘法、减法等。)在构建深度学习和机器学习模型时嵌入张量中。例如，下面是一个示例 Theano 代码。

```py
(code redacted please see github)
X, Y = T.fmatrix(), T.vector(dtype=theano.config.floatX)
    weights = init_weights(weight_shape)
    biases = init_biases(bias_shape)
    predicted_y = T.argmax(model(X, weights, biases), axis=1)

    cost = T.mean(T.nnet.categorical_crossentropy(predicted_y, Y))
    gradient = T.grad(cost=cost, wrt=weights)
    update = [[weights, weights - gradient * 0.05]]

    train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)
    predict = theano.function(inputs=[X], outputs=predicted_y, allow_input_downcast=True)

    for i in range(0, 10):
        print(predict(test_x_data[i:i+1]))

if __name__ == '__main__':

    model_predict()

```

当查看本示例中定义的函数时，请注意`T`是为张量定义的变量，这是一个您应该熟悉的重要概念。张量可以被认为是类似于向量的物体；然而，它们是不同的，因为它们通常由数字数组或函数来表示，这些数组或函数由它们自己独有的特定转换规则来控制。张量可以是时空中的一个点或点的集合(任何结合了 x、y、z 轴和一个时间维度的函数/模型)，或者它们可以是一个连续统，这是一个*张量场*。当数据通过计算图传递时，Theano 和 TensorFlow 使用张量来执行大多数数学运算，俗称*模型*。

一般建议，如果你不知道 Theano，你应该专注于掌握 TensorFlow 和 Keras。然而，那些熟悉 Theano 框架的人可以随意在 Theano 中重写现有的 TensorFlow 代码。

### 深度学习在自然语言处理中的应用

本节讨论深度学习在 NLP 中的应用。

#### 自然语言处理技术和文档分类介绍

在第 [3](3.html) 章中，我们将介绍一些介绍性的技术，比如单词标记化、清理文本数据、术语频率、逆文档频率等等。当我们为第 [2](2.html) 章中回顾的一些算法准备数据集时，我们将在数据预处理过程中应用这些技术。具体来说，我们关注分类任务，并回顾不同特征提取技术应用于文档分类任务时的相对优势。

#### 主题建模

在第 [4](4.html) 章中，我们讨论深度学习、机器学习和 NLP 的更高级用途。我们从主题建模以及如何通过潜在的狄利克雷分配和非负矩阵分解来实现主题建模开始。主题建模就是从文档中提取主题的过程。您可以通过数据可视化将这些主题用于探索目的，或者作为标注数据时的预处理步骤。

#### 单词嵌入

单词嵌入是用于将单词(或短语)映射到向量空间的模型/技术的集合，使得它们出现在高维领域中。由此，您可以确定一个单词(或短语，或文档)与另一个单词(或短语，或文档)之间的相似度或相异度。当我们将单词向量投射到一个高维空间时，我们可以想象它看起来像图 [1-3](#Fig3) 所示的东西。

![img/463133_1_En_1_Fig3_HTML.png](img/463133_1_En_1_Fig3_HTML.png)

图 1-3

单词嵌入的可视化

最终，你如何利用单词嵌入取决于你自己的解释。它们可以针对拼写检查等应用进行修改，但也可以用于情感分析，特别是在评估较大的实体时，例如相互关联的句子或文档。我们只关注如何训练算法以及如何准备数据来训练嵌入本身。

#### 涉及 RNNs 的语言建模任务

在第 [5](5.html) 章中，我们通过处理一些更高级的 NLP 应用程序来结束这本书，这是在你熟悉了预处理各种格式的文本数据和训练不同的算法之后。具体来说，我们专注于训练 rnn 来执行诸如名称实体识别、回答问题、语言生成以及将短语从一种语言翻译成另一种语言之类的任务。

## 摘要

这本书的目的是让你熟悉自然语言处理领域，然后学习应用这些知识的例子。这本书在必要的地方涵盖了机器学习，尽管它假设你之前已经在实际环境中使用过机器学习模型。

虽然这本书并不打算面面俱到，也不太学术，但我的意图是充分涵盖材料，以便读者能够比在阅读之前更容易地处理更高级的文本。对于那些对 NLP 的实际应用更感兴趣的人来说，这是我们在例子中讨论和展示的绝大多数内容。事不宜迟，让我们开始回顾机器学习，特别是它与本书中使用的模型的关系。