# 九、硬件和软件建议

要在专业环境中应用本书中探索的技术，硬件升级可能会成为一个考虑因素。在某些情况下，甚至有必要从头开始建造一台计算机。很少有现成的版本，即使有也要花费惊人的金钱。考虑到这一点，本章旨在为读者提供他们最应该注意的硬件组件的基本概述，并提供关于购买硬件的一般建议。

## 用标准硬件处理数据

在相对“普通”的机器上操作时，您可能会面临许多困难。当使用大型数据集处理机器学习和深度学习问题时，通常建议您对数据子集运行大多数操作，并以迭代次数乘以子集大小等于原始数据集大小的方式进行训练。虽然这只是提供了一个近似的性能，但是它可能能够运行您的解决方案，而不会由于 RAM 不足而导致解释器崩溃。

也强烈建议资金充足的个人使用亚马逊网络服务(AWS)。从专业角度来说，亚马逊是云服务的首选解决方案，甚至可能让你获得许多雇主渴望拥有的宝贵技能。简而言之，你可以付费在云环境中运行你需要的所有硬件的实例。尽管出于部署目的，这样做可能成本极高，但对于概念证明或研究，使用像 Amazon AWS 这样的云服务可能是解决深度学习问题的一种经济高效且简单的解决方案。但是，如果你需要实现解决方案，作为为业务或服务部署算法的一部分，请继续阅读——本章给出的建议是一个很好的起点。

## 固态硬盘和硬盘(HDD)

硬盘(HDD)是一种用于保存信息的存储设备，即使机器不在线。硬盘的主要特征是它可以存储的数据量和它提供的性能。正如我在本书前面提到的，自 2000 年代中期以来，存储的价格大幅下降，促进了对机器学习和深度学习科学的兴趣复苏。这一发展使得存储和收集大量的训练数据和/或训练模型成为可能，您可以在以后更新这些数据和/或模型或将其用于相关任务。用户应该熟悉他们最想处理的案例。

## 图形处理单元

在区分能够提供高性能深度学习的机器和不是专门用于深度学习的机器方面，GPU 是最常被引用的硬件之一)。对于深度学习，GPU 加速了计算的处理，是深度学习构建的一个组成部分。与中央处理器(CPU)计算相比，GPU 的性能明显优于 CPU，并且是大部分计算发生的地方。您可以构建一个具有多个 GPU 的单元，但在这样做时要意识到有效利用计算能力的挑战。如果您不熟悉并行计算，学习和正确实现这样的构建可能会非常耗时，并且会花费未知的时间，更不用说在有效部署算法/解决方案之前设计和调试软件所需的时间了。

有不同语言的软件包可以并行化您的代码并提高性能。在 R 中，我建议您考虑并行包，特别是对于在大量数据上执行相同的任务。不是将整个数据集输入到算法中，而是将其分解，使得相同的任务与数据集的块并行执行，从而使其更高效。在适用的情况下，您还应该实现`lapply`函数。这个函数接受一个参数并将其传递给一个函数，使得执行复杂的操作比使用嵌套循环在计算上更有效。

我对 GPU 的建议(截至 2017 年初)集中在以下 Nvidia 型号上:

*   泰坦 x 号
*   GTX 680
*   GTX 980

截至 2017 年初，英伟达是少数几家专注于开发专门用于深度学习的 GPU 的公司之一。(注意，AMD 正在与谷歌合作创建深度学习硬件，将于 2017 年某个时候发布。)虽然这对普通从业者来说可能不太划算，但对于专业人士或有足够预算的人来说，我建议您在 AMD 的 FirePro S9300 x2 GPU 发布时查看其规格和性能评论。

选择 GPU 取决于您想要解决的问题类型以及您预计在此过程中消耗的内存量。使用 CNN 的人应该会消耗大量内存，尤其是在训练给定模型的过程中。深度学习的图像和其他数据的物理存储是另一个需要记住的考虑因素。尽管固态存储和虚拟存储的价格都大幅下降，但您应该留出时间来正确估计所需的存储。

## 中央处理器

除了执行非常基本的算术、逻辑和输入/输出功能之外，CPU 还指示计算机应该进行什么操作以及这些操作应该在哪里进行。CPU 还与 GPU 密切合作，以启动函数调用并启动向 GPU 的计算传输。对于深度学习特定的工作，CPU 核心的数量以及 CPU 缓存大小都很重要。大多数深度学习库依赖于使用单个 CPU 线程，通常每个 GPU 使用一个线程就可以很好地执行。然而，每个 GPU 使用更多线程可能会带来更好的性能——将这一事实与您打算执行的任务联系起来。对于图像分类任务，比如经典的 MNIST 数字分类任务，我发现如果我在使用本地机器时遇到困难，使用 AWS 的 g2.2xlarge 实例就足够了——它提供了 1 个 GPU，15 GB 的 RAM 和 60 GB 的 SSD 存储。

关于 CPU 缓存大小，有几种不同速度的缓存类型。L1 和 L2 往往很快，L3 和 L4 很慢。CPU 缓存的目的是通过匹配密钥对值来帮助加速计算。在实际环境中遇到的大多数数据集都太大，无法放入 CPU 缓存中，因此对于每个小批量，将从给定计算机上的 RAM 中读入新数据。在深度学习的情况下，大部分计算发生在 GPU 中，所以你不必担心购买能够处理这种负载的 CPU。但是，由于 CPU 缓存未命中，您可能会经常看到机器性能不佳，并且您有延迟问题。这导致了缓存未命中的核心考虑因素:RAM 以及在机器学习和深度学习中经常需要更多 RAM。

## 随机存取存储器

ram 存储经常使用的程序指令，使得程序的速度增加，因为它存储将被读取或写入的数据，而不管其在 RAM 中的位置。至于你需要的内存大小，它应该与你正在使用的 GPU 的大小相当。使用小于 GPU 大小的 RAM 可能会导致延迟问题，这可能会导致问题，特别是在训练不同的网络(如 CNN)时。使用更多而不是更少的 RAM 可以让您更容易地执行预处理和特征工程。说“买尽可能多的内存”很容易，但当然这并不总是可能的。然而，你应该考虑在这方面投入大量的可用资金。

## 母板

主板是主要的电路板，除了个人电脑之外，在各种产品中都可以找到。它的主要目的是促进计算机内各种组件之间的通信，并保持这些组件之间的连接器。确保主板有足够的 PCIe 端口来支持将安装在给定计算机中的 GPU 数量，并支持所有其他选择的硬件组件。

## 电源装置(PSU)

电源单元将交流电转换为稳定的直流电，以便计算机内的组件可以使用。关于用于深度学习的 PSU，请注意，如果您使用多个 GPU，请购买一个可以服务于您使用的 GPU 数量的 PSU。深度学习通常需要密集的训练，运行这些实例的成本应该最小化。给定深度学习机器所需的瓦特数可以通过将 GPU 和 CPU 的瓦特数相加，同时为计算机内的其他组件和功耗差异添加大约 200 瓦特来估算。

## 优化机器学习软件

本章的主要目的是让读者找到他们在改进机器方面的关注点。最终目标是提高被测试和部署的软件的性能，但是其中一部分涉及到直接优化软件。为此，在所有其他步骤之前，我建议您尝试改进您正在使用的算法，或者在实现给定解决方案时找到一个更好的算法。算法的最佳选择和找到所述算法的最佳实现可能相当耗时。这可能需要通读大量的文档，深入查看各种函数的代码，还可能需要做实验。虽然这本书是为那些在 R 方面相对有经验的人和刚接触深度学习/机器学习的人准备的，但在阅读完这篇文章后，你应该有足够的信心开始创建自己的各种机器学习算法的实现。虽然很费时间，但这样做可以让你学到很多关于不同算法及其实现的效率。

目前一个常见的争论围绕着使用哪种语言。r 是一种非常容易理解的语言，非常适合用于概念验证，特别是因为它的语法允许快速编写和测试代码。然而，当试图为任何需要实时应用的东西部署算法时，尤其是当试图将软件嵌入其他应用时，往往会被证明是麻烦的。如果你打算在一个专业的环境中工作，在设计任何事情的最终解决方案时，请记住这一点。通常，那些希望提高速度的人经常用 C++来写。当然，这本书没有涵盖 C++，也没有涉及 C++中的任何包，但是读者应该探索 C++中用于机器学习和深度学习的无数库。

## 摘要

本章应该让读者对他们在为机器学习进行专门构建时，或者在试图修改他们现有的硬件以更好地服务于他们的深度学习需求时，应该关注的一些最常见的问题有一个基本的了解。

第 [10](10.html) 章深入探讨了更多使用机器学习和深度学习解决方案的实际例子。