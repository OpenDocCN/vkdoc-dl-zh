# 一、深度学习简介

随着硬件的进步和大数据的出现，更先进的计算方法变得越来越受欢迎。消费者对更好产品的需求不断增加，企业寻求更有效地利用资源，这也是推动这一趋势的主要原因。为了应对这些市场力量，我们最近看到了对机器学习领域的新的广泛关注。在统计学、数学和计算机科学的交叉领域，机器学习是指创建和研究算法的科学，这些算法通过设计以迭代的方式改善自己的行为。最初，该领域致力于开发人工智能，但由于当时存在的理论和技术的限制，将这些算法集中在特定任务上变得更符合逻辑。现有的大多数机器学习算法都专注于函数优化，产生的解决方案并不总是解释数据中的潜在趋势，也没有提供人工智能试图接近的推理能力。因此，使用机器学习算法经常成为一个重复的试错过程，其中跨问题的算法选择会产生不同的性能结果。这在某些情况下没问题，但是在语言建模和计算机视觉的情况下，这就成问题了。

为了应对机器学习的一些缺点，以及我们今天可支配的理论和技术能力的重大进步，深度学习已经出现，并正在迅速扩展为最令人兴奋的科学领域之一。它正被用于自动驾驶汽车、社交媒体平台上的图像识别以及从一种语言到另一种语言的文本翻译等技术。深度学习是机器学习的子领域，致力于构建算法，解释和学习传统机器学习算法通常无法实现的高层次和低层次的数据抽象。深度学习中的模型通常受到许多知识来源的启发，如博弈论和神经科学，许多模型通常模仿人类神经系统的基本结构。随着该领域的发展，许多研究人员设想了一个世界，在这个世界中，软件不像今天经常需要的那样被硬编码，从而允许更健壮、更通用的解决问题的解决方案。

虽然它最初是在类似于机器学习的空间中开始的，其中主要关注的是对不同复杂程度的约束满足，但深度学习现在已经发展到包含更广泛的算法定义，这些算法能够理解对应于不同复杂层次的数据的多级表示。换句话说，算法不仅具有预测和分类能力，而且能够学习不同程度的复杂性。这方面的一个例子是在图像识别中发现的，在图像识别中，神经网络建立在识别睫毛、脸、人等等的基础上。这其中的力量是显而易见的:我们可以达到创建智能软件所需的复杂程度。我们目前在自动更正等功能中看到这一点，该功能针对每个人的词汇，对观察到的语音模式的建议更正进行建模。

深度学习模型的结构通常是这样的，它们具有处理数据的非线性单元或神经元的层，并且这些模型中的多个层处理数据的不同抽象级别。图 [1-1](#Fig1) 显示了神经网络层的可视化。

![A435493_1_En_1_Fig1_HTML.jpg](img/A435493_1_En_1_Fig1_HTML.jpg)

图 1-1。

Deep neural network

深度神经网络的区别在于具有许多隐藏层，这些隐藏层被称为“隐藏的”，因为除了知道它们是前一层的输出之外，我们不一定看到这些神经元的输入和输出是什么。层的增加，以及这些层的神经元内部的功能，是将一个单独的架构与另一个架构区分开来，并建立给定模型的不同用例的原因。

更具体地说，这些模型的较低层解释“如何”，而较高层的神经网络处理“为什么”。这些层中使用的函数取决于用例，但通常可由用户定制，这使得它们比通常用于分类和回归的一般机器学习模型更加健壮。深度学习模型的基本假设是，被解释的数据是由分层组织的不同因素的相互作用产生的。因此，拥有多个层允许模型处理数据，以便从简单的方面到更大的结构建立理解。这些模型的目标是在没有许多机器学习算法需要的相同程度的显式指令的情况下执行任务。关于如何使用这些模型，一个主要的好处是当应用于无监督学习问题时，或者在执行实验之前我们不知道响应变量 y 应该给定一组解释变量 x 的问题时，它们表现出的前景。一个例子是图像识别，特别是在模型已经根据给定的数据集训练之后。假设我们在测试阶段输入一张狗的图片，这意味着我们没有告诉模型这张图片是什么。神经网络将首先识别鼻子之前的睫毛，然后识别狗的头部形状，等等，直到它将图像分类为狗的图像。

## 深度学习模型

既然我们已经建立了深度学习的简要概述，那么讨论一下你在本书中将会学到什么，以及描述我们将在这里讨论的模型将会很有用。

本文假设你对数学和统计学有一定的了解。尽管如此，我们将简要回顾理解线性代数、优化和机器学习所需的所有概念，以便我们将形成掌握深度学习所需的坚实知识基础。虽然它确实有助于准确理解所有这些技术信息，但那些对更高级的数学感到不舒服的人不必担心。如果需要的话，这份正文以这样的方式被写，给读者进一步研究它所必需的所有背景信息。然而，本文的主要目标是向读者展示如何应用机器学习和深度学习模型，而不是对所有讨论的理论概念进行冗长的学术论述。

在我们充分回顾了所有必要的数学和机器学习概念之后，我们将进一步详细讨论机器学习模型。本节描述并举例说明深度学习模型。

### 单层感知器模型(SLP)

单层感知器(SLP)模型是最简单的神经网络形式，也是深度学习中开发的更高级模型的基础。通常，我们在分类问题中使用 SLP，在分类问题中，我们需要基于输入给出数据观察标签(二元或多项式)。输入图层中的值在乘以权重并在累积和中添加偏差后，直接发送到输出图层。然后，这个累积和被放入一个激活函数中，这个函数就是定义输出的函数。当该输出高于或低于用户确定的阈值时，确定最终输出。研究人员麦卡洛克-皮茨神经元在 20 世纪 40 年代描述了一个类似的模型(见图 [1-2](#Fig2) )。

![A435493_1_En_1_Fig2_HTML.jpg](img/A435493_1_En_1_Fig2_HTML.jpg)

图 1-2。

Single layer perceptron network

### 多层感知器模型(MLP)

与 SLP 非常相似，多层感知器(MLP)模型具有多个层，这些层以这样一种方式相互连接，从而形成一个前馈神经网络。一层中的每个神经元都与另一层的神经元有直接连接。该模型和单层感知器模型的关键区别因素之一是反向传播算法，这是训练神经网络的一种常用方法。反向传播将从输出层计算的误差传递到输入层，这样我们可以看到每一层对误差的影响，并相应地改变网络。这里，我们使用梯度下降算法来确定每次迭代时权重应该改变的程度。梯度下降(Gradient descent)是另一种流行的机器学习/优化算法，它只是一个函数的导数，这样我们就可以找到一个指向最大动量方向的标量值(一个以大小为唯一属性的数字)。通过减去梯度，我们会得到一个比当前更优的解，直到达到全局最优(见图 [1-3](#Fig3) )。

![A435493_1_En_1_Fig3_HTML.jpg](img/A435493_1_En_1_Fig3_HTML.jpg)

图 1-3。

MultiLayer perceptron network

### 卷积神经网络

卷积神经网络(CNN)是最常用于图像处理和计算机视觉的模型。它们被设计成模仿动物视觉皮层的结构。具体来说，CNN 具有三维排列的神经元:宽度、高度和深度。给定层中的神经元仅连接到前一层的一小部分区域。CNN 模型最常用于图像处理和计算机视觉(见图 [1-4](#Fig4) )。

![A435493_1_En_1_Fig4_HTML.jpg](img/A435493_1_En_1_Fig4_HTML.jpg)

图 1-4。

Convolutional neural network

### 循环神经网络

循环神经网络(RNNs)是人工神经网络(ann)的模型，其中单元之间的连接形成有向循环。具体来说，有向循环是一个序列，其中沿着顶点和边的行走完全由所使用的边集决定，因此具有某种特定顺序的外观。rnn 通常专门用于语音和手写识别(参见图 [1-5](#Fig5) )。

![A435493_1_En_1_Fig5_HTML.jpg](img/A435493_1_En_1_Fig5_HTML.jpg)

图 1-5。

Recurrent neural network

### 受限玻尔兹曼机

受限玻尔兹曼机是一种具有独特架构的二进制马尔可夫模型，使得存在多层隐藏随机变量和对称耦合的随机二进制单元的网络。DBMs 由一组可见单元和一系列隐藏单元层组成。然而，同一层的单元之间没有连接。DMBs 可以在对象或语音识别等任务中学习复杂和抽象的内部表征(见图 [1-6](#Fig6) )。

![A435493_1_En_1_Fig6_HTML.jpg](img/A435493_1_En_1_Fig6_HTML.jpg)

图 1-6。

Restricted Boltzmann machine

### 深度信念网络

深度信任网络类似于 RBM，除了每个子网的隐藏层实际上是下一个子网的可见层。dbn 是广义的生成图形模型，由多层潜在变量组成，各层之间有联系，但各层单元之间没有联系(见图 [1-7](#Fig7) )。

![A435493_1_En_1_Fig7_HTML.jpg](img/A435493_1_En_1_Fig7_HTML.jpg)

图 1-7。

Deep belief networks

## 讨论的其他主题

在涵盖了所有关于模型的信息之后，我们将转向理解数据科学的实践。为了有助于这项工作，本节涵盖了其他感兴趣的主题。

### 试验设计

这篇文章的重点最终是让读者对深度学习模型有一个理论上的理解，这样他们就能舒服地应用它们。因此，重要的是讨论实验设计的要素，以帮助读者理解构建其研究的适当方法，从而得出可操作的见解，而不是浪费时间和/或精力。在很大程度上，鉴于深度学习经常遇到的问题，除了定义最佳实践之外，我还将借鉴 Fisher 的原则。

### 特征选择

作为实验设计的一部分，但最终完全是研究的一个子课题，我将介绍变量选择的概念和数据科学家处理高维数据集经常使用的多种方法。具体来说，我将深入谈论主成分分析以及遗传算法。所有讨论的算法都可以在开源包的 R 统计语言中找到。对于那些想进一步研究这个领域的人，我会参考与这个主题相关的论文。从深度学习的角度来看，我们将深入讨论每个模型如何通过层架构的设计来执行其自己的特定特征选择方法，以及解决该领域的最新发现。

### 应用机器学习和深度学习

对于文本的最后一部分，我将带领读者使用 R 语言的包来进行机器学习和深度学习模型，以解决专业和学术设置中常见的问题。希望从这些例子中，读者将被激励在他们的专业和/或学术追求中应用机器学习和深度学习。所有例子、实验和研究的代码都使用 R 编程语言，并将通过 GitHub 提供给所有读者(更多信息请参见附录)。讨论的主题包括使用深度学习模型的回归、分类和图像识别。

### 深度学习的历史

现在，我们已经涵盖了文本的大致轮廓，除了读者在此期间预计要学习的内容，我们将看到该领域如何发展到这一阶段，并了解它今天寻求的方向。虽然深度学习是一个相对较新的领域，但它有着丰富而充满活力的历史，充满了今天仍在进行的发现。至于这个领域最清晰的起源在哪里，讨论把我们带到了 20 世纪 60 年代。

第一个经常与深度学习模型相关联的工作学习算法是由 Ivakhenenko 和帕拉开发的。1965 年，他们在一篇名为“数据处理小组方法(GMDH)训练的网络”的论文中发表了他们的发现。这些是第一批前馈多层感知器类型的深度学习系统。前馈网络描述了单元之间的连接不形成循环的模型，就像在循环神经网络中一样。该模型以多项式激活函数为特征，并且通过回归分析对层进行增量增长和训练。它们随后在单独的验证集的帮助下被修剪，其中正则化被用来剔除多余的单元。

20 世纪 80 年代，福岛国浩推出了新克隆体。它是一种多层人工神经网络，主要用于手写字符识别和需要模式识别的类似任务。它的模式识别能力给了卷积神经网络灵感。不管怎样，新认知神经的灵感来自神经生理学家 Hubel 和 Wiesel 提出的一个模型。也是在这十年间，Yann LeCun 等人将反向传播算法应用于深度神经网络。这样做的最初目的是让美国电话电报公司识别邮件上手写的邮政编码。这项技术的优势是显著的，尤其是在互联网及其商业化于 20 世纪 90 年代末和 21 世纪初出现之前。

在 20 世纪 90 年代，深度学习领域见证了循环神经网络的发展，该网络需要在 RNN 中及时展开超过 1000 层，并且发现可以使用所谓的唤醒-睡眠算法来训练包含六个完全连接的层和数百个隐藏单元的网络。启发式算法，或我们应用于另一个单个或一组算法的算法，唤醒-睡眠算法是一种无监督的方法，它允许算法以输出最佳密度估计值的方式调整参数。“唤醒”阶段描述了神经元从输入到输出的放电过程。来自输入和输出的连接被修改，以增加它们在当前层之下的层中复制正确活动的可能性。“睡眠”阶段与觉醒阶段相反，因此神经元被连接激活，同时识别被修改。

正如该领域在 2000 年代初和 2010 年代取得的进展一样，当前向前发展的时期被描述为深度学习的分水岭时刻。现在，我们看到了深度学习在众多行业和领域的应用，以及用于这些模型的硬件的非常投入的改进。在未来，预计深度学习所涵盖的进步将有助于让技术在人类今天经常做的事情和传统机器学习算法表现不佳的情况下做出行动。虽然肯定还有进步，但许多公司和大学为加速进步所做的投资是显而易见的，并对世界产生了重大影响。

## 摘要

对于读者来说，重要的是最终要理解，无论我们在这里描述的任何模型是多么复杂，无论它可能提供多么有趣和强大的用途，在使用这些模型的领域中，没有什么可以替代足够的领域知识。对于高级和初级从业者来说，很容易陷入这样的陷阱:完全相信深度学习模型的输出，而不认真评估它们使用的环境。虽然看起来不言自明，但强调仔细检查结果的重要性是很重要的，更重要的是，在错误风险最有限的情况下做出可操作的推断。我希望给读者留下深刻印象的不仅仅是他们可以在哪里应用这些模型的知识，还有当今存在的技术和研究的合理限制。

这在机器学习和深度学习中尤其重要，因为尽管这些模型中的许多都很强大，并且能够达到手工几乎不可能达到的适当解决方案，但我们还没有确定为什么总是如此。例如，我们知道反向传播算法是如何工作的，但我们看不到它是如何工作的，我们也不知道到底发生了什么才能得出这样的结论。这种情况产生的主要问题是，当一个流程中断时，我们不一定总是知道为什么会中断。尽管已经创建了尝试和跟踪神经元及其激活顺序的方法，但神经网络的决策过程并不总是一致的，尤其是在不同的问题上。我希望读者在前进时记住这一点，并在必要时适当地评估这一点。