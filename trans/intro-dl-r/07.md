# 7.自动编码器、受限玻尔兹曼机器和深度信念网络

本章涵盖了一些更新、更先进的深度学习模型，这些模型在该领域越来越受欢迎。它旨在帮助您了解数据科学领域的一些最新发展。要了解这些模型在实际环境中是如何应用的，请参见第 [10](10.html) 和 [11](11.html) 章，我们将在实际例子中使用这些模型。

## 自动编码器

在讨论受限玻尔兹曼机器(RBM)之前，我想解决一组相关的算法。自动编码器被称为特征提取器，因为它们能够学习数据的编码/表示。输入到 RBM 的数据将与我们输入到任何机器学习算法的数据相同，但为了简单起见，我们可以将其想象为一个 M x N 矩阵，其中每一列是一个唯一的特征，每一行是 N 个特征的唯一观察。它是一种无监督的学习方法，使用反向传播找到一种方法来重建自己的输入。由 Geoffrey Hinton 和其他研究人员开发的自动编码器解决了如何执行反向传播的问题，而无需明确告诉自动编码器要学习什么。

自动编码器由两部分组成:编码器和解码器。让我们看一个简单的例子，我们称之为 n/p/n 自动编码器架构。该架构由![$$ n,\ p,\ m,\ \mathbb{G},\ \mathbb{F},\ \mathcal{A},\ \mathrm{\mathcal{B}},\ \mathcal{X},\ \varDelta, $$](img/A435493_1_En_7_Chapter_IEq1.gif)表示，其中以下内容为真:

1.  ![$$ \mathbb{G}\ \mathrm{and}\ \mathbb{F} $$](img/A435493_1_En_7_Chapter_IEq2.gif)正集。
2.  n 和 p 是正整数，其中![$$ 0< p< n. $$](img/A435493_1_En_7_Chapter_IEq3.gif)
3.  设![$$ \mathcal{A} $$](img/A435493_1_En_7_Chapter_IEq4.gif)是一个函数，其中![$$ \mathcal{A}:\ {\mathbb{G}}^p\to\ {\mathbb{F}}^n $$](img/A435493_1_En_7_Chapter_IEq5.gif)
4.  设![$$ \mathcal{A} $$](img/A435493_1_En_7_Chapter_IEq6.gif)是一个函数，其中![$$ \mathrm{\mathcal{B}}:\ {\mathbb{F}}^n\to\ {\mathbb{G}}^p $$](img/A435493_1_En_7_Chapter_IEq7.gif)
5.  ![$$ \mathcal{X}=\left\{{x}_1,\dots,\ {x}_M\right\}\in {\mathbb{F}}^n $$](img/A435493_1_En_7_Chapter_IEq8.gif)当目标出现时，![$$ \mathcal{Y}=\left\{{y}_1, \dots,\ {y}_M\right\}\in {\mathbb{F}}^n $$](img/A435493_1_En_7_Chapter_IEq9.gif)
6.  δ是 L <sub>p</sub> 范数或一些其他损失/相异函数。

对于任意的![$$ A\in \mathcal{A}, $$](img/A435493_1_En_7_Chapter_IEq10.gif)和![$$ B\in \mathrm{\mathcal{B}}, $$](img/A435493_1_En_7_Chapter_IEq11.gif)，自动编码器将输入 x 转换为输出向量:

![$$ \widehat{x}= A\circ B(x)\in {\mathbb{F}}^n $$](img/A435493_1_En_7_Chapter_Equa.gif)

概括地说，我们试图通过使用自动编码器来解决的问题最终是一个优化问题——在这种情况下，它是最小化损失/相异度函数。我们把这个问题定义为:

![$$ \min E\left( A, B\right) = \underset{A, B}{ \min }{\displaystyle \sum_{m=1}^M} E\left({x}_m\right)=\underset{A, B}{ m in}\ {\displaystyle \sum_{m=1}^M}\varDelta \left( A\circ B\left({x}_m\right),{x}_m\right) $$](img/A435493_1_En_7_Chapter_Equb.gif)

当目标出现时:

![$$ \min E\left( A, B\right) = \underset{A, B}{ \min }{\displaystyle \sum_{m=1}^M} E\left({x}_m,\ {y}_m\right)=\underset{A, B}{ m in}\ {\displaystyle \sum_{m=1}^M}\varDelta \left( A\circ B\left({x}_m\right),{y}_m\right) $$](img/A435493_1_En_7_Chapter_Equc.gif)

## 线性自动编码器与主成分分析(PCA)

对于这个例子，让我们看看主成分分析(PCA)和线性自动编码器之间的相似之处。主成分分析的主要目的是找到原始数据集的线性变换，这些变换包含了。当将这种分析转换到原始数据集时，我们使用它来实现降维。第 [8](08.html) 章更详细地讨论了 PCA，但是我将在这里解释它与线性自动编码器的关系。简单地说，PCA 是一种正交线性变换，其中我们寻求最大化每个主成分内的方差，以满足每个主成分彼此不相关的约束。让我们把 y 定义为:

![$$ {y}_i= A{x}_i, $$](img/A435493_1_En_7_Chapter_Equd.gif)

其中![$$ x\in {\mathrm{\mathbb{R}}}^n $$](img/A435493_1_En_7_Chapter_IEq12.gif)和是数据集，![$$ A\in {\mathrm{\mathbb{R}}}^{nxn} $$](img/A435493_1_En_7_Chapter_IEq13.gif)和是正交协方差矩阵。与 PCA 的情况一样，每个主成分应该按照方差递减的顺序列出。我们定义最大方差的方向如下:

![$$ \widehat{w}= arg\underset{w}{max}\frac{w^T{X}^T Xw}{w^T w} $$](img/A435493_1_En_7_Chapter_Eque.gif)

根据定义，这是一个约束优化问题，可通过使用拉格朗日乘数来解决。因此，我们可以把这个问题改造成

![$$ \mathrm{\mathcal{L}}\left( w,\ \lambda \right) = {w}^T C w-\lambda \left({w}^t w-1\right), $$](img/A435493_1_En_7_Chapter_Equf.gif)

![$$ C w-\lambda w=0, $$](img/A435493_1_En_7_Chapter_Equg.gif)

![$$ C w=\lambda w $$](img/A435493_1_En_7_Chapter_Equh.gif)

其中![$$ C={X}^T X. $$](img/A435493_1_En_7_Chapter_IEq14.gif)

单层自动编码器将产生与 PCA 几乎完全相同的特征向量。也就是说，PCA 在推导过程中假设了一个线性系统，而自动编码器则不然。在我们在自动编码器中强制线性的情况下，将得到类似的答案。

要查看自动编码器的应用，请参见第 [11 章](11.html)，其中我们专门使用这些模型进行异常检测，并提高标准机器学习模型的模型性能。

## 受限玻尔兹曼机器

在 20 世纪 80 年代，Geoffrey Hinton、David Ackley 和 Terrence Sejnowski 开发了这种算法，它可以被描述为一种随机神经网络。当时，它代表了深度学习科学的突破，因为它是第一批能够学习数据的内部表示并有能力解决困难的组合学问题的模型之一。标准的受限玻尔兹曼机器具有二进制值的隐藏和可见单元，由权重矩阵 W 和偏置权重组成，权重矩阵 W 与给定的一组隐藏单元和可见单元之间的连接相关联。隐藏、可见和偏置单元可以被认为是类似于出现在多层感知器模型中的那些相同的单元。给定这些，一个组态的能量表述如下:

![$$ E\left( v, h\right) = - {\displaystyle \sum_{i=1}^N}{a}_i{v}_i - {\displaystyle \sum_{j=1}^N}{b}_j{h}_j - {\displaystyle \sum_{i=1}^N}{\displaystyle \sum_{j=1}^N}{v}_i{w}_{i, j}{h}_j $$](img/A435493_1_En_7_Chapter_Equi.gif)

这个能量函数类似于 Hopfield 网络的输出神经元(见图 [7-1](#Fig1) )，是一种特殊类型的 RNN。由约翰·霍普菲尔德在 20 世纪 80 年代创建，与其他 RNN 模型一样，输入通常是我们怀疑具有某种潜在模式的数据(例如时间序列)。计算所有输入的加权和，然后将其输入线性分类器，如逻辑函数。我们将输出定义为:

![$$ \widehat{y}=\left\{\begin{array}{c}\hfill 1,\kern0.5em {\displaystyle \sum }{w}_i{x}_i\ge 0\hfill \\ {}\hfill -1,\kern0.75em {\displaystyle \sum }{w}_i{x}_i < 0\hfill \end{array}\right. $$](img/A435493_1_En_7_Chapter_Equj.gif)

![A435493_1_En_7_Fig1_HTML.jpg](img/A435493_1_En_7_Fig1_HTML.jpg)

图 7-1。

Visualization of a Hopfield network

将数据输入模型后，网络中的所有节点都会收到特定的值。然后，使用异步或同步更新对网络进行多次迭代。达到停止标准后，将显示神经元内的值。Hopfield 网络的主要动机是发现存储在权重矩阵中的模式。

当回过头来参考 RBM 模型时，构成数据基础的概率分布被定义为

![$$ P\left( v, h\right)=\frac{1}{Z}{e}^{- E\left( v, h\right)},\kern0.5em Z={\displaystyle \sum }{e}^{- E\left( v, h\right)}, $$](img/A435493_1_En_7_Chapter_Equk.gif)

![$$ P(v)=\frac{1}{Z}{\displaystyle \sum }{e}^{- E\left( v, h\right)} $$](img/A435493_1_En_7_Chapter_Equl.gif)

其中![$$ {e}^{- E\left( v, h\right)} $$](img/A435493_1_En_7_Chapter_IEq15.gif) =指数函数，上标为前述能量函数的负值。

RBMs 和二部图具有相似的性质。这样，给定来自可见单元的激活，来自隐藏单元的激活是相互独立的，使得

![$$ P\left( v\Big| h\right) = {\displaystyle \prod_{i=1}^N} P\left({h}_j\Big| v\right),\kern0.5em P\left( h\Big| v\right) = {\displaystyle \prod_{j=1}^N} P\left({h}_j\Big| v\right), $$](img/A435493_1_En_7_Chapter_Equm.gif)

而个体激活概率分别是

![$$ P\left({h}_j=1\Big| v\right)=\sigma \left({b}_i + {\displaystyle \sum_{j=1}^N}{w}_{i, j}{v}_i\right),\kern0.5em P\left({v}_i=1\Big| h\right)=\sigma \left({a}_j + {\displaystyle \sum_{i = 1}^M}{w}_{i, j}{h}_i\right), $$](img/A435493_1_En_7_Chapter_Equn.gif)

![$$ \sigma =\frac{1}{1+{e}^{- k\left( x - {x}_0\right)}} $$](img/A435493_1_En_7_Chapter_Equo.gif)

其中 a =激活单位。

RBM 的可见单元的值可以从多项式分布中导出，而隐藏单元的值可以从伯努利分布中导出。在我们为可见单元使用 softmax 函数的实例中，我们有以下函数:

![$$ P\left({v}_i^k=1\Big| h\right) = \frac{exp\left({a}_i^k + {\displaystyle {\sum}_{j=1}}{W}_{i, j}^k{h}_j\right)}{{\displaystyle {\sum}_{k=1}^K} exp\left({a}_i^k + {\displaystyle {\sum}_{j=1}}{W}_{i, j}^k{h}_j\right)} $$](img/A435493_1_En_7_Chapter_Equp.gif)

传统上，通过反向传播使用梯度下降来优化 RBM 内部的权重，直到我们收敛到最优解。RBM 最流行的用例之一是填充数据集中缺失的值，特别是在协同过滤的情况下。第 11 章看一个执行协同过滤的简单例子。如果你有兴趣阅读关于使用 RBMs 执行这一操作的文章，可以搜索 Salakhutdinov 等人关于使用 RBMs 进行协同过滤的论文( [`http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf`](http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf) )。

关于 RBMs 的实现，有几个包您可以随意探索，比如 deepnet、darch 和其他在线实现。如果您觉得足够先进，您也可以寻求创建自己的实现。与此同时，你应该检查深度学习框架的更新，看看他们是否/何时添加 RBM 实现。

## 对比发散学习

由 Hinton 开发的对比发散(CD)学习是训练受限玻尔兹曼机器的标准方法。它基于使用 Gibbs 采样的思想，运行 k 个步骤，用训练集的训练样本初始化，并在 k 个步骤后产生样本。作为无向图模型的训练方法，它有更广泛的应用，但它最流行的用例是 RBM 的训练。我将从定义对数似然的梯度开始讨论:

![$$ {\displaystyle \sum_h} p\left( h\Big| v\right)\ \frac{\partial E\left( v, h\right)}{\partial {w}_{i, j}} = {\displaystyle \sum_h} p\left( h\Big| v\right){h}_i{v}_j={\displaystyle \sum_h}{\displaystyle \prod_{k=1}^n} p\left({h}_k\Big| v\right){h}_i{v}_j $$](img/A435493_1_En_7_Chapter_Equq.gif)

![$$ ={\displaystyle \sum_{h_i}}{\displaystyle \sum_{h_{- i}}} p\left({h}_i\Big| v\right) p\left({h}_i\Big| v\right){h}_i{v}_j $$](img/A435493_1_En_7_Chapter_Equr.gif)

![$$ = {\displaystyle \sum_{h_i}} p\left({h}_i\Big| v\right){h}_i{v}_j{\displaystyle \sum_{h_{- i}}} p\left({h}_{- i}\Big| v\right)= p\left({H}_i=1\Big| v\right){v}_j $$](img/A435493_1_En_7_Chapter_Equs.gif)

![$$ = s i g\left({\displaystyle \sum_{j=1}^m}{w}_{i, j}{v}_j+{c}_i\right) $$](img/A435493_1_En_7_Chapter_Equt.gif)

直观上，我们将对数似然定义为某个参数具有某个值的概率。上面，我们将 sig()函数定义为 signum 函数，它返回输入的符号。

我们用下面的等式定义训练模式 v 的对数似然的梯度:

![$$ \frac{\partial ln\mathrm{\mathcal{L}}\left(\theta \Big| v\right)}{\partial {w}_{i, j}} = - {\displaystyle \sum_h} p\left( h\Big| v\right)\ \frac{\partial E\left( v, h\right)}{\partial {w}_{i, j}}+{\displaystyle \sum_{v, h}} p\left( v, h\right)\ \frac{\partial E\left( v, h\right)}{\partial {w}_{i, j}} $$](img/A435493_1_En_7_Chapter_Equu.gif)

![$$ =\kern0.5em {\displaystyle \sum_{h_i}} p\left({h}_i\Big| v\right){h}_i{v}_j-{\displaystyle \sum_v} p(v){\displaystyle \sum_h} p\left( h\Big| v\right){h}_i{v}_j $$](img/A435493_1_En_7_Chapter_Equv.gif)

![$$ = p\left({H}_i=1\Big| v\right){v}_j-{\displaystyle \sum_v} p(v) p\left({H}_i=1\Big| v\right){v}_j $$](img/A435493_1_En_7_Chapter_Equw.gif)

训练集![$$ S=\left\{{v}_1, \dots,\ {v}_{\ell}\right\} $$](img/A435493_1_En_7_Chapter_IEq16.gif)上的梯度的平均值被给定为

![$$ \frac{1}{\ell }{\displaystyle \sum_{v\in S\ }}\frac{\partial ln\mathrm{\mathcal{L}}\left(\theta \Big| v\right)}{\partial {w}_{i, j}}=\frac{1}{\ell }{\displaystyle \sum_{v\in S}}\left[-{\mathbb{E}}_{p\left( h\Big| v\right)}\left[\frac{\partial E\left( v, h\right)}{\partial {w}_{i, j}}\right]+{\mathbb{E}}_{p\left( h, v\right)}\left[\frac{\partial E\left( v, h\right)}{w_{i, j}}\right]\right] $$](img/A435493_1_En_7_Chapter_Equx.gif)

![$$ =\frac{1}{\ell }{\displaystyle \sum_{v\in S\ }}\left[{\mathbb{E}}_{p\left( h\Big| v\right)}\left[{v}_i{h}_j\right]-{\mathbb{E}}_{p\left( h, v\right)}\left[{v}_i{h}_j\right]\right] $$](img/A435493_1_En_7_Chapter_Equy.gif)

![$$ = {\left\langle {v}_i{h}_j\right\rangle}_{p\left( h\Big| v\right) q(v)} - {\left\langle {v}_i{h}_j\right\rangle}_{p\left( h, v\right)} $$](img/A435493_1_En_7_Chapter_Equz.gif)

其中

![$$ {\displaystyle \sum_{v\in S\ }}\frac{\partial ln\mathrm{\mathcal{L}}\left(\theta \Big| v\right)}{\partial {w}_{i, j}}\propto {\left\langle {v}_i{h}_j\right\rangle}_{data} - {\left\langle {v}_i{h}_j\right\rangle}_{model} $$](img/A435493_1_En_7_Chapter_Equaa.gif)

![$$ \frac{\partial ln\mathrm{\mathcal{L}}\left(\theta \Big| v\right)}{\partial {b}_j}={v}_j - {\displaystyle \sum_v} p(v){v}_j, $$](img/A435493_1_En_7_Chapter_Equab.gif)

![$$ \frac{\partial ln\mathrm{\mathcal{L}}\left(\theta \Big| v\right)}{\partial {c}_j}= p\left( H=1\Big| v\right) - {\displaystyle \sum_v} p(v) p\left({H}_i=1\Big| v\right) $$](img/A435493_1_En_7_Chapter_Equac.gif)

现在，回到我们最初的讨论，我们近似训练模式 v 的对数似然的梯度如下:

![$$ C{D}_k\left(\theta,\ {v}^0\right) = -{\displaystyle \sum_h} p\left( h\Big|{v}^0\right)\frac{\partial E\left({v}^0,\ h\right)}{\partial \theta} + {\displaystyle \sum_h} p\left( h\Big|{v}^k\right)\frac{\partial E\left({v}^k,\ h\right)}{\partial \theta} $$](img/A435493_1_En_7_Chapter_Equad.gif)

每一个参数的导数都是根据 p(v)上期望值的近似值计算出来的。在批量学习中，我们计算整个训练集的梯度。然而，在某些情况下，对训练数据集的子集运行这种近似在计算上更有效，我们称之为小批量。如果我们在执行这种近似时评估训练集的单个元素，这就是所谓的在线学习。在 RBMs 中，我们将重建误差称为实际输入和预测输入之间的差异，该差异从训练开始向前移动时急剧下降。建议使用这一指标，但要谨慎行事。CD 学习近似地优化了训练数据和由 RBM 和吉布斯链的混合率产生的数据之间的 KL 散度。也就是说，如果混合率也很小，重建误差通常可能看起来很小。随着 RBM 内权重的增加，我们通常会观察到混合速率反向移动。但是，较低的混合率并不总是意味着一个模型优于混合率较高的模型。

与其他深度学习模型类似，RBM 权重通常使用从正态分布随机采样的值或其他无穷小的值来初始化。关于学习率，必须考虑梯度方法的相同因素，特别是注意不要选择太大或太小的学习率。也就是说，自适应学习速率可能会导致问题，因为它会给出由于较低的重建误差而导致模型正在改善的外观，然而，如前所述，情况可能并不总是如此。建议每次权重更新一般约为当前权重的![$$ {10}^{-3} $$](img/A435493_1_En_7_Chapter_IEq17.gif)倍。初始隐藏偏差和权重通常通过从正态分布中随机选择它们来初始化，这是其他神经网络模型的标准操作程序。

## 成果管理制内的势头

为了提高 RBM 的学习速度，动量法是一种推荐的方法。想象一个梯度图，如图 [7-2](#Fig2) 所示。如果我们可以想象一个圆上的一个点所代表的误差，那么当这个点越来越接近最小值时，它会获得“动量”,但如果它试图越过这个点，沿着对面的球体向上移动，它就会失去动量。

![A435493_1_En_7_Fig2_HTML.jpg](img/A435493_1_En_7_Fig2_HTML.jpg)

图 7-2。

Gradient plot

与传统的梯度下降公式不同，动量法逐渐影响参数更新的速度。我们把动量定义为一个给定时期后仍然存在的速度的百分比；我们假设一个参数的速度随时间衰减。实际上，动量方法使得参数的更新朝着不是最陡下降的方向移动，除了不太复杂之外，与典型的梯度方法一样。使用动量法时，建议将动量参数α设置为. 5。当进一步减小重建误差变得更加困难时，动量应该增加到 0.9。如果我们注意到重建误差的不稳定性——通常表现为偶尔的增量增加——我们会将学习率降低 2 倍，直到这种现象消失。我们将更新参数的动量法定义如下:

![$$ \varDelta {\theta}_i(t)={v}_i(t)=\alpha {v}_i\left( t-1\right)-\epsilon \frac{ d E(t)}{d{\theta}_i} $$](img/A435493_1_En_7_Chapter_Equae.gif)

## 重量衰减

权重衰减可视为一种正则化形式，类似于岭回归和/或 LASSO 中的参数正则化。在 RMBs 中，我们通常使用欧几里德范数，我们将其表示为权重的成本。通常，从业者取罚项的导数，并乘以学习率。这防止了学习率改变我们试图优化的目标函数。权重衰减有助于减少过度拟合，以这种方式实现的解决方案不会有异常大的权重或权重总是打开或关闭的单元。它还提高了混合率，参考我们执行的吉布斯采样，使 CD 学习更准确。Geoffrey Hinton 建议最初使用 0.0001 的权重成本。

## 稀少

一般来说，一个好的模型是具有隐藏单元的模型，这些隐藏单元只在部分时间是活动的。原因是，与活动单元密集的模型相比，活动单元稀疏的模型更容易解释。我们可以通过使用正则化指定一个单元活动的概率来实现稀疏性。这个概率用 q 表示，用

![$$ {q}_{new}=\lambda {q}_{ild} + \left(1-\lambda \right){q}_{current}, $$](img/A435493_1_En_7_Chapter_Equaf.gif)

估计

其中 q <sub>current</sub> =隐藏单元的平均激活概率

要使用的自然惩罚度量是期望分布和实际分布之间的交叉熵:

![$$ Sparsity\ penalty\propto - p logq-\left(1- p\right) log\left(1- q\right) $$](img/A435493_1_En_7_Chapter_Equag.gif)

正如 Hinton 所建议的，我们寻求低至 0.1 <sup>9</sup> 和高至 0.01 的稀疏目标。我们将衰减率表示为λ，它指的是估计的稀疏度值。这应该不高于 0.99，但高于 0.9。如果我们计算的概率是围绕目标值聚集的，我们应该减少稀疏性成本，对这种建模的一般建议是在收集随机样本时收集平均活动的直方图。

### 隐藏单元的数量和类型

通常，主要的考虑是我们寻求避免过度拟合。因此，我们通常会尝试使用更少的隐藏单元，而不是更多。特别是，如果观察到的数据非常相似，我们也应该尝试使用更少而不是更多的隐藏单元。然而，如果我们试图实现的稀疏目标恰好落在一个非常小的范围内(或者本身非常小)，那么使用比正常情况更多的隐藏单元是合理的。至于单位的类型，我们可以使用高斯可见(和/或隐藏)的，除了 sigmoid 和 softmax 之外的单位分别用下面表示:

![$$ E\left( v, h\right) = {\displaystyle \sum_{i\in v}}\frac{{\left({v}_i-{a}_i\right)}^2}{2{\sigma}_i^2} - {\displaystyle \sum_{j\in h}}{b}_j{h}_j - {\displaystyle \sum_{i, j}}\frac{v_i}{\sigma_i}{h}_j{w}_{i, j}, $$](img/A435493_1_En_7_Chapter_Equah.gif)

![$$ E\left( v, h\right)={\displaystyle \sum_{i\in v}}\frac{{\left({v}_i-{a}_i\right)}^2}{2{\sigma}_i^2} + {\displaystyle \sum_{j\in h}}\frac{{\left({h}_j-{b}_j\right)}^2}{2{\sigma}_j^2} - {\displaystyle \sum_{i, j}}\frac{v_i}{\sigma_i}{h}_j{w}_{i, j}, $$](img/A435493_1_En_7_Chapter_Equai.gif)

![$$ p=\frac{1}{1+{e}^{- x}} $$](img/A435493_1_En_7_Chapter_Equaj.gif)

![$$ {p}_j=\frac{e^{x_j}}{\varSigma_{i=1}^K{e}^{x_i}}. $$](img/A435493_1_En_7_Chapter_Equak.gif)

## 深度信念网络

我要介绍的最后一个模型是深度信念网络(DBN)，如图 [7-3](#Fig3) 所示，这是 Geoffrey Hinton 的另一项创新。为了制造 DBN，我们将受限的玻尔兹曼机器堆叠在一起，一次训练一层。通常，我们将 DBNs 用于无监督学习问题。

![A435493_1_En_7_Fig3_HTML.jpg](img/A435493_1_En_7_Fig3_HTML.jpg)

图 7-3。

Visualization of a deep belief network

在 2006 年的一篇论文中，多伦多大学的研究员 Geoffrey Hinton 和 Simon Osindero 描述了一种用于快速学习的算法。具有许多隐藏层的训练网络所带来的困难启发了混合模型的创建。与训练问题相关，该模型的主要吸引力在于，通过设计，存在互补的先验，这允许我们容易地从条件概率分布中提取。这是通过从网络深层的随机配置开始实现的。然后，我们遍历网络的每一层，其中给定层的状态由伯努利试验确定。伯努利函数的参数是从初始“自上而下”传递中的前一层接收的输入中导出的。

## 快速学习算法(Hinton 和 Osindero 2006)

通过在给定的层中取一个随机状态并对其执行 Gibbs 抽样，从 RBM 中生成数据。简而言之，Gibbs 抽样是一种蒙特卡罗方法，在这种方法中，我们试图根据用户指定的概率分布获得一个序列，但该算法试图近似这个序列。通常，分布是多元的。所选层内的所有单元以并行方式更新，并且重复这一过程，直到我们决定从平衡分布中进行采样。在图 [7-4](#Fig4) 中，我们可以看到 RBM 的可见层和隐藏层。

![A435493_1_En_7_Fig4_HTML.jpg](img/A435493_1_En_7_Fig4_HTML.jpg)

图 7-4。

Visualization of restricted Boltzmann machine

每个权重使用一个可见单元 I 和一个隐藏单元 j。当数据向量被“钳制”在可见单元上时，隐藏单元从它们的条件分布中被采样，这是阶乘。对数概率的梯度由下面给出:

![$$ \frac{\partial \log p\left({\boldsymbol{v}}^0\right)}{\partial {w}_{i, j}} = \left\langle {v}_i^0{h}_j^0\right\rangle - \left\langle {v}_i^{\infty }{h}_j^{\infty}\right\rangle $$](img/A435493_1_En_7_Chapter_Equal.gif)

当我们最小化 KL 散度时，我们实际上最大化了对数概率。如果你想学习复杂的模型，把单一的模型分解成更小、更简单的模型。过了这一点，就可以依次学习这些模型了。如第 [3](03.html) 章所述，这种顺序学习的一个例子是梯度推进。基于更高层导出 W <sub>0</sub> 的互补先验的假设，学习 W <sub>0</sub> 的合理近似。在实践中，我们可以通过假设所有权重矩阵必须彼此相等来实现这个结果。当解决这个约束优化问题时，学习变得比以前容易得多，并且问题本身被简化为学习一个 RBM，于是通过最小化对比差异来获得好的近似解。

### 算法步骤

1.  假设所有权重矩阵都是并列的，学习 W <sub>0</sub> 。
2.  使用 W <sub>0</sub> <sup>T</sup> 来推断第一个隐藏层中变量状态的阶乘近似后验分布。
3.  学习一个关于 W <sub>0</sub> <sup>T</sup> 生成的数据的高层抽象的 RBM 模型。
4.  重复直到收敛到最优解。

如果模型中较高层次的权重矩阵发生变化，我们肯定会看到模型的改进。如果![$$ Q\left(.\Big|{\mathbf{v}}^0\right) $$](img/A435493_1_En_7_Chapter_IEq18.gif)是数据的真实后验值，则给定的界限变成等式。Hinton 特别提出了一种贪婪的学习方法，如 Neal 和 Hinton (1998)所述。给定构型 v <sup>0</sup> ，h <sup>0</sup> 的能量定义为

![$$ E\left({\boldsymbol{v}}^0,{\boldsymbol{h}}^0\right) = -\left[ \log p\left({\boldsymbol{h}}^0\right)+ \log p\left({\boldsymbol{v}}^0\Big|{\boldsymbol{h}}^0\right)\right], $$](img/A435493_1_En_7_Chapter_Equam.gif)

![$$ \log p\left({\boldsymbol{v}}^0\right)\ge\ {\displaystyle \sum_{\boldsymbol{all}\ {h}^0}} Q\left({\boldsymbol{h}}^0\Big|{\boldsymbol{v}}^0\right)\left[ \log p\left({\boldsymbol{h}}^0\right)+ log\left({\boldsymbol{v}}^0\Big|{\boldsymbol{h}}^0\right)\right]-{\displaystyle \sum_{\boldsymbol{all}\ {h}^0}} Q\left({\boldsymbol{h}}^0\Big|{\boldsymbol{v}}^0\right) \log Q\left({\boldsymbol{h}}^0\Big|{\boldsymbol{v}}^0\right) $$](img/A435493_1_En_7_Chapter_Equan.gif)

同一个界

其中 h <sup>0</sup> =初始隐藏层单元的二进制配置，p(h <sup>0</sup> ) =当前模型的先验 h <sup>0</sup> ，以及![$$ Q\left(.\Big|{\mathbf{v}}^0\right) $$](img/A435493_1_En_7_Chapter_IEq19.gif) =初始隐藏层的二进制配置的概率分布。

## 摘要

这就结束了对自动编码器、RBM 和 dbn 的讨论。这也结束了所有关于深度学习模型的章节。既然我们已经讨论了这些模型，现在是时候将我们的注意力转向实验设计和特征选择技术，以帮助您提高机器学习模型的准确性。