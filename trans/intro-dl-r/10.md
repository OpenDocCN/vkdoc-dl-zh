# 10.机器学习示例问题

在这一章中，我们将开始把目前讨论的技术应用到你可能面临的实际问题中。所提供的数据集将从随机数据中生成，或将来自 [`https://github.com/TawehBeysolowII/AnIntroductionToDeepLearning`](https://github.com/TawehBeysolowII/AnIntroductionToDeepLearning) 。请注意，您还可以参考前面章节中给出的示例中提供的所有代码和数据集的 URL。

在这一章中，我们将专门研究机器学习问题。虽然我不能涵盖所有可能的领域和问题类型，但是这里的例子将重点解决用户可能遇到的常见场景。

我鼓励您将这些最后的示例章节视为如何从数据集(原始或处理过的)到解决方案的教程。虽然这些例子是可行的解决方案，但最重要的方面是应用我们已经讨论过的实验设计、特性选择和模型评估方法来有效地解决问题。

## 问题 1:资产价格预测

量化金融是一个不断将数据科学和机器学习技术融入其方法的领域，特别是在自动化交易和市场研究的过程中。虽然数量金融学本身是一个具有丰富多样性和自身技术的领域，但我们可以应用许多宽泛的分析和数学概念。对于这个例子，我们将使用 quantmod 包来下载金融数据，我将带您了解如何预测资产价格。我还将简要解释如何创建交易策略——特别是统计套利策略。和往常一样，强烈建议在应用这些技术之前对这些结果进行回溯测试。本章的目的是提供对机器学习的学术理解——它不打算作为量化投资组合管理的教程！

让我们假设你是一家资产管理公司的定量分析师，你的任务是合理预测一项标准普尔 500 资产的回报。你的董事总经理认为，还有十只股票有助于模拟这种特殊资产的表现，你应该在分析中使用它们。除了建议使用机器学习方法来解决这个问题之外，导演没有给出具体的使用方法。

让我们从定义问题开始。

### 问题类型:监督学习—回归

我们试图预测离散或连续值的任何问题都被称为回归问题。因为我们已经有了答案，并且我们正在尝试将我们提出的答案与实际答案进行比较，这是一个监督学习问题。具体来说，我们将尝试根据其他资产 x 的回报来预测一项资产 y 的回报。让我们开始构建管道来解决这个问题。

通常，使用雅虎！或者建议使用 Google Finance API 来完成这些任务。对于那些特别关注机器学习在定量金融中的应用的人，请注意雅虎！《金融》杂志的数据有生存偏见，也就是说，任何已经倒闭的公司都不能再访问他们的数据。因此，因任何原因被除名的公司不再存储在数据库中。这就产生了一个问题，因为使用这些数据的所有策略都不会反映出最糟糕的情况，例如，有人在金融危机期间交易了雷曼兄弟(Lehman Brothers)的贝尔斯登(Bear Sterns)等证券。但是，可以找到保存破产或不再上市的公司数据的数据库(Norgate Data 就是一个例子)。

我们将从使用 Google Finance API 加载数据开始，但是将使用 quantmod 包来完成。对于任何需要访问股票数据的工作，都推荐使用这个软件包，比如获取各种金融工具的每日、每月或每季度的价格，以及从上市公司获取财务报表数据。

让我们开始浏览代码:

```py
#Clear the workspace (1)
rm(list = ls())

#Upload the necessary packages (2)
require(quantmod)
require(MASS)
require(LiblineaR)
require(rpart)
require(mlbench)
require(caret)
require(lmridge)
require(e1071)
require(Metrics)
require(h2o)
require(class)
#Please access github to see the rest of the required packages!

#Summary Statistics Function
#We will use this later to evaluate our model performance (3)
summaryStatistics <- function(array){
  Mean <- mean(array)
  Std <- sd(array)
  Min <- min(array)
  Max <- max(array)
  Range <- Max - Min
  output <- data.frame("Mean" = Mean, "Std Dev" = Std, "Min" =  Min,"Max" = Max, "Range" = Range)
  return(output)
}

```

在前面的代码中，和使用 R 时一样，在进行新的实验时，清空工作空间(1)很重要。然后我们加载所需的包(2)。定义的下一个函数给出了我们正在分析的数组的汇总统计数据(3)。在本例中，我们将只关注 MSE。这是为了提供一个如何评估机器学习模型的简单示例。

我经常采用两种方法:

*   在默认模式下评估几个模型，然后对最佳模型执行参数调整。
*   一次调整一个参数，然后对调整后的模型进行评估。

在这里，我将执行后者，尽管出于简单和解释的目的，没有那么深入。

### 实验描述

我们将创建一个通用管道来解决这个问题，描述如下:

数据摄取→特征选择→模型训练和评估→模型选择

具体来说，在这个问题中，我们将尝试根据我们怀疑准确描述这些回报的股票(市场指数和其他股票的混合)的回报来预测福特公司(股票代码为 F)的回报。我们的股票投资组合的选择本身就是一项研究，但在这种情况下，我们选择了与汽车市场相关的股票(宏观指标和与能源行业相关的指标)。这里的假设是，跟踪福特表现的股票很可能是同一行业的公司，或者是以某种方式服务于汽车市场的相关行业的公司，或者是对整体经济有更大影响的公司。

请注意，除了正确理解如何创建机器学习模型所需的数学知识之外，还有必要为这些模型提供有用的数据。如果我们使用与正在解决的问题完全不相关的特征，我们将很难从拟合的模型中得到任何有用的结果。因此，在我们对算法进行任何微调之前，我们为创建数据集而做出的这些假设将有助于产生更好的结果:

```py
#Loading Data From Yahoo Finance (4)
stocks <- c("F", "SPY", "DJIA", "HAL", "MSFT", "SWN", "SJM", "SLG", "STJ")
stockData  <- list()
for(i in stocks){
  stockData[[i]] <- getSymbols(i, src = 'google', auto.assign = FALSE, from = "2013-01-01", to = "2017-01-01")
}

#Creating Matrix of close prices
df  <- matrix(nrow = nrow(stockData[[1]]), ncol = length(stockData))
for (i in 1:length(stockData)){
  df[,i]  <- stockData[[i]][,4]
}
#Calculating Returns
return_df  <- matrix(nrow = nrow(df), ncol = ncol(df))
for (j in 1:ncol(return_df)){
  for(i in 1:nrow(return_df) - 1){
    return_df[i,j]  <- (df[i+1, j]/df[i,j]) - 1
  }
}

```

在前面的代码中，我们从 Yahoo！金融(4)。除非在初次下载后保存了这些数据，否则您应该有一个活动的互联网连接，否则这部分代码将无法正常执行。在计算给定股票的回报时，您可以将回报视为衍生产品，但基于回报的价格的更简单公式如下:

![$$ Adjusted\kern0.5em Close{R}_{x_t}=\left(\frac{P_{x_t+1}}{P_{x_t}}\right)-1 $$](../Images/A435493_1_En_10_Chapter_Equa.gif)

(一)

其中 x =股票 x，y =股票 y，t =时间段(1，2，… n)，

n =观察次数，![$$ {P}_{x_t} $$](../Images/A435493_1_En_10_Chapter_IEq1.gif)= t 期间股票 x 的价格

为了这个实验的目的，同样在量化金融的许多这样的情况下，我们根据调整后的收盘价计算回报(等式 A)。我们将这些调整后的收盘价称为收盘价，因为它们反映了由于股息、股票分割或其他与股票表现或市场条件无关的财务调整而导致的基础股票价格随时间的任何变化。在这里，我们将查看每日收益。时间频率的选择完全由用户决定，并取决于被评估的策略。一般来说，高频交易在一天内发生多次，低频交易发生的增量明显长于一天。

我们组织数据，使得每一列代表给定股票的收益，每一行代表给定一天的收益。图 [10-1](#Fig1) 显示了数据集的头部。

![A435493_1_En_10_Fig1_HTML.jpg](../Images/A435493_1_En_10_Fig1_HTML.jpg)

图 10-1。

Head of stock return data set

股票回报通常与机器学习算法配合得很好，因为它们都以类似的方式进行缩放，并表示与给定股票内的所有观察结果以及可用于分析的股票范围相关的度量。

### 特征选择

在处理时间序列数据时，我们经常会遇到多重共线性。因此，PCA 是用于特征选择的公平方法。我们这样做是因为除了变量之间的线性相关性很高这一事实之外，可能还有不需要评估的特征，因此不需要评估噪声。因此，根据特征贡献的方差来评价特征是合理的。下面显示了执行 PCA 的代码:

```py
#Feature Selection
#Removing last row since it is an NA VALUE
return_df  <- return_df[-nrow(return_df), ]
#Making DataFrame with all values except label IE all columns except for Ford since we are trying to predict this
#Determing Which Variables Are Unnecessary
pca_df  <- return_df[, -1]
pca  <- prcomp(scale(pca_df))
cor(return_df[, -1])
summary(pca)

```

当执行前面的代码时，我们会收到如图 [10-2](#Fig2) 和 [10-3](#Fig3) 所示的结果。

![A435493_1_En_10_Fig3_HTML.jpg](../Images/A435493_1_En_10_Fig3_HTML.jpg)

图 10-3。

Summary of principal components analysis (PCA) on data set

![A435493_1_En_10_Fig2_HTML.jpg](../Images/A435493_1_En_10_Fig2_HTML.jpg)

图 10-2。

Correlation matrix for entire data set

在图 [10-3](#Fig3) 的第 2 行，你可以看到每个主成分对数据集贡献的方差的比例。为了清楚起见，必须声明主成分不代表数据集中的特征。也就是说，我们可以认为主成分 1 是特征 1 到 8 的组合，PC 2 是特征 2 到 8 的组合，等等。一般的经验法则是将对总方差贡献 1%或更少的主成分视为无关紧要的主成分。当将其转化为数据集时，我们将删除数据集中的特征 8。这种相同的分析模式应该进行外推，但只有当观察到特征之间的线性相关性时。回到图 [10-1](#Fig1) ，你可以看到这些特征之间通常存在中度到强烈的线性相关性，这表明主成分分析确实是特征的一个合适选择。

## 模型评估

既然我们已经预处理了数据，让我们考虑我们的算法选择。在本例中，我们将评估几个不同的选择，并评估所有选择的 MSE。选择的型号数量完全由您决定，但是对于这个实际的例子，我将选择两个。此外，如果您选择评估 MSE 之外的统计数据，例如 R 的平方，则评估这些与实验目标相关的度量是合理的。也就是说，MSE 应该是回归模型中最小化的主要目标，也应该是所有其他评估方法中的主要关注点。

### 里脊回归

让我们选择第一个模型:岭回归。这里，我们将根据调整参数的值来评估 MSE。在下面的代码中，我们从从正态分布(5)中随机采样值开始。这些值将用于选择调整参数的大小，我们用 k 表示。这背后的直觉是，我们将从最低到最高对这些值进行排序，然后随着调整参数的增加，通过可视化误差来比较岭回归模型的 MSEs 性能:

```py
#Ridge Regression
k <- sort(rnorm(100))(5)

```

在下面的代码中，我们开始交叉验证我们的结果，以便我们评估模型性能的一般性，而不是在完全相同的数据集上测试我们的算法(6)。我们选择使用大小相等的训练和测试集，将数据分成两半:

```py
mse_ridge <- c()
for (j in 1:length(k)){ (6)
    valid_rows <- sample(1:(nrow(return_df)/2))
    valid_set <- new_returns[valid_rows, -1]
    valid_y <- new_returns[valid_rows, 1]
#Ridge Regression (7)
    ridgeReg <- lmridge(valid_y ∼ valid_set[,1] + valid_set[,2] + valid_set[,3] + valid_set[,4]
                             + valid_set[,5] + valid_set[,6], data = as.data.frame(valid_set), type = type,  K = k[j])
    mse_ridge <- append(rstats1.lmridge(ridgeReg)$mse, mse_ridge)
}

```

然后，我们使用`lmridge()`函数将数据拟合到岭回归模型，然后将 MSE 附加到名为`mse_ridge` (7)的向量。

当执行以下代码时，我们看到如图 [10-4](#Fig4) 所示的结果:

![A435493_1_En_10_Fig4_HTML.jpg](../Images/A435493_1_En_10_Fig4_HTML.jpg)

图 10-4。

MSE over tuning parameter size

```py
#Plots of MSE and R2 as Tuning Parameter Grows
plot(k, mse_ridge, main = "MSE over Tuning Parameter Size", xlab = "K", ylab = "MSE", type = "l",
     col = "cadetblue")

```

当查看该图时，我们看到当我们的调整参数 K 最接近所显示范围的上限和下限时，该模型表现最佳。具体来说，我们将选择创建一个调整参数值为 1 的拟合模型，因为这个 K 值会产生较低的 MSE。评估模型时，在访谈、实验和个人评估中，使用图来查看模型在某些参数值变化时的性能是很重要的。这对你和其他使用/评估你的代码的人都很有用。这将有助于引导人们了解你的思维过程，而情节往往比看终端代码的数字输出更有吸引力。

在我们对验证集之外的数据测试我们的拟合模型之前，让我们看看如何调整另一个算法:支持向量回归(SVR)。

### 支持向量回归机

这里要调整的主要参数是`kernel`函数，它决定了超平面的形状，因此也决定了回归线的形状。当我们执行下面的代码时，我们得到如图 [10-5](#Fig5) 所示的图:

![A435493_1_En_10_Fig5_HTML.jpg](../Images/A435493_1_En_10_Fig5_HTML.jpg)

图 10-5。

SVR MSE with respect to kernel selection

```py
#Kernel Selection
svr_mse <- c()
k <- c("linear", "polynomial", "sigmoid")
for (i in 1:length(k)){
  valid_rows <- sample(1:(nrow(return_df)/2))
  valid_set <- new_returns[valid_rows, -1]
  valid_y <- new_returns[valid_rows, 1]

  SVR <- svm(valid_y ∼ valid_set[,1] + valid_set[,2] + valid_set[,3] + valid_set[,4]
             + valid_set[,5] + valid_set[,6], kernel = k[i])
  svr_y <- predict(SVR, data = valid_set)
  svr_mse <- append(mse(valid_y, svr_y), svr_mse)
}

#Plots of MSE and R2 as Tuning Parameter Grows
plot(svr_mse, main = "MSE over Tuning Parameter Size", xlab = "K", ylab = "MSE", type = "l",
       col = "cadetblue")

```

在评估输出时，我们注意到图 [10-5](#Fig5) 中的以下 MSE 值。多项式核产生最小的 MSE，因此是我们的选择。现在，我们已经训练了两个模型，我们将使用调整后的模型对样本外进行预测。在实际设置中，您可能需要安装两个以上的模型并评估性能。因为这个过程是详尽的，为了便于解释，我将这个例子浓缩为比较两个模型。无论如何，让我们来看看我们调整后的模型的性能:

```py
#Predicting out of Sample with Tuned Models
#Tuned Ridge Regression
ridgeReg <- lmridge(valid_y ∼ valid_set[,1] + valid_set[,2] + valid_set[,3] + valid_set[,4]
                    + valid_set[,5] + valid_set[,6], data = as.data.frame(valid_set), type = type,  K = 1)

y_h <- predict(ridgeReg, as.data.frame(new_returns[-valid_rows, -1]))
mse_ridge <- mse(new_returns[-valid_rows, 1], y_h)

#Tuned Support Vector Regression
svr <-   SVR <- svm(valid_y ∼ valid_set[,1] + valid_set[,2] + valid_set[,3] + valid_set[,4]
                    + valid_set[,5] + valid_set[,6], kernel = "polynomial")
svr_y <- predict(svr, data = new_returns[-valid_rows, -1])
svr_mse <- mse(new_returns[-valid_rows, 1], svr_y)

#Tail of Predicted Value DataFrames
svr_pred <- cbind(new_returns[-valid_rows, 1], svr_y)
colnames(svr_pred) <- c("Actual", "Predicted")
tail(svr_pred)
ridge_pred <- cbind(new_returns[-valid_rows, 1], y_h)
colnames(ridge_pred) <- c("Actual", "Predicted")
tail(ridge_pred)

```

前面的代码使用了我们训练的回归模型，只是我们根据产生最低 MSE 的值来设置参数值。尽管我们将模型与训练数据相匹配，但我们是在测试数据上进行预测。这表现在我们使用所有我们没有训练模型的观察值从返回数据帧中进行索引。当对测试数据集进行预测时，图 [10-6](#Fig6) 和 [10-7](#Fig7) 显示了每个算法的实际股票值与预测股票值的对比。

![A435493_1_En_10_Fig7_HTML.jpg](../Images/A435493_1_En_10_Fig7_HTML.jpg)

图 10-7。

Tail of actual versus predicted data frame (ridge regression)

![A435493_1_En_10_Fig6_HTML.jpg](../Images/A435493_1_En_10_Fig6_HTML.jpg)

图 10-6。

Tail of actual versus predicted data frame (SVR)

当评估这些算法的 MSE 时，我们得到以下结果:

*   支持向量回归的 MSE:0.0002967161
*   岭回归的 MSE:0.002632815

基于这些结果，有理由说我们应该选择岭回归而不是基于更好的 MSE 的 SVR。在评估一个解决方案时，除了完全不同的算法之外，您应该可以自由地研究给出的示例，并使用不同的特性选择算法。这一节的目的，同样是提供我通常如何处理这些问题的见解，以便您可以开始开发自己的方法。尽管模型选择和调优有一些通用的指导原则，但是每个人都可以按照自己的方式自由地执行。

现在让我们来看一个分类问题。

### 问题 2:速配

在快速约会中，参与者会见许多人，每个人几分钟，然后决定他们希望再次见到谁。我们将使用的数据集包含了对研究生和专业学生进行的快速约会实验的信息。实验中的每个人与 10-20 个随机选择的异性(只有异性配对)见面，每个人四分钟。每次快速约会后，每个参与者都要填写一份关于对方的问卷。我们的目标是建立一个模型来预测哪对约会者希望再次见面(即有第二次约会)。

### 问题类型:分类

我们试图确定二元或有限多项式结果的任何问题都可以被认为是分类问题。在这种情况下，这将是一个监督问题，因为我们事先知道数据的标签，但我们需要通过特定于该数据集的确定性规则来计算它们。第二次约会只有在特定配对中的两个人都决定他们想再次见到对方的情况下才会计划。因此，我们将在数据集的预处理阶段创建该列:

```py
#Upload Necessary Packages
require(ggplot2)
require(lattice)
require(nnet)
require(pROC)
require(ROCR)

#Clear the workspace
rm(list = ls())

#Upload the necessary data
data  <- read.csv("/Users/tawehbeysolow/Desktop/projectportfolio/SpeedDating.csv", header = TRUE, stringsAsFactors = TRUE)

#Creating response label
second_date  <- matrix(nrow = nrow(data), ncol = 1)

for (i in 1:nrow(data)){
  if (data[i,1] + data[i,2] == 2){
    second_date[i]  <- 1
  } else {
    second_date[i]  <- 0
  }
}

```

和往常一样，我们通过加载必要的包和清理工作区来开始实验。然后，我们加载数据并创建一个名为 second_date 的响应标签。

现在我们已经完成了一些初步的预处理，让我们来描述和探索我们的数据集。该数据集中的特征如下，从第一列到最后一列:

*   Second_Date:二进制数据集的响应变量 y。1 =是(您想再次看到日期)，0 =否(您不想再次看到日期)。
*   决定:由性别隔离的个人做出的决定，关于他们是否愿意进行第二次约会。1 =是(您想再次看到日期)，0 =否(您不想再次看到日期)。
*   喜欢:总的来说，你有多喜欢这个人？(1 =完全不喜欢，10 =喜欢很多)。
*   PartnerYes:你认为这个人会答应你的可能性有多大？(1 =不太可能，10 =极有可能)。
*   年龄:年龄。
*   种族:白种人、亚洲人、黑人、拉丁美洲人或其他人种。
*   有吸引力:用 1-10 的标准给伴侣的吸引力打分(1 =糟糕，10 =很棒)。
*   真诚:给合作伙伴的销售诚意评分，1-10(1 =糟糕，10 =很好)。
*   有趣:用 1-10 分的标准评价伴侣的有趣程度(1 =糟糕，10 =很棒)。
*   雄心勃勃:用 1-10 的标准给伴侣的雄心壮志打分(1 =糟糕，10 =伟大)。
*   共同兴趣:用 1-10 分(1 =很糟糕，10 =很棒)来评价你和伴侣共同兴趣/爱好的程度。

### 预处理:数据清理和插补

注意，在这个数据集中有 NA 观察值。如前所述，我们有多种工具来处理这个问题，但重要的是我们要从算法上找到处理这个问题的方法。我们将在执行任何特性转换之前解决这个问题。以下代码显示了我们处理 NA 数据的过程:

```py
#Cleaning Data
#Finding NA Observations
lappend <- function (List, ...){
  List <- c(List, list(...))
  return(List)
}
na_index <- list()
for (i in 1:ncol(data)){
  na_index <- lappend(na_index, which(is.na(data[,i])))
}

```

首先，我们创建一个函数，让我们将向量附加到一个列表中，这样，对于每一列，我们都有一个指示 NA 观察位置的行向量。给定数据集的性质，在给定该列/特征中的数据的情况下，使用最合理的方法估算值是合乎逻辑的。请注意，Second_Date、DecisionM、DecisionF、RaceM 和 RaceF 列没有任何缺失数据。我们将处理确实存在缺失数据的要素。

我们将使用第 [3 章](03.html)中描述的期望最大化(EM)算法进行数据插补。这在`amelia`包中给出，可以从 R 端子安装。不过，在此之前，我们必须稍微准备一下我们的数据:

```py
#Imputing NA Values where they are missing using EM Algorithm
#Step 1: Label Encoding Factor Variables to prepare for input to EM Algorithm
data$RaceM <- as.numeric(data$RaceM)
data$RaceF <- as.numeric(data$RaceF)

#Step 2: Inputting data to EM Algorithm
data <-  amelia(x = data, m = 1,  boot.type = "none")$imputations$imp1

#Proof of EM Imputation
na_index <- list()
for (i in 1:ncol(data)){
  na_index <- lappend(na_index, which(is.na(data[,i])))
}
na_index <- matrix(na_index, ncol = length(na_index), nrow = 1)
print(na_index)

 #Scaling Age Features using Gaussian Normalization
data$AgeM <- scale(data$AgeM)
data$AgeF <- scale(data$AgeF)

```

EM 算法不能处理因子(分类变量)。这意味着我们必须在将这些因素输入算法之前对它们进行数字编码。在这之后，我们执行`amelia`函数，它执行我们想要的。接下来，我们通过索引任何 NA 值，然后打印此输出，提供该数据集中不再有 NA 数据的证据，产生如图 [10-8](#Fig8) 所示的结果。

![A435493_1_En_10_Fig8_HTML.jpg](../Images/A435493_1_En_10_Fig8_HTML.jpg)

图 10-8。

Displaying counts of NA values in cleaned data set

我们已经成功地移除了所有 NA 观测值，并将在继续进行特性选择之前执行最后一点预处理。让我们看看男性和女性的年龄分布。我们对此进行如下编码，并接收后续结果:

```py
#Scaling Age Features using Gaussian Normalization
summaryStatistics(data$AgeM)

Mean  Std.Dev Min Max Range
1 26.60727 3.509664  18  42    24

summaryStatistics(data$AgeF)

Mean  Std.Dev Min Max Range
1 26.24317 3.977411  19  55    36

#Making Histograms of Data
hist(data$AgeM, main = "Distribution of Age in Males", xlab = "Age", ylab = "Frequency", col = "darkorange3")
hist(data$AgeF, main = "Distribution of Age in Females", xlab = "Age", ylab = "Frequency", col = "firebrick1")
data$AgeM <- scale(data$AgeM)
data$AgeF <- scale(data$AgeF)

```

当使用`hist()`函数可视化数据的分布时，代码产生如图 [10-9](#Fig9) 和 [10-10](#Fig10) 所示的结果。

![A435493_1_En_10_Fig10_HTML.jpg](../Images/A435493_1_En_10_Fig10_HTML.jpg)

图 10-10。

Histogram of female ages

![A435493_1_En_10_Fig9_HTML.jpg](../Images/A435493_1_En_10_Fig9_HTML.jpg)

图 10-9。

Histogram of male ages

女性和男性年龄的分布呈正偏态，这意味着平均值小于中位数。然而，请注意，与男性年龄相比，女性年龄的差异明显较小。虽然这也可能是我们想要保留的观点，但是在探索数据集和解释信息显示的内容时，您应该了解显示图表的重要性。对于不太懂技术的人来说，这可能是展示信息的最有吸引力的方式之一。对于那些经常做报告的人来说，有效地利用情节是必须的。最后，我们通过对年龄变量执行高斯归一化来结束我们的数据清理和预处理，以便它们的输入不会影响我们的分类模型的准确性，因为它们与不是数字标签的每个其他变量处于不同的范围。

既然已经完成了所有必要的预处理，我们就可以着手特征选择的任务了。

## 特征选择

这个数据集没有异常大量的观察值，但 27 个单独的特征可能会造成过度杀伤，并将不必要地削弱我们的机器学习算法的预测能力。因此，我们消除不必要的特征是合理的，尽管我们应该注意这个过程不一定像看起来那样简单。

当查看相关矩阵时(该矩阵太大，无法在此显示)，我们注意到通常存在弱到中等的线性相关性。我们可能无法从任何严重依赖线性假设的模型中获得有效的结果。当把它与特征选择联系起来时，我们同样不可能从使用 PCA 中得到好的结果。因此，我选择使用随机森林来表示特征的重要性，基于它们对观察分类的影响程度:

```py
#Feature Selection
corr <- cor(data)

#Converting all Columns to Numeric prior to Input
for (i in 1:ncol(data)){
  data[,i] <- as.integer(data[,i])
}

#Random Forest Feature Selection Based on Importance of Classification
data$second_date <- as.factor(data$second_date)
featImport <- random.forest.importance(second_date ∼., data = data, importance.type = 1)
columns <- cutoff.k.percent(featImport, 0.4)
print(columns)

```

执行上述代码时，以下各列高于为重要性设置的阈值 0.4:

```py
[1] "DecisionF"  "DecisionM"          "AttractiveM"    "FunF"    "LikeM"
[6] "LikeF"      "SharedInterestsF"   "AttractiveF"    "PartnerYesM"

```

这些将是我们训练集中使用的特性，现在我们可以继续进行模型训练和评估。

## 模型训练和评估

既然我们已经有了一个充分简化和转换的数据集，那么是时候开始模型选择的过程了。因为决定分类的函数不是线性的，所以我们应该考虑可以处理这种类型数据的函数。在下一个问题中，我们将使用以下算法组合:

*   逻辑回归
*   贝叶斯分类器
*   k-最近邻

我们将单独调整每个算法的参数，评估训练集的性能，然后预测样本外。一旦我们对所有的算法都这样做了，我们将并排评估结果，然后选择最佳的算法。

### 方法 1:逻辑回归

有人建议，在评估投资组合分类算法时，你应该总是从逻辑回归开始。原因不在于期望这是最好的算法，而更多的是从这样一个观点来看，这形成了一个基线评估，从这个评估中你可以比较不同的分类算法。在本实验中，我们将评估模型在 AUC 分数方面的表现，AUC 分数是(ROC)曲线下的面积:

```py
#Method 1: Logistic Regression
lambda <- seq(.01, 1, .01)
AUC <- c()
for (i in 1:length(lambda)){
  rows <- sample(1:nrow(processedData), nrow(processedData)/2)
  logReg <- glm(as.factor(second_date[rows]) ∼., data = processedData[rows, ], family = binomial(link = "logit"), method = "glm.fit")
  y_h <- ifelse(logReg$fitted.values >= lambda[i], 1, 0)
  AUC <- append(roc(y_h, as.numeric(second_date[-rows]))$auc, AUC)
}

```

我们从改变阈值开始，该阈值决定了我们是基于 lambda 参数将观察分类为 1 还是 0。我们迭代该算法，并将基于该参数的 AUC 分数附加到 AUC 向量。在这个迭代循环之后，我们应该使用一个图来直观地评估性能。当绘制λ值的 AUC 得分向量时，我们编写以下代码，并观察图 [10-11](#Fig11) 中所示的输出:

![A435493_1_En_10_Fig11_HTML.jpg](../Images/A435493_1_En_10_Fig11_HTML.jpg)

图 10-11。

AUC over lambda value

```py
#Summary Statistics and Various Plots
plot(lambda[-1], AUC, main = "AUC over Lambda Value \n(Logistic Regression)",
     xlab = "Lambda", ylab = "AUC", type = "l", col = "cadetblue")

```

我们看到，当λ值为 0.15 时，AUC 得分最高，因此我们将使用该λ值。这是我建议你如何调整机器学习算法参数的一个例子。每个参数都应该单独调整，以便实现给定的目标，无论是最小化 MSE 还是最大化 AUC。在逻辑回归中，对数优势阈值实际上是我们需要调整的唯一参数。我们可以在测试集上通过多次迭代来查看优化模型的性能:

```py
#Tuned Model
AUC <- c()
for (i in 1:length(lambda)){
  rows <- sample(1:nrow(processedData), nrow(processedData)/2)
  logReg <- glm(as.factor(second_date[rows]) ∼., data = processedData[rows, ], family = binomial(link = "logit"), method = "glm.fit")
  y_h <- ifelse(logReg$fitted.values >= lambda[which(AUC == max(AUC))], 1, 0)
  AUC <- append(roc(y_h, as.numeric(second_date[-rows]))$auc, AUC)

}

#Summary Statistics and Various Plots
plot(AUC, main = "AUC over 100 Iterations \n(Naive Bayes Classifier)",
     xlab = "Iterations", ylab = "AUC", type = "l", col = "cadetblue")
hist(AUC, main = "Histogram for AUC \n(Naive Bayes Classifier)",
     xlab = "AUC Value", ylab = "Frequency", col = "firebrick3")

```

通过收集 AUC，我们遵循与调整机器学习算法时相同的直觉。逻辑回归的本质是在每次迭代时拟合模型，而不是像某些算法那样选择最佳回归解。当相对于一段时间内的迭代绘制 AUC 向量并绘制 AUC 向量的直方图时，我们观察到图 [10-12](#Fig12) 和 [10-13](#Fig13) 中所示的结果。

![A435493_1_En_10_Fig13_HTML.jpg](../Images/A435493_1_En_10_Fig13_HTML.jpg)

图 10-13。

Logistic regression AUC histogram over 100 iterations

![A435493_1_En_10_Fig12_HTML.jpg](../Images/A435493_1_En_10_Fig12_HTML.jpg)

图 10-12。

Logistic regression AUC over 100 iterations

在数值上，我们可以用下面的函数来总结这个向量:

```py
summaryStatistics(AUC)

Mean           Std.Dev       Min         Max         Range
1 0.5063276    0.04964798    0.3920711   0.6297832   0.2377121

```

我们将在前进的道路上牢记这些价值观。当按原样分析它们时，逻辑回归是一个不充分的分类器。通常，我们希望 AUC 分数至少为 0.70，因为 0.50 的分数表明模型只有 50%的正确率。小于 0 . 50 不是最佳的，这意味着我们应该认为这个分类器是不够的。

### 方法 3:K-最近邻(KNN)

这是一个相当简单的分类算法，在第 [3](03.html) 章中有详细描述。选择这种算法相对于另一种概率算法的目的是创建一个多样化的算法组合，以便我们可以推断出哪种类型的算法最适合这项任务。作为读者的注意事项，class 包中的 K-NN 算法从测试数据中产生分类。若要仅根据训练数据训练算法，请使用分配给“train”参数的相同数据:

```py
#Method 3: K-Nearest Neighbor
#Tuning K Parameter (Number of Neighbors)
K <- seq(1, 40, 1)
AUC <- c()
for (i in 1:length(K)){
  rows <- sample(1:nrow(processedData), nrow(processedData)/2)
  y_h <- knn(train = processedData[rows, ], test = processedData[rows,], cl = second_date[rows], k = K[i], use.all = TRUE)
  AUC <- append(roc(y_h, as.numeric(second_date[rows]))$auc, AUC)
}

#Summary Statistics and Various Plots
plot(AUC, main = "AUC over K Value \n(K Nearest Neighbor)",  xlab = "K", ylab = "AUC", type = "l", col = "cadetblue")

```

当查看 AUC 与 K 值的关系图时，我们可以看到图 [10-14](#Fig14) 所示的结果。

![A435493_1_En_10_Fig14_HTML.jpg](../Images/A435493_1_En_10_Fig14_HTML.jpg)

图 10-14。

KNN classifier AUC over 100 iterations

对于所有值，训练阶段的 AUC 分数通常令人印象深刻，但是选择比大 K 值低的 K 值以防止过度拟合是合理的。因此，我们将选择 K 为 3。让我们用我们调优的模型在测试集上观察 AUC 分数，如图 [10-15](#Fig15) 和 [10-16](#Fig16) 所示。

![A435493_1_En_10_Fig16_HTML.jpg](../Images/A435493_1_En_10_Fig16_HTML.jpg)

图 10-16。

KNN AUC over 100 iterations on test set histogram

![A435493_1_En_10_Fig15_HTML.jpg](../Images/A435493_1_En_10_Fig15_HTML.jpg)

图 10-15。

KNN AUC over 100 iterations on test set

在数字上，我们评估 AUC 向量如下:

```py
summaryStatistics(AUC)

Mean          Std.Dev       Min         Max        Range
1 0.445006    0.01126862    0.4257075   0.4663915  0.04068396

```

最后，我们预测出样本并观察到以下结果:

```py
#Predicting out of Sample
y_h <- knn(train = processedData[rows, ], test = processedData[-rows, ], cl = second_date[-rows])
roc(y_h, as.numeric(second_date[-rows]))$auc

```

曲线下面积:0.4638

除了测试集的性能客观上很差之外，我们还看到了从训练集到测试集的明显下降。

### 方法 2:贝叶斯分类器

我怀疑第二次约会的发生可以用贝叶斯估计器来建模，所以我们将开始的第一个模型是贝叶斯分类器。在下面的代码中，我们首先对数据集执行双重交叉验证，以便评估训练集的性能。在这个特定的模型中，只需要进行很少的调整，所以我们只需观察模型在 100 次迭代后的性能:

```py
#Method 1: Bayesian Classifier
AUC <- c()
for (i in 1:100){
  rows <- sample(1:nrow(processedData), 92)
  bayesClass <- naiveBayes(y = as.factor(second_date[rows]), x = processedData[rows, ], data = processedData)
  y_h <- predict(bayesClass, processedData[rows, ], type = c("class"))
  AUC <- append(roc(y_h, as.numeric(second_date[rows]))$auc, AUC)
}

#Summary Statistics and Various Plots
plot(AUC, main = "AUC over 100 Iterations \n(Naive Bayes Classifier)",
     xlab = "Iterations", ylab = "AUC", type = "l", col = "cadetblue")

hist(AUC, main = "Histogram for AUC \n(Naive Bayes Classifier)",
     xlab = "AUC Value", ylab = "Frequency", col = "cadetblue")

summaryStatistics(AUC)

```

当执行代码时，我们将 AUC 分数附加到向量 AUC，如前面循环 100 次迭代的代码所示。该矢量的线图和直方图如图 [10-17](#Fig17) 和 [10-18](#Fig18) 所示。

![A435493_1_En_10_Fig18_HTML.jpg](../Images/A435493_1_En_10_Fig18_HTML.jpg)

图 10-18。

Bayes classifier AUC histogram over 100 iterations

![A435493_1_En_10_Fig17_HTML.jpg](../Images/A435493_1_En_10_Fig17_HTML.jpg)

图 10-17。

Bayes classifier AUC performance over 100 iterations

我们观察到 AUC 分数在其分布中具有轻微的右偏，并且大多数 AUC 分数分布在彼此相对紧密的范围内。当查看原始数值数据时，我们观察到以下情况:

```py
Mean          Std.Dev       Min         Max         Range
1 0.8251087   0.03142345    0.7567568   0.9027778   0.146021

```

对于我们选择的模型而言，这些 AUC 分数超出了一般可接受的范围，尽管我们仍应评估样本外模型的性能，以确定该过程的稳定性:

```py
#Predicting out of Sample
y_h <- predict(bayesClass, processedData[-rows, ], type = c("class"))
roc(y_h, as.numeric(second_date[-rows]))$auc

```

执行以下代码后，我们观察到以下 AUC 得分:曲线下面积:0.8219。这在从训练集产生的数据的分布中是可接受的，该 AUC 分数趋向于数据的平均值。

在评估所选的解决方案时，我强烈建议选择贝叶斯分类器，因为它从训练到测试集都很稳定，并且 AUC 得分高于所有其他方法。在实际设置中，我们会使用样本数据的预测来帮助影响我们的决策过程。在专业背景下，这可能包括根据不同用户的交友档案向他们进行有针对性的营销或推荐。

## 摘要

现在你已经对我如何推荐应用我在前面章节中解释的概念有了一个简要而全面的了解。你还应该注意到，虽然我已经成功地使用这种通用过程/方法实现了机器学习算法，但这并不是训练/调整机器学习模型的唯一方式。尽管如此，我还是非常强调度量标准的使用，以及在调优不同参数时根据这些度量标准绘制模型的性能。第 [11](11.html) 章将看如何实现和使用各种深度学习模型的使用示例。