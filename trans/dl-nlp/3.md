# 3.展开递归神经网络

本章介绍了跨文本的上下文信息的使用。对于任何形式的文本工作，即演讲、文本和印刷，以及任何语言，为了理解其中提供的信息，我们试图捕捉和联系现在和过去的上下文，并旨在从中获得一些有意义的东西。这是因为文本的结构创造了一个句子内和跨句子的链接，就像思想一样，贯穿始终。

传统的神经网络缺乏从以前的事件中获取知识并将其传递给未来事件和相关预测的能力。在这一章中，我们将介绍一个神经网络家族，它可以帮助我们长时间地保存信息。

在深度学习中，所有问题一般分为两类:

*   固定拓扑结构:用于具有静态数据的图像，使用案例如图像分类
*   顺序数据:用于带有动态数据的文本/音频，在与文本生成和语音识别相关的任务中

使用卷积神经网络(CNN)解决了静态数据的大多数问题，并且通过递归神经网络(RNNs)，特别是通过长短期记忆(LSTM)方法处理了与序列数据相关的大多数问题。我们将在本章中详细讨论这两种类型的网络，并涵盖 rnn 的使用案例。

在正常的前馈网络中，在时间`t`要分类的输出不一定与已经分类的先前输出有任何关系。换句话说，先前分类的输出在下面的分类问题中不起任何作用。

但是这是不实际的，因为在很少的情况下，我们必须用以前的输出来预测新的输出。例如，在阅读一本书时，我们必须知道并记住章节中提到的上下文以及整本书讨论的内容。另一个主要的用例是对大部分文本的情感分析。对于所有这些问题，RNNs 已经被证明是非常有用的资源。

无线网络和 LSTM 网络可应用于各种领域，包括

*   查特斯
*   顺序模式识别
*   图像/手写检测
*   视频和音频分类
*   情感分析
*   金融中的时间序列建模

## 递归神经网络

递归神经网络非常有效，能够执行几乎任何类型的计算。rnn 有各种各样的用例集，可以实现一组多个更小的程序，每个程序独立绘制一幅单独的图片，所有程序并行学习，最终揭示所有这些小程序协作的复杂效果。

rnn 能够执行这样的操作有两个主要原因:

*   隐藏状态本质上是分布式的，存储了大量过去的信息并有效地传递下去。
*   通过非线性方法更新隐藏状态。

### 什么是复发？

递归是一个递归过程，在此过程中，每一步都会调用一个递归函数来对时态数据集进行建模。

什么是时态数据？依赖于先前数据单元的任何数据单元，尤其是顺序数据。例如，一家公司的股价取决于前几天/几周/几月/几年的股价，因此，对前几天或前几个步骤的依赖性很重要，从而使这类模型非常有用。

所以，下一次你看到任何类型的数据有时间模式时，试着使用本章后面部分讨论的模型类型，但是要预先警告:有大量的数据！

### 前馈神经网络和递归神经网络的区别

在正常的前馈网络中，数据被离散地馈送给它，而不考虑时间关系。这种类型的网络对于离散预测任务非常有用，因为要素在时间上并不相互依赖。这代表了神经网络的最简单形式，信号沿一个方向流动，即从输入到输出。

例如，如果我们获取三个月的股票价格数据，并试图根据这些数据预测下个月的价格，前馈网络将立即获取前三个月的数据，就好像数据之间没有相互依赖关系一样，但事实可能并非如此。

然而，递归神经网络将一次获取每个月的数据，就像时间序列模型一样。

![$$ x(t)=x\left(t-1\right)+ constant $$](A461351_1_En_3_Chapter_Equa.gif)T2】

这一概念的类似功能驱动 RNNs 首先对过去间隔(比如说 t1)的信息执行一些计算，并将其与对当前间隔数据(比如说 t)完成的计算一起使用，并将两者组合以产生下一间隔的结果。

快速浏览一下前馈神经网络和 RNNs 之间的差异，可以发现前馈神经网络仅基于当前输入做出决策，而 RNN 基于当前和先前的输入做出决策，并确保连接也跨隐藏层建立。

以下是前馈神经网络的主要限制:

*   不适用于序列、时间序列数据、视频流、股票数据等。
*   不要在建模中引入记忆因素

图 [3-1](#Fig1) 说明了一种类型的 RNN 和前馈神经网络之间的区别。

![A461351_1_En_3_Fig1_HTML.png](A461351_1_En_3_Fig1_HTML.png)

图 3-1

Structural differentiation between a sample RNN and feedforward neural network

### 递归神经网络基础

在介绍 RNNs 的基础知识和它在 NLP 中的应用之前，我们将快速介绍一个完整的 RNNs 用例。让我们考虑一个例子，其中 RNN 学会了求和运算符的工作方式，并试图复制它。

rnn 属于具有非常强大的序列建模功能的算法家族，在这里，我们将看到，如果给定一个二进制输入序列，该模型如何能够将数字相加，并以近乎完美的精度向我们提供总和作为输出。

给定一个长度为 20 的二进制字符串(只有 0 和 1 的字符串)，我们必须确定二进制字符串中 1 的计数。比如“01010010011011100110”有 11 个 1。因此，我们程序的输入将是一个包含 0 和 1 的长度为 20 的字符串，输出必须是一个介于 0 和 20 之间的数字，表示字符串中 1 的数量。

从普通编程的角度来看，这个任务似乎很容易，读者可能认为它类似于任何典型的“Hello World”问题。然而，如果我们从机器的角度来看，它是一个可以将数字相加的模型，一个采用顺序二进制输入进行求和的模型。这就是我们正在处理的事情！

让我们动手为 rnn 定义一些关键术语。在此之前，在执行任何深度学习模型时要记住的一件事是，作为输入输入到模型的张量的形状。当作为模型的输入时，张量可以是任何维度，3-D/4-D。我们可以把它想象成一个列表的列表。一开始理解起来有点复杂，但是我们将会看到如何将这个概念分解成更小更有意义的表示。

Note

[ [ [ ] ] ]是一个三维张量，具有三个分层放置的列表。

RNN 需要一个三维张量作为输入，它可以被完美地分解成图 [3-2](#Fig2) 所示的组件。

![A461351_1_En_3_Fig2_HTML.jpg](A461351_1_En_3_Fig2_HTML.jpg)

图 3-2

Component-wise detail of a 3-D tensor used as input for RNN Note

没有必要记住这些，当我们继续查看 rnn 的结构时，您将理解以这种方式考虑组件背后的原因。

在当前的问题中，我们采用 20 个时间步长，或长度为 20 的序列输入，并且每个时间步长用 1-D 表示，即，用 0 或 1 的值表示。根据手头的问题，输入时间步长可以是不同的维度。图 [3-3](#Fig3) 显示了我们将使用的模型的架构。

![A461351_1_En_3_Fig3_HTML.jpg](A461351_1_En_3_Fig3_HTML.jpg)

图 3-3

RNN model architecture to compute the number of 1s in a 20 length sequence of binary digits

在模型图中，我们可以看到，我们将每个二进制单元作为每个时间步长(即 20 个时间步长)的输入，并使它们通过一个隐藏层(在这种情况下是一个递归层)，并将最终层的输出作为正常分类多层感知器。

因此，张量流 RNN 的输入形式如下

```
List =   [ [ [0] [1] [1] [1] [0] [0] [1] [1] [0] [1] [1] [1] [0] [0] [1] [1] [0] [1] [1] [1] ],
         [ [0] [1] [1] [1] [0] [0] [1] [1] [0] [1] [1] [1] [0] [0] [1] [1] [0] [1] [1] [1] ] ,    
         ...., [ [0] [1] [1] [1] [0] [0] [1] [1] [0] [1] [1] [1] [0] [0] [1] [1] [0] [1] [1] [1] ]   ]

```

我们建议不要把重点放在实际的训练部分，因为一旦你理解了数据流过程，训练部分就变得更容易理解，你可以训练多个相关的模型。就这一次，不要把你的注意力从图中显示的隐藏的 RNN 层上转移开，试着得到模型输入的要点。

随着我们的深入，我们将考虑一个稍微复杂一点的例子，并尝试使用递归神经网络进行情感分类(NLP 领域中最基本的任务之一)。

### 自然语言处理和递归神经网络

从前面的理论和解释中，我们很容易猜测 rnn 是为顺序任务量身定制的，更适合这种问题陈述的是语言。从童年开始，我们人类的大脑就接受了特殊的训练，以适应任何语言的结构。让我们假设英语是大多数人最常用的语言。当我们说话和写作时，我们知道这种语言的普遍结构，因为我们从小就被教导这种语言，而且我们能够毫不费力地破译它。

我们应该通过使用语法来使用适当的语言，语法构成了语言的基本规则。传统上，NLP 任务极其困难，因为不同语言的语法非常庞大。

针对每种语言的约束的硬编码有其自身的缺点。没有人想在世界上不同语言中存在的成百上千的语法规则中寻找答案，也没有人想按照定制的业务需求进一步学习或编写代码。

将我们从所有这些麻烦中拯救出来的是深度学习，它的目标是学习所有语言的复杂局部结构公式，并使用这种学习来破解问题集中存在的复杂性。

所以，最后，我们让我们的宝贝深度学习模型，属于 RNN 类别，自己学习。我们一个字一个字地给它输入英语句子的序列，让它在一些监督标签上训练，比方说，情感分类的积极或消极，或者暂时对文本进行星级评定的 1，2，3，4，5。

让我们通过考虑一个 n 元语言模型的例子来理解这一点。这里，如果我们有四个前面的单词，4-gram，我们的模型具有通过使用来自这种四个单词的组合类型的出现的过去信息来预测最可能的第五个单词的能力。这种类型的模型在诸如 Google 搜索自动完成建议的问题中有直接的用例。

Note

用于谷歌搜索的实际模型不仅仅是任何 n 元语法的直接实现，而是更复杂模型的组合。

让我们通过考虑一个基本的例子来理解这个概念。假设我们有一个正常的英语句子:“萨钦是一个伟大的板球运动员。”然后，我们可以根据我们的深度学习模型采用的输入来表示这句话，如图 [3-4](#Fig4) 所示。

![A461351_1_En_3_Fig4_HTML.jpg](A461351_1_En_3_Fig4_HTML.jpg)

图 3-4

Inputting the “Sachin is a great” sentence into the model

在这里，最后一个词，板球运动员，可以从前面四个词的顺序来判断沙钦是一个伟大的。我们可以判断“萨钦是一个伟大的”——什么？一个答案可能是“板球运动员”，因为我们对这样一个问题和背景的思考已经被这样建模了。同样，在某些情况下，我们希望模型考虑过去的历史事件，并对未来事件做出预测。这些事件也可能与我们能够从文本中提取的信息有关。

前馈网络一次性将整个句子作为输入，而 RNN 则一个接一个地提取每个单词，然后对给定文本进行分类。前面的图表会使它更清楚。

RNN 以单词嵌入的形式接受输入，这已在第 [2](2.html) 章中介绍过，有两种不同类型的模型，CBOW 和 Skip-gram。

word2vec 模型旨在为每个单词初始化随机向量，进一步学习这些向量以获得有意义的向量，从而执行特定的任务。词向量可以由任何给定的维度构成，并且能够相应地封装信息。

### RNNs 机制

rnn 在不同的领域有创造性的应用，从音频和文本到图像，包括音乐生成、字符生成、机器翻译等。让我们尝试以一种对初学者更友好的方式来理解 RNNs 的功能过程，这样任何没有深度学习背景的人也可以理解它(图 [3-5](#Fig5) )。

我们将使用 NumPy 库进行向量乘法，并描述内部数学。这个阶跃函数在每个时间步长被调用，即递归。

![A461351_1_En_3_Fig5_HTML.png](A461351_1_En_3_Fig5_HTML.png)

图 3-5

Unrolled recurrent neural network

首先，定义 RNN 类:

```
class RNN:
  # ...
  def step(self, x):

    # Update the Hidden state
    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.U_xh, x))

    # Compute the Output vector
    o = np.dot(self.V_hy, self.h)
    return o

```

前面的伪代码指定了基本 RNN 的正向传递。函数`step`在 RNN 类的每个时间步被调用。这个 RNN 的参数是三个矩阵(`W_hh, U_xh, V_hy`)。

以下是来自前面伪码的每个权重矩阵的维数及其来自图 [3-5](#Fig5) 的等效实体:

*   在时间步长 t 输入 X <sub>t</sub>
*   S <sub>t</sub> 是时间步长 t 时的隐藏状态。它是网络的“记忆”,是根据先前的隐藏状态和当前步长的输入计算的。
*   U <sub>xh</sub> 是从输入(x)到隐藏层(h)的映射，因此，h `×`维度(x)，其中 x 的维度是每个时间步长输入的维度(1，在二进制求和的情况下)。请参考上图中的 U 矩阵。
*   W <sub>hh</sub> 在隐藏状态之间映射，因此，h `×` h。参考上图中的 W 矩阵。
*   V <sub>hy</sub> 从最终隐藏层映射到输出 y。因此，h x dimension (y)，其中 y 的维度是输出的维度(20，在之前考虑的二进制求和情况下)。请参考上图中的 V 矩阵。
*   o <sub>t</sub> 是步骤 t 的输出。例如，如果我们想预测一个句子中的下一个单词，它将是我们词汇中的概率向量。

隐藏状态`self.h`用零向量初始化。`np.tanh`函数实现了将激活压缩到范围(`-1, 1`)的非线性。

请简要注意这是如何工作的。在`tanh`函数内部有两个术语:第一个是基于先前的隐藏状态，第二个是基于当前的输入。在 NumPy 中，`np.dot`执行矩阵乘法。

这两个中间体与加法相互作用，然后被`tanh`函数挤压到新的状态向量中。为了从数学符号的角度来推断隐藏状态更新，我们可以将其重写如下:

![$$ {h}_t={f}_1\;\left({W}_{hh}\;*\;{h}_{t-1}+{U}_{xh}\;*\;{x}_t\right) $$](A461351_1_En_3_Chapter_Equb.gif)

其中 f <sub>1</sub> 通常被视为`tanh`或`sigmoid`，并按元素方式应用。

我们用随机数初始化 RNN 的矩阵，并且在训练阶段执行的大部分工作进入产生期望行为的理想矩阵的计算。这是用某种损失函数来衡量的，这种损失函数表达了我们对哪种输出`o`的偏好，我们希望看到哪种输出响应于我们的输入序列`x`。

我们可以用多种方式训练 RNN 模型。然而，不可知的任何具体方式，rnn 有一个非常特殊的问题，它面临的原因是，随着权重随着时间的传播，它们在前面的函数中递归地相乘，从而产生以下两种情况:

*   消失梯度:如果权重很小，后续值将不断变小，并趋于~0。
*   爆炸梯度:如果权重很大，最终值将接近无穷大。

这两个问题使得 RNNs 对时间步长或序列限制的数量非常敏感。我们可以通过考虑 RNN 的输出来更详细地理解这一点。RNN 网络的输出表示如下:

![$$ {h}_t={f}_2\;\left(U{x}_t+V{h}_{t-1}\right) $$](A461351_1_En_3_Chapter_Equc.gif)

其中 U 和 V 分别是连接输入和递归输出的权重矩阵，f <sub>2</sub> 是用于分类任务的 softmax，L2 范数(平方误差)用于回归任务。Softmax 在 h <sub>t</sub> 输出端。

然而，请注意，如果我们参考，比方说，我们的递归神经网络中的三个时间步长(在前面的部分中解释)，我们有以下:

![$$ {h}_t=\sigma\;\left(U{x}_t+V\;\left(\sigma\;\left(U{x}_{t-1}+V\left(\sigma \left(U{x}_{t-2}\right)\right)\right)\right)\right) $$](A461351_1_En_3_Chapter_Equd.gif)

从前面的等式中，我们可以推断，随着网络通过添加更复杂的层而变得更深，并且随着时间的传播，它将导致梯度消失或爆炸问题。

当输入值接近 0 或 1 时，会出现`sigmoid`函数的梯度问题。此时，梯度很小，趋于消失，如图 [3-6](#Fig6) 所示。

![A461351_1_En_3_Fig6_HTML.jpg](A461351_1_En_3_Fig6_HTML.jpg)

图 3-6

Logistic curve, at top, along with its first degree differentiation, below

图 [3-7](#Fig7) 说明了 RNN 中的消失梯度问题。

![A461351_1_En_3_Fig7_HTML.jpg](A461351_1_En_3_Fig7_HTML.jpg)

图 3-7

Example of vanishing gradient

如上图所示(h <sub>0</sub> ，h <sub>1</sub> ，h <sub>2</sub> ，h <sub>3</sub> ，均为隐藏状态)，在每个时间步，当我们运行反向传播算法时，梯度变得越来越小，当我们回到句子的开头时，梯度变得如此之小，以至于实际上无法对必须更新的参数产生显著影响。之所以会出现这种效应，是因为除非 d h<sub>t1</sub>/d h<sub>t</sub>恰好为 1，或者 d h<sub>t1</sub>/d h<sub>t</sub>= 1，否则它将倾向于减小或放大梯度 d l/d h <sub>t</sub> ，当这种减小或其放大重复进行时，它将对损耗的梯度产生指数效应。

为了解决这个问题，使用了一种称为长短期记忆(LSTM)网络和门控整流单元(GRUs)的特定类型的隐藏层。后者是特殊的门控细胞，旨在本质上处理这种情况。我们将在本章的后面部分简要介绍这些内容。

### 培训注册护士

RNNs 最值得注意的一点是，它们在训练方面非常灵活，可以在监督和非监督领域的广泛问题上表现出色。在进入正题之前，让我们先了解一下隐藏态(LSTM/GRU/s 形神经元)的深层秘密。

好奇的人可能会想知道隐藏状态到底是什么。它像一个正常的前馈网络吗？还是本质上更复杂？

前面问题的答案是，任何隐藏状态的数学表示与任何正常前馈网络的数学表示相同，并且对于任何静态/无状态维度，它确实表示输入的隐藏特征。

然而，正如我们看到的 RNNs 的特殊递归属性，在任何时间间隔步长的 RNNs 的隐藏状态中，它以压缩密集的方式表示所有先前时间步长的上下文表示。它也包含密集向量中的语义序列信息。

例如，在时间 t，H(t)的隐藏状态包含时间间隔 X(t-1)，X(t-2)，，的一些噪声和一些真实信息。。。，X(0)。

考虑到 RNN 训练，对于监督学习的任何问题，我们必须找到一个`Loss`函数，它有助于通过反向传播或梯度下降来更新随机初始化的权重。

Note

不熟悉反向传播实现的读者不应该太担心，因为像 TensorFlow 和 PyTorch 这样的现代库具有超快的自动微分过程，使这些任务变得容易得多。人们只需要定义网络架构和目标。然而，建议读者彻底了解反向传播技术，用神经网络进行更多的实验，因为这是任何神经网络训练的基础。

现在，让我们创建二进制序列求和的初始示例。以下是对网络如何运行和训练的逐步解释:

1.  将隐藏状态初始化为一个随机数向量(隐藏层的大小是我们设置的自由参数)。
2.  Feed the binary number, 0 or 1, at each sequence step. Hence, calculating and updating the hidden vector at each step according to the following equation:

    ![$$ H(t)= tanh\;\left(U\cdot X(t)+V\cdot H\left(t-1\right)\right) $$](A461351_1_En_3_Chapter_Eque.gif)

    where, ‘.’ represents the dot product between the two matrices, and H, X, U, V have the same references as before.  
3.  最后一个隐藏层(特别是在这种情况下)作为输出，并馈入另一个多层感知器(前馈网络)。

所以，基本上，最后一层是整个序列的表示，这最后一层(t 时刻的隐藏表示)是最重要的一层。然而，在更早的时间间隔{t-1，t-2，…，0}的其他隐藏状态也可以用于其他目的。

Note

与传统的反向传播不同，RNNs 有一种称为时间反向传播(BPTT)的特定算法。在 BPTT，在时间 t，层的梯度更新依赖于时间 t-1，t-2，…，0。因此，在其所有形式中，反向传播是通过连续的时间步骤完成的。然而，如果一个人理解 BPTT，很明显它只是正常反向传播的一个特例。

除了通过从最后一个隐藏层获取输出来进行训练之外，如果一个人具有好奇/直觉的头脑，他/她可能会想为什么我们没有获取所有的隐藏状态并将它们平均。的确，那是另一种手段。如果读者已经得出结论，那么很高兴知道他/她正在很好地掌握 RNNs！图 [3-8](#Fig8) 显示了利用模型输出的多种方式。

![A461351_1_En_3_Fig8_HTML.jpg](A461351_1_En_3_Fig8_HTML.jpg)

图 3-8

An RNN can be trained in multiple ways, as required. One can take output of just the last time step, or all the time steps, or take the average of all the time steps.

### RNN 隐藏状态的元意义

RNN 中的隐藏状态非常重要。除了作为矩阵乘法的数学输出之外，RNN 隐藏状态还保存了关于数据的一些关键信息，即，特别是顺序信息。RNN 的最后隐藏状态能够完成各种高度创造性的任务。例如，有一个非常直观的模型叫做序列对序列(seq-to-seq 或 seq2seq)模型。这些模型用于机器翻译、图像字幕等。我们将在接下来的章节中简要概述它是如何工作的，但是编码和其他相关的细节已经超出了本书的范围。

假设我们有一个英语句子，我们想使用 seq2seq 模型将它自动转换/翻译成法语。直觉上，我们向 RNN 模型输入一个单词序列，一个英语句子，并且只考虑最后的隐藏输出。这个隐藏的输出似乎存储了句子最相关的信息。接下来，我们使用这个隐藏状态来初始化另一个将进行转换的 RNN。就这么简单，对吧？

### 调谐 rnn

rnn 对输入变量非常关键，本质上非常容易接受。在训练过程中起主要作用的 RNNs 中的一些重要参数包括:

*   隐藏层数
*   每层隐藏单元的数量(通常选择每层相同的数量)
*   优化器的学习速率
*   退出率(RNNs 中最初成功的退出仅适用于前馈连接，不适用于循环连接)
*   迭代次数

通常，我们可以用验证曲线和学习曲线来绘制输出，并检查过度拟合和欠拟合。训练和测试在每次分裂时的误差应该被绘制出来，根据我们检查的问题，如果它是一个过拟合，那么我们可以减少隐藏层或隐藏神经元的数量，或者增加辍学率，或者增加辍学率，反之亦然。

然而，除了这些考虑之外，另一个主要问题是权重，我们在 TensorFlow 库中有权重/梯度裁剪和多个初始化函数。

### 长短期记忆网络

LSTM 网络由 Sepp Hochreiter 和 J `ü` rgen Schmidhuber 于 1997 年首次提出，解决了 rnn 在更长时间内( [`www.bioinf.jku.at/publications/older/2604.pdf`](http://www.bioinf.jku.at/publications/older/2604.pdf) )保留信息的问题。

已经证明 RNNs 是处理与序列分类相关的问题的唯一选择，并且已经证明它们适合于保留来自先前输入数据的信息，并且使用该信息在任何时间步骤修改输出。然而，如果序列的长度足够长，则在 RNN 模型的训练过程中计算的梯度，特别是反向传播，或者由于 0 和 1 之间的值的累积乘法效应而消失，或者再次由于大值的累积乘法而爆炸，从而导致模型以相对较慢的方式训练。

LSTM 网络是这里的救星。正是这种类型的 RNN 体系结构有助于在冗长的序列中训练模型，并有助于保持输入到模型的先前时间步骤的记忆。理想情况下，它通过引入额外的门、输入和遗忘门来解决梯度消失或梯度爆炸问题，从而允许更好地控制梯度，允许保留什么信息和遗忘什么信息，从而控制信息对当前单元状态的访问，这使得能够更好地保持“长期依赖性”

即使我们可以尝试其他的[激活函数](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#_blank)，比如 ReLU，来减少问题，它们也不能完全解决问题。RNN 的这一缺点导致了 LSTM 网络的兴起，从而有效地解决了这一问题。

#### LSTM 的组成部分

LSTM 网络也具有链状结构，但是重复模块具有不同的结构。不是只有一个神经网络层，而是有四个，以一种非常特殊的方式相互作用。LSTM 电池的结构如图 [3-9](#Fig9) 所示。

![A461351_1_En_3_Fig9_HTML.png](A461351_1_En_3_Fig9_HTML.png)

图 3-9

LSTM module with four interacting layers

使用多个门来形成 LSTM，这是一个很好的选择，可以用来管理通过的信息。它们有一个 sigmoid 神经网络层，输出为[0，1]以衡量组件的通过限制，以及一个逐点乘法运算。

在上图中，C <sub>i</sub> 是细胞状态，它存在于所有的时间步中，并因每个时间步中的相互作用而改变。为了通过单元状态保留流经 LSTM 的信息，它有三种类型的门:

*   Input gate : To control the contribution from a new input to the memory

    ![$$ {i}_t=\sigma\;\left({W}_i\cdot \left[{h}_{t-1},\;{x}_t\right]+{b}_i\right) $$](A461351_1_En_3_Chapter_Equf.gif)

    ![$$ {\acute{C}}_t= tanh\;\left({W}_C\cdot \left[{h}_{t-1},\;{x}_t\right]+{b}_c\right) $$](A461351_1_En_3_Chapter_Equg.gif)

    Here x <sub>t</sub> denotes the input at time step t, h<sub>t - 1</sub> denotes the hidden state at time step t-1, i <sub>t</sub> denotes the input gate layer output at time step t, Ć <sub>t</sub> refers to candidate values to be added to input gate output at time step t, b <sub>i</sub> and b <sub>c</sub> denote the bias for the input gate layer and the candidate value computation, W <sub>i</sub> and W <sub>c</sub> denote the weights for the input gate layer and the candidate value computation.

    ![$$ {C}_t={f}_t\;*\;{C}_{t-1}+{i}_t\;*\;\overset{\mathit{\hbox{'}}}{C_t} $$](A461351_1_En_3_Chapter_Equh.gif)

    Here, C <sub>i</sub> denotes the cell state after time step i, and f <sub>t</sub> denotes the forget state at time step t.

    ![A461351_1_En_3_Figb_HTML.png](A461351_1_En_3_Figb_HTML.png)

    ![A461351_1_En_3_Figa_HTML.png](A461351_1_En_3_Figa_HTML.png)

*   Forget gate: To control the limit up to which a value is pertained in the memory

    ![$$ {f}_t=\sigma\;\left({W}_f\cdot \left[{h}_{t-1},\;{x}_t\right]+{b}_f\right) $$](A461351_1_En_3_Chapter_Equi.gif)

    Here, f <sub>t</sub> denotes the forget state at time step t and, W <sub>f</sub> and b <sub>f</sub> denote the weights and bias for the forget state at time step t.

    ![A461351_1_En_3_Figc_HTML.png](A461351_1_En_3_Figc_HTML.png)

*   Output gate: To control up to what limit memory contributes in the activation block of output

    ![$$ {o}_t=\sigma\;\left({W}_o\;.\;\left[{h}_{t-1},\;{x}_t\right]+{b}_o\right) $$](A461351_1_En_3_Chapter_Equj.gif)

    ![$$ {h}_t={o}_t\;*\; \tanh \left({C}_t\right) $$](A461351_1_En_3_Chapter_Equk.gif)

    Here, o <sub>t</sub> denotes the output gate output at time step t, and W <sub>o</sub> and b <sub>o</sub> denote the weights and bias for the output gate at time step t.

    ![A461351_1_En_3_Figd_HTML.png](A461351_1_En_3_Figd_HTML.png)

今天，LSTM 网络已经成为比基本 rnn 更受欢迎的选择，因为它们已经被证明在各种问题上非常有效。与 RNNs 相比，最显著的结果是用 LSTM 网络实现的，并且现在这种现象已经扩展到，无论哪里引用 RNN，它通常仅指 LSTM 网络。

#### LSTM 如何帮助减少消失梯度问题

如我们之前提到的，在基本 RNN 中，在反向传播期间，即在计算梯度以更新权重时，出现消失梯度，因为它涉及偏导数的级联，并且每个偏导数涉及σ项，即 sigmoid 神经网络层。由于每个 sigmoid 导数的值可能变得小于 1，从而使整体梯度值变得足够小，以至于它们不能进一步更新权重，这意味着模型将停止学习！

现在，在一个 LSTM 网络中，遗忘门的输出是

![$$ {C}_t={f}_t\;*\;{C}_{t-1}+{i}_t\;*\;{\acute{C}}_t $$](A461351_1_En_3_Chapter_Equl.gif)

所以，C 对其时间滞后值 C <sub>t -1</sub> 的偏导数将得到值 f <sub>t</sub> ，乘以偏导数的次数。现在，如果我们设置 f = 1 的输出，就不会有梯度的衰减，这意味着所有过去的输入都会被记忆在单元格中。在训练过程中，遗忘之门将决定哪些信息是重要的，保留哪些信息，删除哪些信息。

##### 了解 GRUs

今天有许多 LSTM 的变体在使用。LSTM 的一个合理变化是门控循环单元，或 GRU(图 [3-10](#Fig10) )。它通过组合遗忘门和输入门来形成更新门，还合并单元状态和隐藏状态，并改变生成输出的方式。与标准的 LSTM 模型相比，得到的模型通常具有较低的复杂性。

GRU 像 LSTM 单元一样控制信息流，但不需要使用存储单元。它只是暴露了完全隐藏的内容，没有任何控制。

据观察，LSTM 更适合较大的数据集，而 GRU 更适合较小的数据集。因此，没有硬性的规则，因为在某种程度上，效率取决于数据和模型的复杂性。

![A461351_1_En_3_Fig10_HTML.png](A461351_1_En_3_Fig10_HTML.png)

图 3-10

LSTM and GRU

##### LSTMs 的局限性

除了 LSTM 网络的复杂性，它们通常比其他典型模型要慢。通过仔细的初始化和训练，即使是 RNN 也能产生类似于 LSTM 的结果，而且计算复杂度更低。此外，当最近的信息比旧信息更重要时，毫无疑问，LSTM 模型总是更好的选择，但有些问题我们希望深入到过去来解决。在这种情况下，一种被称为注意力机制的新机制——这是一种稍微修改过的版本——越来越受欢迎。我们将在后面的小节“注意力评分”中介绍它

### 序列间模型

序列到序列(seq2seq)模型被用于从聊天机器人到语音到文本到对话系统到 QnA 到图像字幕的一切。seq2seq 模型的关键是序列保持了输入的顺序，而基本神经网络却不是这样。当然没有好的方法来表示时间和随时间变化的事物的概念，所以 seq2seq 模型允许我们处理带有时间或时间顺序元素的信息。它们允许我们保存普通神经网络无法保存的信息。

#### 这是什么？

简单来说，seq2seq 模型由两个独立的 rnn 组成，即编码器和解码器。编码器将信息作为多个时间步长中的输入，并将输入序列编码成上下文向量。解码器获取该隐藏状态，并将其解码为所需的输出序列。对于这种类型的模型，需要大量的数据，比如难以置信的大量数据。

seq2seq 模型背后的关键任务是将序列转换成固定大小的特征向量，该向量只编码序列中的重要信息，而丢失不必要的信息。

让我们考虑一个基本问答系统的例子，其中的问题是“你好吗？”在这种情况下，模型将单词序列作为输入，因此我们将尝试将序列中的每个单词放入一个固定大小的特征向量中，然后该向量可用于预测模型的输出，以获得结构化答案。模型必须记住第一个序列中的重要事情，同时也要丢掉该序列中任何不必要的信息，以产生相关的答案。

图 [3-11](#Fig11) 显示了编码器和解码器的展开版本，以便更好地理解整个过程。

![A461351_1_En_3_Fig11_HTML.jpg](A461351_1_En_3_Fig11_HTML.jpg)

图 3-11

Sample seq2seq model with input and output sentence

在编码器阶段，我们向网络输入嵌入在问题“你好吗？”中的单词向量，连同一组权重分配给 LSTMs 序列。在解码器端，在顶部，我们有一个时间分布的密集网络(在代码部分解释)，它用于预测当前文本词汇中的单词以获得答案。

相同的模型可以用于聊天机器人、语言翻译和其他相关目的。

##### 双向编码器

在双向编码器中，我们有一个覆盖正向文本的 lstm 系列和另一个覆盖反向文本的 lstm 系列，就在前一个系列之上。因此，这种情况下的权重，即上图中的 A，基本上是隐藏状态，我们最终有两个隐藏状态:一个来自向前方向，一个来自向后方向。这允许网络从文本中学习并获得关于上下文的全部信息。

对于几乎所有的 NLP 任务来说，双向 LSTMs 通常比其他任何方法都要好(图 [3-12](#Fig12) )。我们添加的双向 LSTMs 层越多，结果就越好。

![A461351_1_En_3_Fig12_HTML.jpg](A461351_1_En_3_Fig12_HTML.jpg)

图 3-12

Bidirectional encoder

##### 堆叠双向编码器

对于堆叠式双向编码器，如下图所示，我们有两个双向 LSTMs 或四层。(对于更复杂的结构和实现更好的结果，可以达到六个双向 LSTMs。)

这些 LSTM 层中的每一层内部都有权重，这些权重在自我学习，同时也影响前面层中的权重。

随着网络相对于给定的输入在时间上向前移动，并且遇到来自传入文本的新信息，它产生一个隐藏状态，表示在整个文本中存在的所有有用的东西(图 [3-13](#Fig13) )。

![A461351_1_En_3_Fig13_HTML.jpg](A461351_1_En_3_Fig13_HTML.jpg)

图 3-13

Stacked bidirectional encoder

##### 解码器

编码器输出上下文向量，该向量提供之前发生的整个序列的快照。通过将上下文向量传递给解码器，上下文向量用于预测输出。

在解码器中，我们有一个使用 softmax 的密集层，就像在正常的神经网络中一样，并且它是时间分布的，这意味着每个时间步都有一个这样的层。

在图 [3-14](#Fig14) 中，顶部的圆圈代表整个词汇，得分最高的对应那个时间步的输出。这是有效的，如果我们正在处理文本，并试图只获得单词的结果，顶层将有一个神经元用于词汇表中的每个单词。随着词汇表大小的增加，顶层通常会变得非常大。

重要的是，为了开始预测，我们传入一个`<GO>`令牌来启动预测过程。接下来，我们将`<GO>`标记本身作为第一个单元格的输入，它现在预测我们答案的第一个单词，以及来自上下文向量的信息，然后我们从模型中获取预测的第一个单词，并将其作为输入输入到下一个时间步骤，以获得第二个单词的预测，依此类推。这将导致我们的答案的整个文本的创建。理论上，在理想情况下，当预测正确时，模型应该预测我们试图回答或翻译的任何内容。

![A461351_1_En_3_Fig14_HTML.jpg](A461351_1_En_3_Fig14_HTML.jpg)

图 3-14

Decoder

### 高级序列到序列模型

基本的 seq2seq 模型对于短句的正常任务很有效，但是对于长句就开始失效了。此外，正常的 LSTMs 可以记住大约 30 个时间步长，并且在 30 个时间步长之后开始非常快速地下降。如果他们没有得到足够的训练，他们甚至会更快地离开。

与基本的 seq2seq 模型相比，注意机制在短期长度序列上表现更好。此外，使用注意机制，我们可以达到大约 50 个时间步长的最大长度。目前 NLP 的一个主要限制是我们没有任何东西可以真正回到过去，甚至记住几个段落，更不用说整本书了。

有几个技巧可以解决这个问题。例如，我们可以翻转输入，并向后训练模型，即向后进入，向前出来。这通常会使结尾词更接近，并有助于更好地关联预测词。

序列到序列可以是 rnn、lstm(首选)或 gru，对于较低级别的任务，首选双向 lstm。我们将研究一些用于处理此类问题的高级模型。

#### 注意力评分

注意力模型查看显示的整个内容，并找出方法来计算出哪个单词对文本中的每个单词最重要。所以，它会给你句子中的每个单词打分，这样，它就能感觉到某些单词对某些单词的依赖程度远远超过其他单词。

以前的文本生成方法包括生成语法非常好的句子，但这要么会弄错名称，要么会重复一些字符，如问号。理解注意力模型的最好方法是把它们想象成一种小小的记忆模块，它基本上位于网络之上，然后查看单词并挑选出最重要的。例如，在下面的句子中，显然不是所有的单词都同等重要:

上个月大家都去了俱乐部，但我呆在家里。

上个月大家都去了俱乐部，但我呆在家里。

与句子中的其他单词相比，第二个句子中的斜体单词是被注意到且得分较高的单词。这有助于翻译成不同的语言，也有助于保留上下文信息，例如“上个月”发生的事件，因为在执行 NLP 任务时需要这个时间信息。

增加注意力有助于获得固定长度的向量，每个单词的得分告诉我们每个单词和时间步长在给定序列中的重要性。这在翻译时变得很重要。当手动翻译一个长句子时，我们更关注特定的单词或短语，而不考虑它们在句子中的位置。注意力有助于为神经网络重建同样的机制。

如前所述，正常模型无法捕捉完整句子的关键，仅使用单个隐藏状态，随着长度的增加，情况会变得更糟。注意力向量(如图 [3-15](#Fig15) 所示)通过在解码器的每一步从整个输入句子中捕捉信息，有助于提高模型的性能。该步骤确保解码器不仅依赖于最后的解码器状态，还依赖于所有输入状态的组合权重。

最好的技术是在编码器中使用双向 LSTMs，同时注意它。

![A461351_1_En_3_Fig15_HTML.jpg](A461351_1_En_3_Fig15_HTML.jpg)

图 3-15

Attention scoring network

图 [3-16](#Fig16) 展示了一个用于语言翻译的注意力评分网络的用例。编码器获取输入令牌，直到它获得一个特殊的结束令牌，比如说`<DONE>`，然后解码器接管并开始生成令牌，也以它自己的结束令牌`<DONE>`结束。

随着英语句子标记的到来，编码器改变其内部状态，然后，一旦最后一个标记到达，就获取最终的编码器状态并将其传递给解码器，不变并重复。在解码器中，生成每一个德国令牌。解码器也有自己的动态内部状态。

![A461351_1_En_3_Fig16_HTML.jpg](A461351_1_En_3_Fig16_HTML.jpg)

图 3-16

Language translation using an attention scoring network

##### 教师强迫

教师强制使用地面实况作为每个连续时间步长的输入，而不是网络的输出。

人们可以参考关于教师强迫的原始论文的摘要，“教授强迫:训练递归网络的新算法”，以获得对该技术的令人信服的解释( [`https://papers.nips.cc/paper/6099-professor-forcing-a-new-algorithm-for-training-recurrent-networks.pdf`](https://papers.nips.cc/paper/6099-professor-forcing-a-new-algorithm-for-training-recurrent-networks.pdf) )。

> Teachers' mandatory algorithm trains recursive networks by providing observed sequence values as input in the training process and using the network's own one-step prediction to do multi-step sampling. We introduce the professor-forced algorithm, which uses the opposite domain adaptation to encourage the cyclic network to have the same dynamics when training the network and sampling from the network at multiple time steps.

为了更好地理解这一点，当我们训练教师强制模型时，在进行预测部分时，我们检查预测的每个单词是否正确，并在反向传播网络时使用该信息。但是，我们不会将预测的单词输入到下一个时间步骤。相反，在进行每个下一个单词预测时，我们使用上一个时间步的正确单词答案进行下一个时间步预测。这就是为什么这个过程被称为“教师强迫”我们基本上是强迫解码器部分不仅使用最后一个隐藏状态的输出，而且实际上使用正确的答案。这极大地改进了文本生成的训练过程。在对测试数据集进行实际评分时，不需要遵循此流程。将学习到的权重用于计分步骤。

教师强迫技术是作为训练 RNN 的时间反向传播的一种替代方法而开发的。图 [3-17](#Fig17) 显示了一个使用教师强制机制训练 RNN 的例子。

![A461351_1_En_3_Fig17_HTML.jpg](A461351_1_En_3_Fig17_HTML.jpg)

图 3-17

Teacher forcing approach

##### 偷看

扫视包括通过 RNN 或 LSTM 的每一步直接输入上下文向量的隐藏状态。隐藏状态在每次通过权重时都会改变，我们利用这个更新的隐藏状态，并且还保留来自编码器的原始上下文向量，以便它检查发生的定期更新，从而找出提高准确性的方法。

Peeking 是由 Yoshua Bengio 等人在研究论文《使用 RNN 编码器学习短语表示——统计机器翻译的解码器》( [`https://arxiv.org/abs/1406.1078`](https://arxiv.org/abs/1406.1078) )中提出的。

> We propose a new neural network model called rnn encoder-decoder, which consists of two RNN. One RNN encodes the symbol sequence into a fixed-length vector representation, and the other decodes the representation into another symbol sequence. The encoder and decoder of this model are jointly trained to maximize the conditional probability of the target sequence given the source sequence. The proposed model learns the semantic and syntactic meaningful expressions of language phrases.

### 序列间用例

对于 seq2seq 模型的用例，我们采用了 H. Gurulingappa 的研究论文“支持从医学病例报告中自动提取药物相关不良反应的基准语料库的开发”( [`www.sciencedirect.com/science/article/pii/S1532046412000615`](http://www.sciencedirect.com/science/article/pii/S1532046412000615) )中使用的注释语料库的文本内容。

> The purpose of this paper is to generate a systematic annotated corpus, which can support the development and verification of methods for automatically extracting drug-related adverse reactions from medical case reports. In order to ensure the consistency of annotations, documents are systematically double annotated in different rounds. The annotations are finally coordinated to generate representative consistent annotations. We use the open source skip-gram model ( [`http://evexdb.org/pmresources/vec-space-models/wikipedia-pubmed-and-PMC-w2v.bin`](http://evexdb.org/pmresources/vec-space-models/wikipedia-pubmed-and-PMC-w2v.bin) ) provided by NLPLab, which is trained on all PubMed abstracts and PMC full texts (4.08 million different words). The output of the skip model is a set of 200-dimensional word vectors.

像往常一样，首先导入所有必需的模块:

```
# Importing the required packages
import os
import re
import csv
import codecs
import numpy as np
import pandas as pd

import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
from string import punctuation
from gensim.models import KeyedVectors

```

检查用于本练习的 Keras 和 TensorFlow 版本:

```
import keras
print(keras.__version__)
> 2.1.2
import tensorflow
print(tensorflow.__version__)
> 1.3.0

```

确保您已经从前面提到的链接下载并保存了 word 嵌入文件到当前的工作目录中。

```
EMBEDDING_FILE = 'wikipedia-pubmed-and-PMC-w2v.bin'
print('Indexing word vectors')
> Indexing word vectors

word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)
print('Found %s word vectors of word2vec' % len(word2vec.vocab))
> Found 5443656 word vectors of word2vec

import copy
from keras.preprocessing.sequence import pad_sequences
> Using TensorFlow backend.

```

Gurulingappa 在论文中使用的 ADE 语料库分为三个文件:`DRUG-AE.rel`、`DRUG-DOSE.rel`和`ADE-NEG.txt`。我们正在利用`DRUG-AE.rel`文件，该文件提供了药物和不良反应之间的关系。

以下是该文件中的文本示例:

```
10030778 | Intravenous azithromycin-induced ototoxicity. | ototoxicity | 43 | 54 | azithromycin | 22 | 34
10048291 | Immobilization, while Paget’s bone disease was present, and perhaps enhanced activation of dihydrotachysterol by rifampicin, could have led to increased calcium-release into the circulation. | increased calcium-release | 960 | 985 | dihydrotachysterol | 908 | 926
10048291 | Unaccountable severe hypercalcemia in a patient treated for hypoparathyroidism with dihydrotachysterol. | hypercalcemia | 31 | 44 | dihydrotachysterol | 94 | 112
10082597 | METHODS: We report two cases of pseudoporphyria

caused by naproxen and oxaprozin. | pseudoporphyria | 620 | 635 | naproxen | 646 | 654
10082597 | METHODS: We report two cases of pseudoporphyria caused by naproxen and oxaprozin. | pseudoporphyria | 620 | 635 | oxaprozin | 659 | 668

```

`DRUG-AE.rel`文件的格式如下，字段由管道分隔符分隔:

第 1 列:PubMed-ID

第二栏:句子

第 3 栏:不利影响

第 4 列:在“文档级别”开始抵消不利影响

第 5 列:“文档级别”的不利影响的结束偏移量

第 6 栏:药物

第 7 列:药品在“文件级别”的起始偏移量

第 8 列:药品在“文档级别”的结束偏移量

Note

在注释过程中，使用了以下格式的文档:PubMed-ID \n \n Title \n \n Abstract。

```
# Reading the text file 'DRUG-AE.rel' which provides relations between drugs and adverse effects.
TEXT_FILE = 'DRUG-AE.rel'

```

接下来，我们想要为我们的模型创建输入。我们模型的输入是一个字符序列。目前，我们认为序列长度为 200，也就是说，我们将拥有一个大小为“原始字符数-序列长度”的数据集

对于每一个输入数据，即 200 个字符的序列，接下来，一个字符将以一键编码的格式输出。我们将在`input_data_ae`和`op_labels_ae`张量中添加输入数据字段及其相应的标签，如下所示:

```
f = open(TEXT_FILE, 'r')

for each_line in f.readlines():
    sent_list = np.zeros([0,200])
    labels = np.zeros([0,3])
    tokens = each_line.split("|")
    sent = tokens[1]
    if sent in sentences:
        continue
    sentences.append(sent)
    begin_offset = int(tokens[3])
    end_offset = int(tokens[4])
    mid_offset = range(begin_offset+1, end_offset)
    word_tokens = nltk.word_tokenize(sent)
    offset = 0
    for each_token in word_tokens:
        offset = sent.find(each_token, offset)
        offset1 = copy.deepcopy(offset)
        offset += len(each_token)
        if each_token in punctuation or re.search(r'\d', each_token):
            continue
        each_token = each_token.lower()
        each_token = re.sub("[^A-Za-z\-]+","", each_token)
        if each_token in word2vec.vocab:
            new_word = word2vec.word_vec(each_token)
        if offset1 == begin_offset:
            sent_list = np.append(sent_list, np.array([new_word]), axis=0)
            labels = np.append(labels, np.array([[0,0,1]]), axis=0)
        elif offset == end_offset or offset in mid_offset:
            sent_list = np.append(sent_list, np.array([new_word]), axis=0)
            labels = np.append(labels, np.array([[0,1,0]]), axis=0)
        else:
            sent_list = np.append(sent_list, np.array([new_word]), axis=0)
            labels = np.append(labels, np.array([[1,0,0]]), axis=0)
    input_data_ae.append(sent_list)
    op_labels_ae.append(labels)
input_data_ae = np.array(input_data_ae)
op_labels_ae  = np.array(op_labels_ae)

```

向输入文本添加填充，在任何时间步长输入的最大长度为 30(一个安全的赌注！).

```
input_data_ae = pad_sequences(input_data_ae, maxlen=30, dtype="float64", padding="post")
op_labels_ae = pad_sequences(op_labels_ae, maxlen=30, dtype="float64", padding="post")

```

检查输入数据中条目总数的长度及其对应的标签。

```
print(len(input_data_ae))
> 4271
print(len(op_labels_ae))
> 4271

```

从 Keras 导入所需模块。

```
from keras.preprocessing.text import Tokenizer
from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Bidirectional, TimeDistributed
from keras.layers.merge import concatenate
from keras.models import Model, Sequential
from keras.layers.normalization import BatchNormalization
from keras.callbacks import EarlyStopping, ModelCheckpoint

```

创建训练和验证数据集，训练中有 4，000 个条目，其余 271 个在验证数据集中。

```
# Creating Train and Validation datasets, for 4271 entries, 4000 in train dataset, and 271 in validation dataset
x_train= input_data_ae[:4000]
x_test = input_data_ae[4000:]
y_train = op_labels_ae[:4000]
y_test =op_labels_ae[4000:]

```

现在我们有了标准格式的数据集，接下来是这个过程中最重要的部分:定义模型架构。我们将使用双向 LSTM 网络的一个隐藏层，有 300 个隐藏单元，丢失概率为 0.2。除此之外，我们还使用了一个 TimeDistributedDense 层，丢失概率为 0.2。

Dropout 是一种正则化技术，通过这种技术，当你更新神经网络的层时，你随机地不更新，或`dropout`，某些层。也就是说，在更新你的神经网络层时，你用概率`1-dropout`更新每个节点，用概率`dropout`保持不变。

时间分布层用于 RNN(和 LSTMs)以保持输入和输出之间的一对一映射。假设我们有 30 个时间步长和 200 个数据样本，即 30 个`×` 200，我们想要使用输出为 3 的 RNN。如果我们不使用一个时间分布密度层，我们将得到一个 200 `×` 30 `×` 3 张量。因此，我们将输出平坦化，每个时间步长混合。如果我们应用 TimeDistributedDense 层，我们将在每个时间步长上应用完全连接的密集层，并按时间步长分别获得输出。

我们还使用`categorical_crossentropy`作为损失函数，`adam`作为优化器，`softmax`作为激活函数。

您可以尝试所有这些东西，以便更好地了解 LSTM 网络是如何工作的。

```
batch = 1      # Making the batch size as 1, as showing model each of the instances one-by-one
# Adding Bidirectional LSTM with Dropout, and Time Distributed layer with Dropout
# Finally using Adam optimizer for training purpose
xin = Input(batch_shape=(batch,30,200), dtype="float")
seq = Bidirectional(LSTM(300, return_sequences=True),merge_mode='concat')(xin)
mlp1 = Dropout(0.2)(seq)
mlp2 = TimeDistributed(Dense(60, activation="softmax"))(mlp1)
mlp3 = Dropout(0.2)(mlp2)
mlp4 = TimeDistributed(Dense(3, activation="softmax"))(mlp3)
model = Model(inputs=xin, outputs=mlp4)
model.compile(optimizer='Adam', loss="categorical_crossentropy")

```

我们将用 50 个纪元和 1 的批量大小来训练我们的模型。只要模型不断改进，您总是可以增加纪元的数量。还可以创建检查点，以便以后可以检索和使用模型。创建检查点的想法是在训练时保存模型权重，以便以后不必再次经历相同的过程。这是留给读者的一个练习。

```
model.fit(x_train, y_train,
          batch_size=batch,
          epochs=50,
          validation_data=(x_test, y_test))
> Train on 4000 samples, validate on 271 samples
> Epoch 1/50
4000/4000 [==============================] - 363s 91ms/step - loss: 0.1661 - val_loss: 0.1060
> Epoch 2/50
4000/4000 [==============================] - 363s 91ms/step - loss: 0.1066 - val_loss: 0.0894
> Epoch 3/50
4000/4000 [==============================] - 361s 90ms/step - loss: 0.0903 - val_loss: 0.0720
> Epoch 4/50
4000/4000 [==============================] - 364s 91ms/step - loss: 0.0787 - val_loss: 0.0692
> Epoch 5/50
4000/4000 [==============================] - 362s 91ms/step - loss: 0.0698 - val_loss: 0.0636
...
...
...
> Epoch 46/50
4000/4000 [==============================] - 344s 86ms/step - loss: 0.0033 - val_loss: 0.1596
> Epoch 47/50
4000/4000 [==============================] - 321s 80ms/step - loss: 0.0033 - val_loss: 0.1650
> Epoch 48/50
4000/4000 [==============================] - 322s 80ms/step - loss: 0.0036 - val_loss: 0.1684
> Epoch 49/50
4000/4000 [==============================] - 319s 80ms/step - loss: 0.0027 - val_loss: 0.1751
> Epoch 50/50
4000/4000 [==============================] - 319s 80ms/step - loss: 0.0035 - val_loss: 0.1666
<keras.callbacks.History at 0x7f48213a3b38>

```

在具有 271 个条目的验证数据集上验证模型结果。

```
val_pred = model.predict(x_test,batch_size=batch)
labels = []
for i in range(len(val_pred)):
    b = np.zeros_like(val_pred[i])
    b[np.arange(len(val_pred[i])), val_pred[i].argmax(1)] = 1
    labels.append(b)

print(val_pred.shape)
> (271, 30, 3)

```

Note

`val_pred`张量的大小为(271 × 30 × 3)。

使用 F1 分数以及精确度和召回率检查模型性能。从 scikit-learn 库中导入所需的模块。

```
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score  

```

定义变量以记录模型性能。

```
score =[]
f1 = []
precision =[]
recall =[]
point = []

```

我们可以将验证数据集中 F1 值超过 0.6 的所有实例列入候选名单。这将使我们对验证数据的性能有一个公平的概念，使用我们设定的基准。

```
for i in range(len(y_test)):
    if(f1_score(labels[i],y_test[i],average='weighted')>.6):
        point.append(i)
    score.append(f1_score(labels[i],y_test[i],average='weighted'))
    precision.append(precision_score(labels[i],y_test[i],average='weighted'))
    recall.append(recall_score(labels[i],y_test[i],average='weighted'))

print(len(point)/len(labels)*100)
> 69.37
print(np.mean(score))
> 0.686
print(np.mean(precision))
> 0.975
print(np.mean(recall))
> 0.576

```

虽然产生的结果不太令人满意，但它确实达到了接近最先进的结果。这些限制可以通过构建更密集的网络、增加历元的数量和数据集的长度来克服。

使用 CPU 训练大型数据集需要太多时间。这就是为什么使用 GPU 几乎是不可避免的，并且对于快速训练深度学习模型非常重要。

训练 RNN 是一项有趣的运动。相同的算法可以扩展到许多其他练习，例如音乐生成、语音生成等。它还可以有效地扩展到现实生活中的应用，如视频字幕和语言翻译。

我们鼓励读者在这个层次上为不同的应用程序创建自己的模型。我们将在接下来的章节中涉及更多这样的例子。

## 后续步骤

本章介绍的结构是最重要的部分，也是任何 RNN 类型的核心，无论是暹罗网络、seq2seq 模型、注意机制还是迁移学习。(建议读者进一步研究这些概念，以便更好地理解广泛可用的网络、其结构的变化以及它们各自的用例。)

此外，如果您能够直观地理解三维向量的维数和乘法在 TensorFlow 和 NumPy 中是如何工作的，您就能够实现最复杂的模型。所以，重点应该是尽可能多地掌握基础知识。旨在通过注意力/权重增加复杂性的模型只是为了提高模型准确性而进行的一些迭代/思考。这些进一步的改进更像是黑客，无论多么成功，但仍然需要一个结构化的思考过程。同样，最好的办法是不断尝试不同类型的模型及其广泛的应用，以便很好地掌握概念。